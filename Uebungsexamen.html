<!DOCTYPE html>
<html lang="de">
    <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ISTQB FL Übungsfragen</title>

    <style>
    body {
        display: flex;
        justify-content: center;
        align-items: center;
        scroll-behavior: smooth;
    }

    form {
        border: 2px solid gainsboro;
        margin-top: .5vh;
        width: 75vw;
    }

    textarea {
        padding-left: 2rem;
        width: 67vw;
        height: 450px;
    }

    form img {
        padding-left: 5rem;
    }

    label {
        position: relative;
        width: 100%;
        font: 14px Verdana, Arial, sans-serif
    }

    form fieldset div {
        transform-origin: center;
        margin-left: 7rem;
        margin-top: .5rem;
        margin-bottom: .5rem;
    }

    #submit {
        margin-left: 5rem;
    }

    input[type='checkbox'],label {
        margin-top: 2rem;
        border-width: 1rem;
        position: relative;
    }

    input[type='checkbox'] {
        display: none;
    }

    input[type='checkbox'] + label::before,
    input[type='checkbox'] + label::after {
        content: "";
        position: absolute;
        left: -2rem;
        top: 0;
        aspect-ratio: 1/1;
        border-radius: 50%;
    }

    input[type='checkbox'] + label::after {
        background-color: white;
        border: 2px solid white;
        height: 24px;
        transform: translate(-6px,-6px);
    }

    input[type='checkbox'] + label::before {
        background-color: midnightblue;
        border-width: 20px;
        height: 32px;
        transform: translate(-8px,-8px);
    }
/*
    div:hover label::before {
        background-color: gold;
    }

    div:hover label::after {
        background-color: gold;
    }
*/
    input[type='checkbox']:checked + label::after {
        background-color: midnightblue;
    }

    fieldset {
        border: none;
        width: 68vw;
    }

    #question {
        align-items: center;
        color: white;
        background-color: midnightblue;
        padding: 1em;
        font-size: 1rem;
    }

    input[type='button'] {
        border: none;
        color: white;
        background-color: midnightblue;
        padding: 1rem 2rem;
        border-radius: 25% / 50%;
    }

    input[type='button']:active {
        transform: translatey(.2rem);
    }

    input[type='button']:hover {
        transform: scale(1.02);
    }

    input[type='checkbox'] + .correct::after {
        background-color: orange;
    }

    input[type='checkbox'] + .correct::before {
        background-color: orange;
        height: 36px;
        transform: translate(-10px,-10px);
    }

    input[type='checkbox']:checked + .correct::after {
        background-color: green;
    }

    input[type='checkbox']:checked + .correct::before {
        background-color: green;
        height: 36px;
        transform: translate(-10px,-10px);
    }

    input[type='checkbox'] + .correct {
        font-weight: 700;
    }
    </style>
    <script>
        var running = false; //Quiz is running
        //Mode-array "lsModeSettings" stores [mode, modewrongcount, modehidecount, shuffle]
        var mode = 1; //1 = Normal (mode is stored at index 0 in lsModeSettings),
        //2 = Only questions that were wrong #(modewrongcount = index 1) times,
        //3 = Don't show questions that were correct #(modehidecount = index 2) times
        //4 = mode 2&3
        var modewrongcount = 0; //Default value = 0
        var modehidecount = 0; //Default value = 0
        var shuffle = true;
        var lsModeSettings; //All mode settings.
        var counterOutput = " / ";
        var msgAlertOnlyOne = "Bitte wählen Sie genau eine Antwort aus.";
        var msgCorrectAnswers = "Fertig. Richtige Antworten: ";
        var msgIllegalSelection = "Bei Ihrer aktuellen Auswahl werden 0 Fragen ausgewählt, bitte passen Sie die Auswahl an."
        var msgCorrectAnswersOf = " von ";
        var q = 0;
        var correctAnswers = 0;
        var lsAnswersWrong; //Results (wrong).
        var lsAnswersCorrect; //Results (correct).
        var lsRuns; //Number of runs [started, ended/finished]
        //Format:
        //[question, a1, a2, a3, a4, correct-answer, explanation, image, chapter, exam]
        //0 = question
        //1..4 = answer 1 - answer 4
        //5 = correct answer (index)
        //6 = explanation, escaped line breaks
        //7 = image (optional, can be empty string '')
        //8 = chapter 1-6 or 0=glossary
        //9 = exam [0 = 1.3, 1 = 1.6, 2 = 2016B, 3 = HTB]
        var qanda = [];
        var qanda_original = [
        ['Welche der folgenden Aussagen ist die korrekte Definition des Begriffes „Testfall“?',
'Teilmenge des Wertebereichs innerhalb einer Komponente oder eines Systems, für die aufgrund der Spezifikation erwartet wird, dass alle Werte gleichartig behandelt werden.',
'Menge von Vorbedingungen, Eingaben, Aktionen, erwarteten Ergebnissen und Nachbedingungen, welche auf Basis von Testbedingungen entwickelt wurden.',
'Arbeitsergebnis, welches während des Testprozesses erstellt wird und dazu gebraucht wird, um die Tests zu planen, zu entwerfen, auszuführen, auszuwerten und darüber zu berichten.',
'Informationsquelle zur Ermittlung des erwarteten Ergebnisses, um es mit dem tatsächlichen Ergebnis eines Systems unter Test zu vergleichen.',
2,
'Schlüsselwort: Testfall\n\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Basierend auf der Definition Äquivalenzklasse aus dem Glossar 3.3.\n\nb) KORREKT – Basierend auf einer Definition Testfall aus dem Glossar 3.3.\n\nc) FALSCH – Basierend auf der Glossardefinition Testmittel (Glossar 3.3).\n\nd) FALSCH – Basierend auf der Definition des Begriffs Testorakel (Glossar 3.3).',
'',0,0],
['Welche der folgenden Aussagen ist ein typisches Ziel des Testens von Software?',
'Fehlerwirkungen und Fehlerzustände aufdecken',
'Validierung von Projektplänen',
'Sicherstellen von vollständigen Tests',
'Vergleich der Istergebnisse mit den erwarteten Ergebnissen',
1,
'FL-1.1.1 (K1) Typische Ziele des Testens identifizieren können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Eines der typischen Hauptziele des Testens aus dem Lehrplan (1.1.1).\n\nb) FALSCH – Die Validierung des Projektplans ist eine Projektmanagementaktivität.\n\nc) FALSCH – Widerspruch zum Grundsatz 2; Vollständiges Test ist nicht möglich. (CTFL CORE Syllabus 2018, V.3.1; Abschnitt 1.3).\n\nd) FALSCH – „Vergleich der Istergebnisse mit den erwarteten Ergebnissen“ ist eine Aktivität der Testdurchführung, aber kein Testziel. (CTFL CORE Syllabus 2018, V.3.1; Abschnitt 1.4.2, Testdurchführung).',
'',1,0],
['Welches der folgenden Beispiele ist eine Fehlerwirkung in einem Tempomat eines Autos?',
'Der Entwickler des Systems hat vergessen, Variablen nach einem Ausschneiden und Einfügen umzubenennen.',
'Nicht benötigter Code, der beim Rückwärtsfahren einen Alarm auslöst, wurde in das System aufgenommen.',
'Das System hält die eingestellte Geschwindigkeit nicht mehr ein, wenn die Radiolautstärke erhöht oder verringert wird.',
'Die System-Entwurfsspezifikation gibt die Geschwindigkeit falsch an.',
3,
'FL-1.2.3 (K2) Zwischen Fehlhandlung, Fehlerzustand und Fehlerwirkung unterscheiden können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Dies ist ein Beispiel für einen vom Entwickler begangenen Fehler (Fehlhandlung).\n\nb) FALSCH – Dies ist ein Beispiel für einen Fehlerzustand (etwas, das im Code falsch ist und einen Fehler verursachen kann).\n\nc) KORREKT – Dies ist eine Abweichung von der erwarteten Funktionalität - ein Tempomat sollte nicht von der Lautstärkeeinstellung des Radios betroffen sein.\n\nd) FALSCH – Dies ist ein Beispiel für einen Defekt (Fehlerzustand in einer Spezifikation, die eine Fehlerwirkung verursachen kann, wenn gegen die Spezifikation anschließend implementiert wird).',
'',1,0],
['Welche der folgenden Aussagen ist eher ein Fehlerzustand als eine Grundursache für einen Fehlerzustand in einem Fitness-Tracker?',
'Der Anforderungsmanager war mit der Domäne des Fitnesstrainings nicht vertraut und ging zu Unrecht davon aus, dass die Benutzer die Herzschlag-Frequenz in Schlägen pro Stunde ablesen wollen.',
'Der Tester des Smartphone-Interfaces war nicht im zustandsbasierten Testen geschult und hat daher einen signifikanten Fehler übersehen.',
'Eine vom Entwickler für die GPS-Funktion fehlerhaft implementierte Konfigurationsvariable kann während der Sommerzeit zu Standortproblemen führen.',
'Die Designerin der Benutzeroberfläche hat noch nie an tragbaren Geräten gearbeitet und missverstand deshalb die Auswirkungen von reflektiertem Sonnenlicht.',
3,
'FL-1.2.4 (K2) Zwischen der Grundursache eines Fehlerzustands und seinen Auswirkungen unterscheiden können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Die mangelnde Vertrautheit des Autors der Anforderungen mit der Fitnessdomäne ist eine wesentliche Grundursache für einen Fehlerzustand.\n\nb) FALSCH – Die fehlende Schulung des Testers im zustandsbasierten Testen war eine der wesentlichen Grundursachen für den Fehler.\n\nc) KORREKT – Die fehlerhaften Konfigurationsdaten stellen einen Fehlerzustand in der Software des Fitness-Trackers dar, der zu Fehlerwirkungen führen kann. Die Grundursache ist „Eine vom Entwickler für die GPS-Funktion fehlerhaft implementierte Konfigurationsvariable". (V.3.0)\n\nd) FALSCH – Die mangelnde Erfahrung bei der Gestaltung von Benutzeroberflächen für tragbare Geräte ist ein typisches Beispiel für eine Grundursache für einen Fehlerzustand.',
'',1,0],
['Als Ergebnis der Risikoanalyse werden mehr Tests auf die Bereiche des Systems unter Test angewendet, in denen die ersten Tests mehr Fehler als in den anderen Bereichen aufgedeckt haben. Welcher der folgenden Grundsätze des Testens wird angewendet?',
'Vorsicht vor dem Pestizid-Paradoxon.',
'Das Testen ist kontextabhängig.',
'Trugschluss: Keine Fehler bedeutet brauchbares System.',
'Häufung von Fehlerzuständen.',
4,
'FL-1.3.1 (K2) Die sieben Grundsätze des Softwaretestens erklären können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – „Vorsicht vor dem Pestizid-Paradoxon“ befasst sich mit dem erneuten Ausführen der gleichen Tests und der Verringerung ihrer Wirksamkeit bei der Fehlersuche.\n\nb) FALSCH – Dieses Prinzip des Testens befasst sich mit der Durchführung von Tests, die je nach Kontext unterschiedlich sind (z.B. Spiele vs. sicherheitskritisch).\n\nc) FALSCH – Dieses Prinzip des Testens betrifft den Unterschied zwischen einem getesteten und einem festen System und einem validierten System. Keine "Fehler" bedeutet nicht, dass das System einsatzbereit ist.\n\nd) KORREKT – Wenn eine Häufung von Fehlerzuständen identifiziert wird (Bereiche des Systems, die mehr Fehler enthalten als der Durchschnitt), sollte der Testaufwand auf diese Bereiche ausgerichtet sein.',
'',1,0],
['Welches ist die korrekte Paarung von Testaktivitäten und Testaufgaben?',
'A-2, B-3, C-4, D-1',
'A-2, B-1, C-3, D-4',
'A-3, B-2, C-4, D-1',
'A-3, B-2, C-1, D-4',
1,
'FL-1.4.2 (K2) Die Testaktivitäten und zugehörigen Aufgaben innerhalb des Testprozesses beschreiben können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nOption a) ist korrekt. Die korrekte Paarung von Testaktivitäten und -aufgaben laut Lehrplan (1.4.2) ist:\nA. Testentwurf – (2) Identifizierung von notwendigen Testdaten zur Unterstützung der Testbedingungen und Testfälle.\n\nB. Testrealisierung – (3) Priorisierung von Testabläufen und Vorbereitung der Testdaten.\n\nC. Testdurchführung – (4) Analyse von Abweichungen, um deren Ursache zu ermitteln.\n\nD. Testabschluss – (1) Erfassung von Änderungsanforderungen für offene Fehlerberichte.',
'https://i.imgur.com/blPgs39.png',0,0],
['Welche der folgenden Aussagen beschreibt AM BESTEN, wie ein Mehrwert durch Aufrechterhaltung und Wartung der Verfolgbarkeit zwischen Testbasis und Testartefakten erzielt wird?',
'Wartungstests können basierend auf Änderungen der ursprünglichen Anforderungen vollständig automatisiert werden.',
'Es kann festgestellt werden, ob ein neuer Testfall eine höhere Abdeckung der Anforderungen erreicht.',
'Testmanager können feststellen, welche Tester die Fehler mit dem höchsten Schweregrad gefunden haben.',
'Bereiche, die möglicherweise durch Seiteneffekte einer Änderung beeinflusst werden, können durch Regressionstests gezielt überprüft werden.',
2,
'FL-1.4.4 (K2) Die Bedeutung der Pflege der Verfolgbarkeit zwischen Testbasis und Testarbeitsergebnissen erklären können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Die Verfolgbarkeit ermöglicht die Verknüpfung vorhandener Testfälle mit aktualisierten und gelöschten Anforderungen (obwohl keine neuen Anforderungen unterstützt werden), sie hilft jedoch nicht bei der Automatisierung von Wartungstests.\n\nb) KORREKT – Wenn alle Testfälle mit Anforderungen verknüpft sind, kann bei jeder Hinzufügung eines neuen Testfalls (mit Verfolgbarkeit) festgestellt werden, ob zuvor nicht abgedeckte Anforderungen durch den neuen Testfall abgedeckt werden.\n\nc) FALSCH – Die Verfolgbarkeit zwischen Testbasis und Testartefakten liefert keine Informationen darüber, welche Tester Fehler mit hohem Schweregrad festgestellt haben, und selbst wenn diese Informationen ermittelt werden könnten, wäre dies von begrenztem Wert.\n\nd) FALSCH – Bereiche die durch eine Änderung DIREKT betroffen sind, können durch die Verfolgbarkeit identifiziert werden. Seiteneffekte betreffen jedoch die Bereiche welche NICHT DIREKT betroffen und damit NICHT VERFOLGBAR sind.',
'',1,0],
['Welche der folgenden Eigenschaften findet man EHER in der Denkweise eines Testers als in der Denkweise eines Entwicklers?',
'Die Leistung eines Testers wächst und reift mit steigender Erfahrung.',
'Die Fähigkeit zu erkennen, was an Lösungen falsch sein könnte.',
'Gute Kommunikation mit Teammitgliedern.',
'Aufmerksamkeit für Details.',
2,
'FL-1.5.2 (K2) Den Unterschied zwischen der für Testaktivitäten erforderlichen Denkweise und der für Entwicklungsaktivitäten erforderlichen Denkweise erklären können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Sowohl Entwickler als auch Tester profitieren von Erfahrung.\n\nb) KORREKT – Entwickler sind häufig stärker am Entwurf und an der Erstellung von Lösungen interessiert als daran, darüber nachzudenken, was an diesen Lösungen falsch sein könnte (Siehe CTFL CORE Lehrplan 2018, Abschnitt 1.5.2).\n\nc) FALSCH – Sowohl Entwickler als auch Tester sollten gute Kommunikationsfähigkeiten haben.\n\nd) FALSCH – Sowohl Entwickler als auch Tester müssen auf Details achten.',
'',1,0],
['Welche der folgenden Optionen zeigt KORREKT, welche dieser Aussagen wahr und welche falsch sind?',
'Wahr – 1, 2; Falsch – 3, 4',
'Wahr – 2, 3; Falsch – 1, 4',
'Wahr – 1, 2, 4; Falsch – 3',
'Wahr – 1, 4; Falsch – 2, 3',
4,
'FL-2.1.1 (K2) Die Beziehungen zwischen Softwareentwicklungsaktivitäten und Testaktivitäten im Softwareentwicklungslebenszyklus erklären können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\n1. WAHR: „Für jede Entwicklungsaktivität sollte es eine zugehörige Testaktivität geben.“(siehe CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).\n\n2. FALSCH: „Reviewaktivitäten sollten starten, sobald die finale Version der Dokumente verfügbar ist.“ Sie sollten starten, sobald erste Entwürfe dafür vorliegen, (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.).\n\n3. FALSCH: „Testentwurf und Implementierung der Tests sollten während der entsprechenden Entwicklungsaktivitäten starten.“\n– Testanalyse und Testentwurf sollten während der entsprechenden Entwicklungsaktivitäten beginnen, nicht die Testimplementierung, (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.\n\n4. WAHR: „Testaktivitäten sollten schon in frühen Phasen des Softwareentwicklungslebenszyklus beginnen.“ (siehe CTFL Lehrplan 2018, Abschnitt 2.1.1.)\nFolglich ist d) korrekt',
'https://i.imgur.com/nKE7Tvo.png',2,0],
['Auf welcher der angegebenen Teststufen wird der dargestellte Test AM WAHRSCHEINLICHSTEN durchgeführt?',
'Integrationstest.',
'Abnahmetest.',
'Systemtest.',
'Komponententest.',
1,
'FL-2.2.1 (K2) Die unterschiedlichen Teststufen unter den Aspekten der Testziele, Testbasis, Testobjekte, typischen Fehlerzustände und Fehlerwirkungen sowie der Testvorgehensweise und Verantwortlichkeiten vergleichen können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nAufgrund der obigen Beschreibung und des CTFL Lehrplans 2018, Abschnitt 2.2 erkennt man:\n\n• „Er basiert auf Schnittstellenspezifikationen” – Die Testbasis für Integrationstests enthält die Spezifikationen von Schnittstellen (zusammen mit Kommunikationsprotokollen). Hingegen enthält keine der anderen angegebenen Teststufen diese Arbeitsergebnisse als Testbasis.\n\n• „Der Schwerpunkt liegt auf dem Finden von Fehlerwirkungen in der Kommunikation” –Fehlerwirkungen in der Kommunikation der getesteten Komponenten sind eine der typischen Fehlerarten, welche man beim Integrationstest findet, während diese Fehlerart bei keiner anderen der angegebenen Teststufen im Schwerpunkt liegt.\n\n• „Die Testvorgehensweise wendet sowohl funktionale als auch strukturelle Testarten an” –Funktionale und strukturelle Testarten sind beim Integrationstest beide als Vorgehensweise möglich, wie sie auch für jede andere Teststufe geeignet wären. Im Lehrplan werden sie allerdings nur noch beim Systemtest explizit erwähnt.\n\nFolglich ist Option a) richtig',
'https://i.imgur.com/yYh7V5I.png',2,0],
['Welche der folgenden Aussagen über Testarten und Teststufen ist ZUTREFFEND?',
'Funktionaler und nicht-funktionaler Test können auf den Teststufen System- und Abnahmetest durchgeführt werden, während der White-Box-Test auf Komponenten- und Integrationstests beschränkt ist.',
'Funktionaler Test kann auf jeder Teststufe durchgeführt werden, während der White-Box-Test auf Komponententest beschränkt ist.',
'Es ist möglich, funktionale, nicht-funktionale und White-Box-Tests in jeder Teststufe durchzuführen.',
'Funktionaler und nicht-funktionaler Test können auf jeder Teststufe durchgeführt werden, während der White-Box-Test auf Komponenten- und Integrationstests beschränkt ist.',
3,
'FL-2.3.2 (K1) Erkennen können, dass funktionale, nicht-funktionale und White-Box-Tests auf jeder Teststufe eingesetzt werden können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Es ist möglich, jede der Testarten (funktional, nicht-funktional, White-Box) in jeder Teststufe durchzuführen. Obwohl die Aussage richtig ist, dass funktionaler und nicht-funktionaler Test auf den Teststufen System- und Abnahmetest durchgeführt werden können, ist die Aussage falsch, dass White-Box-Test auf Komponenten- und Integrationstests beschränkt ist. (Siehe CTFL CORE Lehrplan 2018, Abschnitt 2.3.5)\n\nb) FALSCH – Es ist möglich, jede der Testarten (funktional, nicht-funktional, White-Box) in jeder Teststufe durchzuführen. Deswegen ist die Aussage falsch, dass White-Box-Test auf Komponententests beschränkt ist. (Siehe CTFL CORE Lehrplan 2018, Abschnitt 2.3.5)\n\nc) KORREKT – Es ist möglich, jede der Testarten (funktional, nicht-funktional, White-BoxTest) in jeder Teststufe durchzuführen. (Siehe CTFL CORE Lehrplan 2018, Abschnitt 2.3.5)\n\nd) FALSCH – Es ist möglich, jede der Testarten (funktional, nicht-funktional, White-Box) in jeder Teststufe durchzuführen. Deswegen ist die Aussage falsch, dass White-Box-Test auf Komponenten- und Integrationstests beschränkt ist. (Siehe CTFL CORE Lehrplan 2018, Abschnitt 2.3.5)',
'',2,0],
['Welche der folgenden Aussagen vergleicht die Zwecke der Fehlernachtests und Regressionstests AM BESTEN miteinander?',
'Der Regressionstest stellt sicher, dass alle früher durchgeführten Tests immer noch korrekt laufen, während der Fehlernachtest sicherstellt, dass Korrekturen an einem Teil des Systems die anderen Teile nicht negativ beeinflussen.',
'Der Fehlernachtest prüft, dass ein vorher gefundener Fehlerzustand korrigiert wurde, während der Regressionstest sicherstellt, dass die Korrektur keine anderen Teile des Systems negativ beeinflusst hat.',
'Der Regressionstest stellt sicher, dass Korrekturen an einem Teil des Systems die anderen Teile nicht negativ beeinflussen, während der Fehlernachtest prüft, dass alle früher durchgeführten Tests immer noch die gleichen Ergebnisse produzieren.',
'Der Fehlernachtest bestätigt, dass die Änderungen am System erfolgreich durchgeführt wurden, während der Regressionstest Tests durchführt, die vorher fehlgeschlagen sind, um sicherzustellen, dass sie jetzt korrekt funktionieren.',
2,
'FL-2.3.3 (K2) Den Zweck von Fehlernachtests und Regressionstests vergleichen können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Obwohl die Beschreibung des Regressionstests weitgehend richtig ist, ist die Beschreibung des Fehlernachtests (welcher bestätigen sollte, dass ein Fehlerzustand behoben wurde) falsch.\n\nb) KORREKT – Die Beschreibungen von Fehlernachtest und Regressionstest entsprechen sinngemäß dem CTFL Lehrplan 2018, Abschnitt 2.3.\n\nc) FALSCH – Obwohl die Beschreibung des Regressionstests weitgehend richtig ist, ist die Beschreibung des Fehlernachtests (erneute Durchführung aller früher durchgeführten Tests) falsch. Der Zweck des Fehlernachtests ist zu prüfen, ob Tests, die früher fehlgeschlagen sind, jetzt korrekt funktionieren.\n\nd) FALSCH – Obwohl die Beschreibung des Fehlernachtests weitgehend richtig ist, ist die Beschreibung des Regressionstests (Tests durchzuführen, die vorher fehlgeschlagen sind) falsch. Das würde eher einer detaillierteren Beschreibung des Fehlernachtests entsprechen.',
'',2,0],
['Welche der folgenden Aussagen beschreibt eine Aufgabe der Auswirkungsanalyse im Wartungstest KORREKT?',
'Die Auswirkungsanalyse unterstützt bei der Entscheidung, ob sich eine Fehlerkorrektur beim zu wartenden System lohnt.',
'Die Auswirkungsanalyse identifiziert, wie Daten in das gewartete System zu migrieren sind.',
'Die Auswirkungsanalyse unterstützt bei der Entscheidung, welche Hot Fixes den meisten Nutzen für den Benutzer haben.',
'Die Auswirkungsanalyse unterstützt die Ermittlung der Effektivität neuer Wartungstestfälle.',
1,
'FL-2.4.2 (K2) Den Einsatz der Auswirkungsanalyse im Wartungstest beschreiben können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Die Auswirkungsanalyse kann verwendet werden, um die Bereiche des Systems zu identifizieren, die von einer Fehlerbehebung betroffen sind. Daher kann das Ausmaß der Auswirkungen (z. B. nötige Regressionstests) verwendet werden, um bei der Entscheidung zu helfen, ob die Veränderung vorgenommen werden sollte (Siehe CTFL CORE Lehrplan 2018, Abschnitt 2.4.2).\n\nb) FALSCH – Obwohl der Test der migrierten Daten Teil des Wartungstests ist (siehe Konvertierungstest), ermittelt die Auswirkungsanalyse nicht, wie dieser Test auszusehen hat.\n\nc) FALSCH – Die Auswirkungsanalyse ermittelt, welche Teile eines Systems von einer Änderung betroffen sind. Somit kann sie den Unterschied zwischen verschiedenen Hot Fixes in Hinsicht auf die Auswirkungen auf das System aufzeigen. Sie gibt aber keine Hinweise darauf, welchen Nutzen die Änderungen für den Benutzer haben.\n\nd) FALSCH – Die Auswirkungsanalyse ermittelt, welche Teile eines Systems von einer Änderung betroffen sind. Sie kann aber keine Anhaltspunkte zur Effektivität von Testfällen liefern.',
'',2,0],
['Welche der folgenden Aussagen gibt den Nutzen des statischen Tests KORREKT wieder?',
'Nach der Einführung von Reviews stellten wir fest, dass sich sowohl die Qualität der Spezifikationen als auch die für Entwicklung und Test benötigte Zeit erhöht haben.',
'Durch die Anwendung von statischem Test können wir den Test besser steuern und haben ein günstigeres Fehlermanagement, weil sich Fehlerzustände später im Lebenszyklus leichter finden lassen.',
'Da wir jetzt statische Analyse nutzen, haben fehlende Anforderungen abgenommen und die Kommunikation zwischen Testern und Entwicklern hat sich verbessert.',
'Seitdem wir statische Analysen eingeführt haben, finden wir Programmierfehler, die wir allein durch dynamischen Test möglicherweise nicht gefunden hätten.',
4,
'Begründung:\n\na) FALSCH – Reviews sollten die Qualität der Spezifikationen erhöhen, aber die für Entwicklung und Test benötigte Zeit verringern (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.1.2).\n\nb) FALSCH – Die Behebung von Fehlerzuständen ist im Allgemeinen früher im Lebenszyklus leichter (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.1.2).\n\nc) FALSCH – Reviews führen zu weniger fehlenden Anforderungen und besserer Kommunikation zwischen Testern und Entwicklern, aber Letzteres gilt nicht für statische Analysen (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.1.2).\n\nd) KORREKT – Dies ist ein Nutzen der statischen Analyse (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.1.2).',
'',3,0],
['Welche der folgenden Aussagen zur Anwendung von Checklisten bei einem formalen Review ist KORREKT?',
'Im Rahmen der Planung des Reviews erstellen die Reviewer die für das Review benötigten Checklisten.',
'Im Rahmen der Befundkommunikation füllen die Reviewer die für das Review bereitgestellten Checklisten aus.',
'Im Rahmen der Reviewsitzung erstellen die Reviewer auf Basis der für das Review bereitgestellten Checklisten Fehlerberichte.',
'Im Rahmen des Reviewbeginns (Kick-Off) erhalten die Reviewer die für das Review benötigten Checklisten.',
4,
'FL-3.1.2 (K2) Beispiele nennen können, um den Wert des statischen Tests zu beschreiben\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – In der Planung wird entschieden, ob Checklisten eingesetzt werden (vgl. Lehrplan, Abschnitt 3.2.1). Die Erstellung der Checklisten ist nicht Teil der Planung. Außerdem sind die Reviewer weder in die Planung involviert, noch für die Erstellung der Checklisten verantwortlich (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.2).\n\nb) FALSCH – In der Befundkommunikation werden im individuellen Review identifizierte potenzielle Fehlerzustände kommuniziert. Das Ausfüllen von Checklisten durch die Reviewer erfolgt, wenn überhaupt, bereits im individuellen Review (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.1).\n\nc) FALSCH – In der Reviewsitzung kommunizieren die Reviewer die im Rahmen des individuellen Reviews identifizierten potenziellen Fehlerzustände des Arbeitsergebnisses (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.1). Fehlerberichte werden erst in der Aktivität Fehlerbehebung und Bericht erstellt.\n\nd) KORREKT – Der Reviewbeginn (Kick-Off) umfasst das Verteilen des Arbeitsergebnisses und anderer Materialien, wie Checklisten (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.1).',
'',3,0],
['Welche der folgenden Optionen gibt die Rollen und Verantwortlichkeiten in einem formalen Review KORREKT wieder?',
'Management – Entscheidet über die Durchführung von Reviews',
'Reviewleiter – Stellt den erfolgreichen Ablauf von Reviewsitzungen sicher',
'Protokollant – Behebt Fehlerzustände im Arbeitsergebnis, das einem Review unterzogen wurde',
'Moderator – Überwacht die stetige Kosteneffizienz',
1,
'FL-3.2.2 (K1) Die unterschiedlichen Rollen und Verantwortlichkeiten in einem formalen Review erkennen können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Das Management entscheidet über die Durchführung von Reviews (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.2).\n\nb) FALSCH – Der Moderator stellt den erfolgreichen Ablauf von Reviewsitzungen sicher (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.2).\n\nc) FALSCH – Der Autor behebt Fehlerzustände im Arbeitsergebnis, das einem Review unterzogen wurde (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.2).\n\nd) FALSCH – Das Management überwacht die stetige Kosten-Wirksamkeits-Analyse (Siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.2).',
'',3,0],
['Welche der Reviewarten wird hier AM WAHRSCHEINLICHSTEN verwendet?',
'Informelles Review',
'Walkthrough',
'Technisches Review',
'Inspektion',
2,
'FL-3.2.3 (K2) Die Unterschiede zwischen den unterschiedlichen Reviewarten erklären können: informelles Review, Walkthrough, technisches Review und Inspektion\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nGemäß CTFL Lehrplan 2018, Abschnitt 3.2.3, lassen sich die genannten Eigenschaften wie folgt bewerten:\n• Es gibt die Rolle des Protokollanten – kommt bei Walkthrough, technischem Review und Inspektion vor, nicht aber bei informellem Review.\n• Der Zweck ist es, potenzielle Fehlerzustände zu entdecken – dieser Zweck kommt bei allen Reviewarten vor.\n• Die Reviewsitzung wird vom Autor geleitet – dies ist bei Inspektion ausgeschlossen, bei technischem Review untypisch, die Regel bei Walkthrough und erlaubt bei informellem Review.\n• Die Reviewer finden potenzielle Fehlerzustände durch individuelles Review – alle Reviewarten einschließlich informellem Review können individuelles Review einschließen.\n• Es wird ein Reviewbericht erstellt – bei allen Reviewarten kann ein Reviewbericht entstehen, obwohl das bei informellem Review weniger wahrscheinlich ist.\n\nDaraus ergibt sich, dass Option b) am wahrscheinlichsten und damit korrekt ist.',
'https://i.imgur.com/gJmgWgs.png',3,0],
['Welche folgenden Kombinationen weisen Inkonsistenzen zwischen Anforderungspaaren RICHTIG auf?',
'6-10, 6-15, 7-12',
'6-15, 9-11',
'6-10, 6-15, 9-11',
'6-15, 7-12',
2,
'FL-3.2.4 (K3) Ein Reviewverfahren auf ein Arbeitsergebnis anwenden können, um Fehlerzustände zu finden\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nZu betrachten werden die potenziellen Inkonsistenzen:\n\n• 6-10 – Wenn Bibliothekare eine Systemrückmeldung innerhalb von 5 Sekunden erhalten sollen, dann ist das konsistent dazu, dass Nutzer eine Systemrückmeldung innerhalb von 3 Sekunden erhalten sollen.\n\n• 6-15 – Wenn Bibliothekare eine Systemrückmeldung innerhalb von 5 Sekunden erhalten sollen, dann ist das inkonsistent dazu, dass alle Benutzer eine Systemrückmeldung innerhalb von 3 Sekunden erhalten sollen.\n\n• 7-12 – Wenn sich Nutzer maximal 3 Bücher gleichzeitig ausleihen können, dann ist das konsistent dazu, dass sie sich Bücher reservieren können (falls sie ausgeliehen sind).\n\n• 9-11 – Wenn ein Nutzer wegen Nichtrückgabe eines Buches innerhalb von 3 Wochen mit einer Mahngebühr belegt wird, dann ist das inkonsistent dazu, dass Bücher kostenlos für maximal 4 Wochen ausgeliehen werden dürfen. Die zwei Fristen sind unterschiedlich.\n\nFolglich ist Antwort b) korrekt',
'https://i.imgur.com/QHGCdAN.png',3,0],
['Welche der folgenden Aussagen beschreibt AM BESTEN exploratives Testen?',
'Eine Testvorgehensweise/ein Testansatz, bei der eine intensive Untersuchung des Hintergrunds des Testobjekts dazu genutzt wird, mögliche Schwachstellen zu identifizieren, die durch Testfälle untersucht werden.',
'Eine Testvorgehensweise/ein Testansatz, bei dem die Tester, basierend auf ihrem Wissen, der Erkundung des Testelements und dem Ergebnis früherer Tests, dynamisch Tests entwerfen und durchführen.',
'Eine Testvorgehensweise/ein Testansatz, bei dem die Testaktivitäten - insbesondere Testanalyse und Testentwurf - als unterbrechungsfreie Sitzungen geplant werden, oft in Verbindung mit checklisten-basiertem Testen.',
'Eine Testvorgehensweise/ein Testansatz, das auf der Erfahrung, dem Wissen und der Intuition des Testers basiert.',
2,
'Schlüsselbegriff: exploratives Testen\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Exploratives Testen wird meistens bei kurzfristigen Zeitvorgaben durchgeführt, daher sind intensive Untersuchungen des Hintergrunds des Testobjekts eher ungewöhnlich.\n\nb) KORREKT – Ein Testansatz, bei dem die Tests dynamisch entworfen und ausgeführt werden, basierend auf Wissen, der Erkundung des Testelements und den Ergebnissen früherer Tests. (Definition Glossar V.3.3\n\nc) FALSCH – Basiert auf der Definition des Glossars für sitzungsbasiertes Testen, jedoch wurde Testdurchführung durch Testanalyse ersetzt.\n\nd) FALSCH – Basiert auf der Definition des Glossars für erfahrungsbasiertes Testen.',
'',0,0],
['Welche der Zuordnungen von Beschreibungen zu verschiedenen Kategorien von Testverfahren trifft AM BESTEN zu?',
'Black – 4, 5; White – 1, 2; Erfahrung – 3',
'Black – 3; White – 1, 2; Erfahrung – 4, 5',
'Black – 4; White – 1, 2; Erfahrung – 3, 5',
'Black – 1, 3, 5; White – 2; Erfahrung – 4',
1,
'FL-4.1.1 (K2) Die Eigenschaften, Gemeinsamkeiten und Unterschiede zwischen Black-Box-Testverfahren, White-Box-Testverfahren und erfahrungsbasierten Testverfahren erklären können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nDie korrekte Verknüpfung der Beschreibungen zu den verschiedenen Kategorien von Testverfahren entsprechend des Syllabus (4.1.1) ist:\n- Black-Box-Testverfahren:\nAbweichungen von Anforderungen werden überprüft (4)\nUser-Stories werden als Testbasis herangezogen (5)\n\n- White-Box-Testverfahren:\nÜberdeckung wird auf Basis einer ausgewählten Struktur des Testobjektes gemessen (1)Verarbeitung innerhalb des Testobjekts wird überprüft (2)\n\n- erfahrungsbasiertes Testverfahren:\nTests basieren auf der Wahrscheinlichkeit von Fehlerzuständen und deren Verteilung (3)\n\nFolglich ist Antwort a) korrekt',
'https://i.imgur.com/9VuW2xl.png',4,0],
['Welche der Gruppen von Testeingabewerten würde für die BESTE Überdeckung von Äquivalenzklassen sorgen?',
'0, 1000, 2000, 3000, 4000',
'1000, 2001, 4000, 4001, 6000',
'123, 2345, 3456, 4567, 5678',
'666, 999, 2222, 5555, 6666',
4,
'FL-4.2.1 (K3) Die Äquivalenzklassenbildung anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nDie folgenden gültigen Äquivalenzklassen können gebildet werden:\n1) ≤ 1000 - Couch Potato!\n2) 1001 - 2000 - Faulpelz!\n3) 2001 - 4000 - Die Richtung stimmt!\n4) 4001 - 6000 - Nicht schlecht!\n5) > 6000 - Super!\n\nDie Gruppen von Testeingabewerten decken daher folgende Klassen ab:\na) 0 (1), 1000 (1), 2000 (2), 3000 (3), 4000 (3) – 3 Klassen (von 5).\n\nb) 1000 (1), 2001 (3), 4000 (3), 4001 (4), 6000 (4) – 3 Klassen (von 5).\n\nc) 123 (1), 2345 (3), 3456 (3), 4567 (4), 5678 (4) – 3 Klassen (von 5).\n\nd) 666 (1), 999 (1), 2222 (3), 5555 (4), 6666 (5) – 4 Klassen (von 5)\n\nFolglich ist Option d) richtig',
'https://i.imgur.com/LnooTFt.png',4,0],
['Wie viele Testfälle müssen mindestens zusätzlich zu den dargestellten erzeugt werden, um eine vollständige Überdeckung ALLER GÜLTIGEN Eingabe-Äquivalenzklassen zu gewährleisten?',
'1',
'2',
'3',
'4',
2,
'FL-4.2.1 (K3) Die Äquivalenzklassenbildung anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nDie folgenden Äquivalenzklassen können identifiziert werden:\n\n• Dauer\n1. Unter 3 Stunden\n2. 3 – 6 Stunden\n3. Über 6 Stunden\n\n• Intensität\n4. sehr niedrig\n5. niedrig\n6. mittel\n7. hoch\n\nDie existierenden Testfälle decken die folgenden gültigen Eingabe- Äquivalenzklassen ab:\n\nT1 1,5 (1) sehr niedrig (4)\nT2 7,0 (3) mittel (6)\nT3 0,5 (1) sehr niedrig (4)\n\nFolglich sind die fehlenden gültigen Eingabe- Äquivalenzklassen (2), (5) und (7).\n\nSie können mit zwei zusätzlichen Testfällen abgedeckt werden, da (2) sowohl mit (5) als auch mit (7) kombiniert werden kann.\n\nFolglich ist Antwort b) richtig',
'https://i.imgur.com/Rnrl6rH.png',4,0],
['Welches der Testsets liefert die höchste Überdeckung von Grenzwerten, wenn die Grenzwertanalyse ausschließlich unter Verwendung der Minimal- und Maximalwerte verwendet wird?',
'0°C, 11°C, 20°C, 22°C, 23°C',
'9°C, 15°C, 19°C, 23°C, 100°C',
'10°C, 16°C, 19°C, 22°C, 23°C',
'14°C, 15°C, 18°C, 19°C, 21°C, 22°C',
3,
'FL-4.2.2 (K3) Die Grenzwertanalyse anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nBei den angegebenen Eingabe-Äquivalenzklassen ergibt das Zwei-Punkt-Grenzwertverfahren folgende 8 Überdeckungselemente:\n\n10°C, 11°C, 15°C, 16°C, 19°C, 20°C, 22°C, 23°C.\n\nDie Überdeckung durch die Optionen ist folglich jeweils:\na) 4 von 8 (11, 20 ,22 und 23).\n\nb) 3 von 8 (15, 19 und 23).\n\nc) 5 von 8 (10, 16, 19, 22 und 23).\n\nd) 3 von 8 (15, 19 und 22)\n\nFolglich ist Option c) richtig',
'https://i.imgur.com/qs7f8Rq.png',4,0],
['Welche zwei der zusätzlichen Testfälle würden eine 100% Überdeckung der gesamten Entscheidungstabelle erreichen (in Kombination mit den Testfällen TF1 und TF2)?',
'TF3, TF4',
'TF4, TF5',
'TF4, TF6',
'TF5, TF6',
3,
'FL-4.2.3 (K3) Entscheidungstabellentests anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\nDie zusätzlichen Testfälle überdecken jeweils die folgenden Regeln:\n\nTestfall TF3 TF4 TF5 TF6\nüberdeckte Regel R1 R3 R1 R2\n\nUm 100% Überdeckung zu erreichen, sind Testfälle erforderlich, die die Regeln R2 und R3 überdecken. Daher ist Option c) korrekt:\n\na) FALSCH – Regel R2 ist nicht überdeckt.\n\nb) FALSCH – Regel R2 ist nicht überdeckt.\n\nc) KORREKT – R1, R2, R3 und R4 sind jeweils durch TF1, TF6, TF4 bzw. TF2 überdeckt.\n\nd) FALSCH – Regel R3 ist nicht überdeckt.',
'https://i.imgur.com/Hie7xxq.png',4,0],
['Welche der Zustandsübergangs-Sequenzen ergibt die höchste Überdeckung der Zustandsübergänge?',
'Aus → Warten → Aus → Warten → Erhaltungsladen → Laden → Hoch → Laden → Niedrig',
'Warten → Erhaltungsladen → Warten → Aus → Warten → Erhaltungsladen → Laden → Niedrig → Laden',
'Hoch → Laden → Niedrig → Laden → Erhaltungsladen → Warten → Erhaltungsladen → Warten → Erhaltungsladen',
'Warten → Erhaltungsladen → Laden → Hoch → Laden → Erhaltungsladen → Warten → Aus → Warten',
4,
'FL-4.2.4 (K3) Zustandsübergangstests anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nIm folgenden Zustandsdiagramm sind die Zustandsübergänge nummeriert:\n\nDie Sequenzen in den Antwortoptionen erreichen folgende Überdeckung der Zustandsübergänge:\n\na) FALSCH – Aus → (1) Warten → (2) Aus → (1) Warten → (3) Erhaltungsladen → (5) Laden → (9) Hoch → (10) Laden → (7) Niedrig. Das sind 7/10=70%.\n\nb) FALSCH – Warten → (3) Erhaltungsladen → (4) Warten → (2) Aus → (1) Warten → (3) Erhaltungsladen → (5) Laden → (7) Niedrig → (8) Laden. Das sind 7/10=70%.\n\nc) FALSCH – Hoch → (10) Laden → (7) Niedrig → (8) Laden → (6) Erhaltungsladen → (4) Warten → (3) Erhaltungsladen → (4) Warten → (3) Erhaltungsladen. Das sind 6/10=60%.\n\nd) KORREKT – Warten → (3) Erhaltungsladen → (5) Laden → (9) Hoch → (10) Laden → (6) Erhaltungsladen → (4) Warten → (2) Aus → (1) Warten. Das sind 8/10=80%.\n\nAntwortoption d) erreicht mit 80% die höchste Überdeckung der Zustandsübergänge.',
'https://i.imgur.com/7qvsm1n.png',4,0],
['Welche der folgenden Aussagen beschreibt AM BESTEN, wie Testfälle aus Anwendungsfällen entworfen werden?',
'Testfälle werden entworfen, um das im Anwendungsfall definierte grundlegende, Sonder- und Fehlerbehandlungs-Verhalten des Systems in Interaktion mit den Akteuren auszuführen.',
'Testfälle werden entworfen, indem die vom Anwendungsfall betroffenen Komponenten identifiziert und Integrationstests erstellt werden, welche die Interaktionen dieser Komponenten ausführen.',
'Testfälle werden entworfen, indem die Interaktionen der Akteure mit dem System analysiert werden, um sicherzustellen, dass die Benutzungsschnittstelle des Systems leicht bedienbar ist.',
'Testfälle werden entworfen, mit denen alle Entscheidungspunkte im Geschäftsprozess des Anwendungsfalls ausgeführt werden, um eine 100%-ige Entscheidungsüberdeckung zu erreichen.',
1,
'FL-4.2.5 (K2) Erklären können, wie man Testfälle aus einem Anwendungsfall ableitet\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Im Lehrplan unter 4.2.5 Anwendungsfallbasierter Test steht: Jeder Anwendungsfall definiert ein bestimmtes Verhalten, das ein Objekt in Zusammenarbeit mit einem oder mehreren Akteuren ausführen kann. Weiter unten ist zu lesen: Ein Anwendungsfall besteht aus mehreren möglichen Varianten seines grundlegenden Verhaltens, was u. a. Sonder- und Fehlerbehandlungen einschließt (Antwort- und Wiederherstellungsmechanismen des Systems nach Programmier-, Anwendungs- und Kommunikationsfehler, die z. B. zu Fehlermeldungen führen). Tests werden entworfen, um das definierte Verhalten nachzuweisen (grundlegendes, außergewöhnliches oder alternatives Verhalten und die Fehlerbehandlungsroutinen).\n\nb) FALSCH – Anwendungsfälle spezifizieren normalerweise Anforderungen und schließen daher nicht die Komponenten ein, die sie implementieren.\n\nc) FALSCH – Anwendungsfallbasierte Tests führen zwar Interaktionen des Systems mit einem oder mehreren Akteuren aus. Aber sie konzentrieren sich auf die Funktionalität und betrachten nicht die leichte Bedienbarkeit der Benutzungsschnittstelle.\n\nd) FALSCH – Tests decken zwar die Ablaufpfade des Anwendungsfalls ab, es geht jedoch nicht um eine Entscheidungsüberdeckung in diesen Pfaden, und bestimmt nicht in den Kontrollfluss im Geschäftsprozess.',
'',4,0],
['Welche der folgenden Beschreibungen der Anweisungsüberdeckung ist korrekt?',
'Die Anweisungsüberdeckung ist ein Maß für die Anzahl der Quellcodezeilen (ohne Kommentare), die im Test ausgeführt wurden.',
'Die Anweisungsüberdeckung ist ein Maß für den prozentualen Anteil der ausführbaren Anweisungen im Quellcode, die im Test ausgeführt wurden.',
'Die Anweisungsüberdeckung ist ein Maß für den prozentualen Anteil der Quellcodezeilen (ohne Kommentare), die im Test ausgeführt wurden.',
'Die Anweisungsüberdeckung ist ein Maß für die Anzahl der ausführbaren Anweisungen im Quellcode, die im Test ausgeführt wurden.',
2,
'FL-4.3.1 (K2) Anweisungsüberdeckung erklären können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nGlossareintrag Anweisungsüberdeckung: Der Anteil der Anweisungen, die durch eine Testsuite ausgeführt wurden, bezogen auf alle Anweisungen.\n\nFL Lehrplan 4.3.1: Anweisungstests untersuchen die (potenziell) ausführbaren Anweisungen im Code. Die Überdeckung wird an der Anzahl der im Test ausgeführten Anweisungen dividiert durch die Gesamtzahl aller ausführbaren Anweisungen insgesamt im Testobjekt gemessen – üblicherweise als Prozentsatz dargestellt\n\nb) KORREKT – Der prozentuale Anteil der ausführbaren Anweisungen ist der Anteil im Test ausgeführter Anweisungen bezogen auf alle Anweisungen, also (Anzahl durch die Testsuite ausgeführter Anweisungen / Anzahl alle Anweisungen) x 100%.\n\na) FALSCH – Die Anweisungsüberdeckung bezieht sich auf durch Tests ausführbare Anweisungen. In einer Zeile können mehrere solcher Anweisungen stehen, und eine Anweisung kann sich über mehrere Zeilen erstrecken.\n\nc) FALSCH – Die Anweisungsüberdeckung bezieht sich nicht auf Quellcodezeilen, sondern auf durch Tests ausführbare Anweisungen, s. Begründung zu a).\n\nd) FALSCH – Die Anweisungsüberdeckung bezieht sich nicht auf die absolute Anzahl der von der Testsuite ausgeführten Anweisungen, sondern auf deren Anteil bezogen auf alle ausführbaren Anweisungen.',
'',4,0],
['Welche der folgenden Beschreibungen der Entscheidungsüberdeckung ist zutreffend?',
'Die Entscheidungsüberdeckung ist ein Maß für den prozentualen Anteil möglicher Pfade durch den Quellcode, die im Test ausgeführt wurden.',
'Die Entscheidungsüberdeckung ist ein Maß für den prozentualen Anteil der Geschäftsabläufe durch die Komponente, die im Test ausgeführt wurden.',
'Die Entscheidungsüberdeckung ist ein Maß für die „IF-Anweisungen“ im Quellcode, die im Test sowohl mit dem Ergebnis „WAHR“ als auch mit „FALSCH“ ausgeführt wurden.',
'Die Entscheidungsüberdeckung ist ein Maß für den Anteil der Entscheidungsergebnisse, die im Test ausgeführt wurden.',
4,
'FL-4.3.2 (K2) Entscheidungsüberdeckung erklären können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nLehrplan 4.3.2: Der Überdeckungsgrad wird gemessen anhand der Anzahl der Entscheidungsergebnisse, die durch die Tests ausgeführt werden, dividiert durch die Gesamtzahl an möglichen Entscheidungsergebnissen im Testobjekt – üblicherweise als Prozentsatz dargestellt.\n\na) FALSCH – Ein Pfad durch den Quellcode ist ein möglicher Ablauf durch den Quellcode vom Eintrittspunkt zum Austrittspunkt, der eine Reihe von Entscheidungsergebnissen ausführen kann. Zwei verschiedene Pfade können bis auf einen die gleichen Entscheidungsergebnisse ausführen. Wird nur ein einziges Entscheidungsergebnis geändert, so wird ein anderer Pfad durchlaufen. Testfälle, die eine vollständige Entscheidungsabdeckung erzielen, sind in der Regel eine winzige Teilmenge der Testfälle, die eine vollständige Pfadüberdeckung erzielen würden. In der Praxis haben die meisten nicht-trivialen Programme (und alle Programme mit unbeschränkten Schleifen, z. B. \'while\'-Schleifen) eine potenziell unendliche Anzahl möglicher Pfade, sodass die Messung des abgedeckten Prozentsatzes praktisch unmöglich ist.\n\nb) FALSCH – Geschäftsabläufe können im anwendungsfallbasierten Test betrachtet werden. Sie werden jedoch nicht durch die Entscheidungsüberdeckung gemessen, auch wenn sie ein oder mehrere Entscheidungsergebnisse ausführen würden.\n\nc) FALSCH – „IF-Anweisungen“ beinhalten zwar Entscheidungen, sind jedoch nicht die einzige Quelle für Entscheidungen, da z. B. auch Schleifen oder „CASE-Anweisungen“ Entscheidungen beinhalten, aufgrund deren Ergebnis sie ausgeführt oder nicht ausgeführt werden.\n\nd) KORREKT – S. Lehrplan-Auszug 4.3.2 oben',
'',4,0],
['Welche der folgenden Optionen beschreibt AM BESTEN das Konzept der intuitiven Testfallermittlung?',
'Die intuitive Testfallermittlung erfordert, dass Sie sich vorstellen, der Benutzer des Testobjekts zu sein, und dass Sie Fehler erraten, die der Benutzer bei der Interaktion damit machen könnte.',
'Die intuitive Testfallermittlung bezieht Ihre persönlichen Entwicklungserfahrungen und die Fehler mit ein, die Sie als Entwickler gemacht haben.',
'Die intuitive Testfallermittlung verwendet Ihre Kenntnisse und Erfahrungen mit Fehlerzuständen, die in der Vergangenheit gefunden wurden, sowie mit typischen Fehlhandlungen von Entwicklern.',
'Die intuitive Testfallermittlung erfordert, dass Sie die Entwicklungsaufgabe schnell selbst wiederholen, um die Art von Fehlern zu identifizieren, die Entwickler dabei möglicherweise machen könnten.',
3,
'FL-4.4.1 (K2) Die intuitive Testfallermittlung erklären können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nLehrplan 4.4.1: Intuitive Testfallermittlung ist ein Verfahren, das das Auftreten von Fehlhandlungen, Fehlerzuständen und Fehlerwirkungen aufgrund des Wissens des Testers vermutet […,1,0]\n\na) FALSCH – Die intuitive Testfallermittlung ist kein Gebrauchstauglichkeitstestverfahren, um zu erraten, wie die Interaktion der Benutzer mit dem Testobjekt möglicherweise fehlschlagen könnte.\n\nb) FALSCH – Obwohl Tester, die früher Entwickler waren, ihre persönliche Erfahrung nutzen können, um Fehler zu erraten, basiert das Verfahren nicht auf Vorkenntnissen über die Entwicklung.\n\nc) KORREKT – Siehe Lehrplanexzerpt oben, Fehlhandlungen sind u. a. Fehler von Entwicklern. Das Grundkonzept der intuitiven Testfallermittlung ist, dass Tester anhand von Erfahrungswerten (und manchmal auch Checklisten) erraten, welche Fehler die Entwickler möglicherweise gemacht haben könnten und welche Fehlerzustände im Testobjekt vorliegen könnten.\n\nd) FALSCH – Das Wiederholen der Entwicklungsaufgabe ist keine intuitive Testfallermittlung. Es wäre darüber hinaus aufgrund mehrerer Probleme nicht praktikabel, z. B. der Anforderung, dass Tester über die gleichen Fähigkeiten wie Entwickler verfügen, und dem zeitlichen Aufwand für eine wiederholte Durchführung der Entwicklung.',
'',4,0],
['Welche der folgenden Aussagen beschreibt am BESTEN einen Vorteil von unabhängigem Testen?',
'Die Verwendung eines unabhängigen Testteams erlaubt dem Projektmanagement die Verantwortung für die Qualität des finalen Arbeitsergebnisses auf das Testteam zu übertragen. Somit ist jedem bewusst, dass die Qualität in der Gesamtverantwortung des Testteams liegt.',
'Wenn ein Testteam außerhalb der Organisation zur Verfügung gestellt werden kann, hat dies deutliche Vorteile, da dieses externe Team nicht so leicht von den Bedenken des Projektmanagements und der Notwendigkeit der Einhaltung strenger Lieferfristen beeinflusst wird.',
'Ein unabhängiges Testteam kann vollkommen separat von den Entwicklern arbeiten, muss sich nicht von sich ändernden Projektanforderungen ablenken lassen und kann die Kommunikation mit den Entwicklern auf das Verfassen von Fehlerberichten über das Fehlermanagementsystem beschränken.',
'Wenn Spezifikationen Mehrdeutigkeiten und/oder Inkonsistenzen enthalten, werden Annahmen zu deren Interpretation getroffen. Ein unabhängiger Tester kann hilfreich sein, um die vom Entwickler getroffenen Annahmen und vorgenommenen Interpretationen in Frage zu stellen.',
4,
'FL-5.1.1 (K2) Vor- und Nachteile unabhängigen Testens erklären können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Qualität sollte in der Verantwortung aller am Projekt Beteiligten liegen und nicht in der alleinigen Verantwortung des Testteams (siehe CTFL Lehrplan 2018, Abschnitt 5.1.1, „Mögliche Nachteile von Testunabhängigkeit …“, 2. Punkt).\n\nb) FALSCH – Zum einen ist es kein Vorteil, wenn ein externes Testteam die Lieferfristen nicht einhält, und zum anderen gibt es keinen Grund zu der Annahme, dass externe Testteams das Gefühl haben, die strengen Lieferfristen nicht einhalten zu müssen (siehe CTFL Lehrplan 2018, Abschnitt 5.1.1, „Mögliche Nachteile von Testunabhängigkeit …“, 3. Punkt).\n\nc) FALSCH – Es ist eine schlechte Praxis für das Testteam, völlig isoliert zu arbeiten, und außerdem sollte sich auch ein externes Testteam mit sich ändernden Projektanforderungen befassen und gut mit den Entwicklern kommunizieren (siehe CTFL Lehrplan 2018, Abschnitt 5.1.1, „Mögliche Nachteile von Testunabhängigkeit …“, 1. Punkt).\n\nd) KORREKT – Spezifikationen sind niemals perfekt, was bedeutet, dass Annahmen vom Entwickler getroffen werden müssen. Ein unabhängiger Tester ist nützlich, um die Annahme in Frage zu stellen und zu überprüfen (siehe CTFL Lehrplan 2018, Abschnitt5.1.1, „Mögliche Vorteile von Testunabhängigkeit…“, 2.Punkt)',
'',5,0],
['Welche der folgenden Aufgaben wird AM WAHRSCHEINLICHSTEN vom Testmanager ausgeführt?',
'Erstellen von Testabschlussberichten auf der Grundlage der während des Tests gesammelten Informationen.',
'Tests prüfen, die von anderen entwickelt wurden.',
'Testdaten vorbereiten und beschaffen.',
'Anforderungen, Spezifikationen und Modelle auf Testbarkeit analysieren, prüfen und beurteilen.',
1,
'FL-5.1.2 (K1) Die Aufgaben eines Testmanagers und eines Testers benennen können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Eine der typischen Aufgaben eines Testmanagers gemäß CTFL Lehrplan 2018, Abschnitt 5.1.2.\n\nb) FALSCH – Eine der typischen Aufgaben eines Testers gemäß CTFL Lehrplan 2018, Abschnitt 5.1.2.\n\nc) FALSCH – Eine der typischen Aufgaben eines Testers gemäß CTFL Lehrplan 2018, Abschnitt 5.1.2.\n\nd) FALSCH – Eine der typischen Aufgaben eines Testers gemäß CTFL Lehrplan 2018, Abschnitt 5.1.2.',
'',5,0],
['Welche der Kombinationen kategorisiert sie AM BESTEN als Eingangs- und Endekriterien?',
'Eingangskriterien – 5, 6; Endekriterien – 1, 2, 3, 4',
'Eingangskriterien – 2, 3, 6; Endekriterien – 1, 4, 5',
'Eingangskriterien – 1, 3; Endekriterien – 2, 4, 5, 6',
'Eingangskriterien – 3, 5, 6; Endekriterien – 1, 2, 4',
4,
'FL-5.2.3 (K2) Beispiele für mögliche Eingangs- und Endekriterien geben können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nDie korrekte Zuordnung von Beispielen für Eingangs- und Endekriterien sind:\n• Eingangskriterien:\n\n- (3) Die Testumgebung für den Performanz-Test wurde entworfen, eingerichtet und verifiziert - ein Beispiel dafür, dass eine Testumgebung bereit sein muss, bevor mit dem Testen begonnen werden kann.\n\n- (5) Die Designspezifikationen für den Autopiloten wurden einem Review unterzogen und nachgebessert – ein Beispiel dafür, dass die Testbasis zur Verfügung stehen muss, bevor mit dem Testen begonnen werden kann.\n\n- (6) Die Komponente für die Berechnung des Steuersatzes hat die Unit-Tests bestanden ein Beispiel für die Notwendigkeit, dass ein Testobjekt die Endekriterien einer vorangegangenen Teststufe erfüllen muss, bevor mit dem Testen begonnen werden kann.\n\n• Endekriterien:\n\n- (1) Das ursprüngliche Testbudget von 30.000 US-Dollar plus eine Sicherheitsreserve von 7.000 US-Dollar wurde ausgegeben – ein Beispiel dafür, dass ein vollständig ausgeschöpftes Testbudget ein Signal ist, das Testen zu beenden.\n\n- (2) 96% der geplanten Tests für das Zeichenpaket wurden ausgeführt und die verbleibenden Tests sind jetzt nicht mehr Bestandteil des Testumfangs - ein Beispiel dafür, dass die Durchführung aller geplanten Tests ein Signal ist, das Testen zu beenden (normalerweise zusammen mit den Endekriterien für ungelöste Fehlerzustände verwendet).\n\n- (4) Derzeit gibt es keine kritischen Fehlerzustände und zwei Fehlerzustände mit hoher Priorität. – ein Beispiel für die Anzahl ungelöster Fehlerzustände, die eine geplante Grenze erreichen, welche die Beendigung des Testens signalisiert (normalerweise zusammen mit den Endekriterien für geplante Tests verwendet).\n\nSomit ist Option d) korrekt.',
'https://i.imgur.com/7We3en3.png',5,0],
['Welcher Testausführungsplan berücksichtigt AM BESTEN die Prioritäten sowie technische und logische Abhängigkeiten?',
'TF1 – TF3 – TF4 – TF6 – TF2 – TF5',
'TF4 – TF3 – TF1 – TF2 – TF5 – TF6',
'TF4 – TF1 – TF3 – TF5 – TF6 – TF2',
'TF4 – TF2 – TF5 – TF1 – TF3 – TF6',
2,
'FL-5.2.4 (K3) Wissen über Priorisierung sowie technische und logische Abhängigkeiten anwenden können, um die Testdurchführung für ein gegebenes Testfallset zu planen\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nDie Testfälle sollten in der Reihenfolge der Priorität ausgeführt werden, aber der Ausführungsplan muss auch die Abhängigkeiten berücksichtigen.\n\nDie zwei Testfälle mit der höchsten Priorität (TF1 und TF3) sind beide abhängig von TF4, daher sollten die ersten drei Testfälle entweder in der Reihenfolge TF4 – TF1 – TF3 oder in der Reihenfolge TF4 – TF3 –TF1 ausgeführt werden (Wir haben keine Möglichkeit, zwischen TF1 und TF3 zu unterscheiden).\n\nAls nächstes müssen wir den verbleibenden Testfall mittlerer Priorität TF6 betrachten. TF6 ist abhängig von TF5, aber TF5 ist abhängig von TF2, daher müssen die nächsten drei Testfälle in folgender Reihenfolge ausgeführt werden: TF2 – TF5 – TF6.\nDas bedeutet, es gibt zwei optimale Ausführungspläne:\n• TF4 – TF1 – TF3 – TF2 – TF5 – TF6 oder\n• TF4 – TF3 – TF1 – TF2 – TF5 – TF6\n\nSomit ist Option b) korrekt',
'https://i.imgur.com/wBIZH2y.png',5,0],
['Welche der folgenden Aussagen über Testschätzverfahren ist korrekt?',
'Beim metrikbasierten Verfahren basiert die Schätzung auf Testmaßnahmen aus dem Projekt, so dass diese Schätzung erst nach Beginn des Tests verfügbar ist.',
'Beim expertenbasierten Verfahren empfiehlt eine vom Kunden identifizierte Gruppe von Experten das erforderliche Testbudget.',
'Beim expertenbasierten Verfahren schätzen die für die verschiedenen Testaktivitäten verantwortlichen Testmanager den erwarteten Testaufwand.',
'Beim metrikbasierten Ansatz wird ein Durchschnitt der Testkosten, die aus mehreren vergangenen Projekten ermittelt wurden, als Testbudget verwendet.',
3,
'FL-5.2.6 (K2) Den Unterschied zwischen zwei Schätzverfahren erklären können: das metrikbasierte Verfahren und das expertenbasierte Verfahren\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Die Schätzungen werden möglicherweise aktualisiert, sobald weitere Informationen verfügbar sind. Es sind jedoch Schätzungen erforderlich, um die Planung vor Beginn der Tests zu unterstützen.\n\nb) FALSCH – Die Experten beim expertenbasierten Verfahren müssen Experten für das Testen sein und nicht für das Testobjekt.\n\nc) KORREKT – Beim expertenbasierten Ansatz werden die für die verschiedenen Testaktivitäten verantwortlichen Testmanager als Experten für ihr jeweiliges Gebiet betrachtet. Daher sind sie in der Lage, den erwarteten Testaufwand zu schätzen.\n\nd) FALSCH – Es ist zwar nützlich, die Testkosten aus früheren Projekten zu kennen, jedoch ist ein anspruchsvollerer Ansatz erforderlich, als nur den Durchschnitt vergangener Projekte zu ermitteln. (Das neue Projekt kann möglicherweise nicht mit den vergangenen Projekten vergleichbar sein, z. B. kann es viel größer oder viel kleiner sein als die vergangenen Projekte).',
'',5,0],
['Welche der folgenden Aussagen definiert AM BESTEN die Risikostufe (Höhe des Risikos)?',
'Die Risikostufe wird berechnet, indem die Wahrscheinlichkeiten aller Problemsituationen und der daraus resultierende finanzielle Schaden addiert werden.',
'Die Risikostufe wird geschätzt, indem die Wahrscheinlichkeit einer Bedrohung des Systems multipliziert wird mit der Wahrscheinlichkeit, dass die Bedrohung auftritt und finanzielle Schäden verursacht.',
'Die Risikostufe wird bestimmt durch eine Kombination der Wahrscheinlichkeit eines unerwünschten Ereignisses und der erwarteten Auswirkung dieses Ereignisses.',
'Die Risikostufe ist die Summe aller potenziellen Gefahren für ein System multipliziert mit der Summe aller potenziellen Verluste aus diesem System.',
3,
'FL-5.5.1 (K1) Risikostufe anhand der Wahrscheinlichkeit (des Eintritts) und Auswirkung (im Schadensfall) definieren können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Die Risikostufe wird bestimmt, indem eine Kombination aus der Wahrscheinlichkeit von Problemsituationen und dem daraus resultierenden Schaden betrachtet wird; die Risikostufe kann jedoch nicht durch Addition dieser Faktoren berechnet werden (die Wahrscheinlichkeit würde im Bereich von 0 bis 1 liegen und der Schaden könnte in Euro beziffert sein).\n\nb) FALSCH – Das Risiko wird bestimmt, indem eine Kombination aus Wahrscheinlichkeit und Auswirkung berücksichtigt wird. Diese Definition berücksichtigt nur Wahrscheinlichkeit und Zufall ohne Berücksichtigung der Auswirkungen (oder des Schadens).\n\nc) KORREKT – Wie beschrieben im CTFL Lehrplan 2018, Abschnitt 5.5.1\n\nd) FALSCH – Das Risiko wird bestimmt, indem eine Kombination aus Wahrscheinlichkeit und Auswirkung berücksichtigt wird. Diese Definition berücksichtigt nur Gefahren und Verluste (eine Gefahr ist ein schlechtes Ereignis wie ein Risiko, während ein Verlust eine Form der Auswirkung ist), ohne die Wahrscheinlichkeit zuberücksichtigen.',
'',5,0],
['Welcher der folgenden Aussagen ist AM EHESTEN ein Beispiel für ein Produktrisiko?',
'Die erwarteten IT-Sicherheitsmerkmale werden von der Systemarchitektur möglicherweise nicht unterstützt.',
'Die Entwickler haben möglicherweise nicht die Zeit, alle vom Testteam gefundenen Fehler zu beheben.',
'Die Testfälle decken die spezifizierten Anforderungen möglicherweise nicht vollständig ab.',
'Die Umgebung für den Performanztest ist möglicherweise nicht einsatzbereit, bevor das System zur Auslieferung ansteht.',
1,
'FL-5.5.2 (K2) Zwischen Projekt- und Produktrisiken unterscheiden können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Werden die erwarteten IT-Sicherheitsmerkmale von der Systemarchitektur nicht unterstützt, kann das System schwerwiegende Fehler aufweisen. Da hier das zu produzierende System das Problem ist, handelt es sich um ein Produktrisiko.\n\nb) FALSCH – Wenn die Entwickler das Budget überschreiten oder die Zeit knapp wird, ist das ein Problem mit dem Projektablauf - es ist ein Projektrisiko.\n\nc) FALSCH – Wenn die Testfälle die Anforderungen nicht vollständig überdecken, bedeutet dies, dass die Prüfung möglicherweise nicht die Anforderungen des Testkonzepts erfüllt -es ist ein Projektrisiko.\n\nd) FALSCH – Wenn die Testumgebung nicht einsatzbereit ist, bedeutet dies, dass der Test möglicherweise nicht durchgeführt werden kann, oder dass er auf einer anderen Umgebung durchgeführt werden muss, und dass er sich auf die Durchführung des Projekts auswirkt - es ist ein Projektrisiko.',
'',5,0],
['Welche der folgenden Aussagen zum Zusammenhang von Produktrisiko und Testmanagement ist am wenigsten sinnvoll?',
'Die potenziellen Auswirkungen von IT-Sicherheitsmängeln wurden als besonders hoch eingestuft, so dass IT-Sicherheitstests vor einigen anderen Testaktivitäten priorisiert wurden.',
'Die Tests haben ergeben, dass die Qualität des Netzwerkmoduls besser ist als erwartet, so dass nun zusätzliche Tests in diesem Bereich durchgeführt werden.',
'Die Benutzer hatten Probleme mit der Benutzeroberfläche des bisherigen Systems, so dass zusätzliche Usability-Tests für das Ersatzsystem geplant sind.',
'Die Zeit, die zum Laden von Webseiten benötigt wird, ist entscheidend für den Erfolg der neuen Website, weshalb für dieses Projekt ein Experte für Leistungstests eingesetzt wurde.',
2,
'FL-5.5.3 (K2) Anhand von Beispielen beschreiben können, wie die Produktrisikoanalyse Intensität und Umfang des Testens beeinflussen kann\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Da uns gesagt wird, dass Sicherheitsmängel eine besonders hohe Auswirkung haben, wird ihr Risiko höher sein. Deshalb wurde der Sicherheitstest vor einigen anderen Tests priorisiert. Der Einfluss der Produktrisikoanalyse auf den Test wurde somit KORREKT eingeschätzt.\n\nb) KORREKT – Da im Netzwerkmodul weniger Fehler als erwartet festgestellt wurden, sollte das wahrgenommene Risiko in diesem Bereich geringer sein, und daher sollten sich WENIGER Tests auf diesen Bereich konzentrieren und NICHT zusätzliche Tests. Daher hat die Produktrisikoanalyse den Test in dieser Situation NICHT KORREKT beeinflusst.\n\nc) FALSCH – Da die Anwender Probleme mit der Benutzeroberfläche des bisherigen Systems hatten, ist das Risiko der Benutzeroberfläche inzwischen sehr hoch, was dazu geführt hat, dass weitere Usability-Tests geplant sind. Der Einfluss der Produktrisikoanalyse auf den Test wurde somit KORREKT eingeschätzt. Daher hat die Produktrisikoanalyse den Umfang der Tests RICHTIG beeinflusst.\n\nd) FALSCH – Da die Zeit, die zum Laden von Webseiten benötigt wird, als entscheidend für den Erfolg der neuen Website eingestuft wurde, sollte die Leistung der Website als Risiko angesehen werden, und die Beschäftigung eines Experten für Leistungstests hilft, dieses Risiko zu minimieren. Somit hat die Produktrisikoanalyse den Test RICHTIG beeinflusst.',
'',5,0],
['Welche der dargestellten Informationen sind AM SINNVOLLSTEN in den Fehlerbericht mit aufzunehmen?',
'1, 2, 6',
'1, 4, 5, 6',
'2, 3, 4, 5',
'3, 5, 6',
4,
'FL-5.6.1 (K3) Einen Fehlerbericht schreiben können, der während des Testens gefundene Fehler enthält\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\n1. Grad der Auswirkung (Schwere) des Fehlerzustands - die Entwickler sind sich des Problems bereits bewusst und warten darauf, es zu beheben, daher ist dies eine weniger wichtige Information.\n\n2. Identifizierung des Testelements - da die Entwickler das Problem bereits kennen und SieSystemtests durchführen und Sie bereits die Version des zu testenden Systems zur Verfügung gestellt haben, können Sie davon ausgehen, dass die Entwickler das zu testende Element kennen, daher ist dies eine weniger wichtige Information.\n\n3. Details der Testumgebung - der Aufbau der Testumgebung kann einen spürbaren Einfluss auf die Testergebnisse haben, und es sollten detaillierte Informationen dazu bereitgestellt werden, daher ist dies eine wichtige Information.\n\n4. Dringlichkeit/Priorität für die Behebung- die Entwickler sind sich des Problems bereits bewusst und warten darauf, es zu beheben, daher ist dies eine weniger wichtige Information.\n\n5. Istergebnisse - die Istergebnisse können den Entwicklern gut helfen, festzustellen, was mit dem System schiefläuft, daher ist dies eine wichtige Information.\n\n6. Referenz auf die Testfallspezifikation - dies zeigt den Entwicklern die von Ihnen ausgeführten Tests, einschließlich der Testeingaben, die zum Ausfall des Systems führten (und der erwarteten Ergebnisse), so dass dies eine wichtige Information ist.\n\nOption d) ist korrekt',
'https://i.imgur.com/0JBO1zB.png',5,0],
['Welche der Kombinationen passt am besten zu den aufgelisteten Aktivitäten und Tools?',
'1 – B, 2 – C, 3 – D, 4 – A',
'1 – B, 2 – A, 3 – C, 4 – D',
'1 – B, 2 – A, 3 – D, 4 – C',
'1 – A, 2 – B, 3 – D, 4 – C',
3,
'FL-6.1.1 (K2) Testwerkzeuge gemäß ihrem Zweck und den Testaktivitäten, die sie unterstützen, klassifizieren können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3)\n\nDie korrekte Zuordnung von Testaktivitäten und Testwerkzeugen ist laut Lehrplan 6.1.1:\na) 1. Performanzmessung und dynamische Analyse - (B) Dynamische Analysewerkzeuge\n\nb) 2. Testausführung und Protokollierung - (A) Tools zur Anforderungsüberdeckung\n\nSomit ist Option c) korrekt.\n\nd) 4. Testentwurf - (C) Werkzeuge zur Vorbereitung von Testdaten.',
'https://i.imgur.com/7W7rUQS.png',6,0],
['Welcher der folgenden Punkte wird AM WAHRSCHEINLICHSTEN als Grund für die Verwendung eines Pilotprojekts zur Einführung eines Werkzeugs in einem Unternehmen verwendet?',
'Die Notwendigkeit zu bewerten, wie das Werkzeug zu bestehenden Prozessen und Vorgehensweisen passt und zu bestimmen, was geändert werden muss.',
'Die Notwendigkeit, die Fähigkeiten zur Testautomatisierung sowie die Trainings-, Mentoring- und Coaching-Bedürfnisse der Tester zu bewerten, die das Werkzeug nutzen werden.',
'Die Notwendigkeit zu bewerten, ob das Werkzeug die erforderliche Funktionalität bietet und bestehende Testwerkzeuge nicht dupliziert.',
'Die Notwendigkeit, den Werkzeughersteller zu bewerten in Bezug auf die Schulung und andere Unterstützung, die er anbietet.',
1,
'FL-6.2.2 (K1) Sich an Ziele für die Nutzung von Pilotprojekten zur Einführung von Werkzeugen erinnern können\n\nBegründung: (CTFL CORE Syllabus 2018, V.3.1; Glossar V.3.3\n\na) KORREKT – Gemäß Lehrplan (6.2.2).\n\nb) FALSCH – Die Bewertung der Fähigkeiten zur Testautomatisierung und der Trainings-, Mentoring- und Coaching-Bedürfnisse der Tester, die das Tool verwenden werden, hätte im Rahmen der Werkzeugauswahl gemäß Lehrplan (6.2.1) durchgeführt werden sollen.\n\nc) FALSCH – Die Entscheidung, ob das Werkzeug die erforderliche Funktionalität bietet und bestehende Werkzeuge nicht dupliziert, hätte im Rahmen der Werkzeugauswahl gemäß Lehrplan (6.2.1) getroffen werden sollen.\n\nd) FALSCH – Die Bewertung des Werkzeugherstellers im Hinblick auf die Schulung und andere Unterstützung, die er anbietet, hätte im Rahmen der Werkzeugauswahl gemäß Lehrplan (6.2.1) durchgeführt werden sollen.',
'',6,0],



['Welche der folgenden Definitionen entspricht dem Begriff „Testbedingung“ gemäß Glossar?',
'Ein kennzeichnendes Merkmal einer Komponente oder eines Systems.',
'Ein testbarer Aspekt einer Komponente oder eines Systems, der als Grundlage für das Testen identifiziert wurde.',
'Der Grad, zu dem eine Komponente oder ein System Funktionen zur Verfügung stellt, welche unter festgelegten Bedingungen explizit genannte und implizite Bedürfnisse erfüllen.',
'Testfälle entworfen im Hinblick auf die Ausführung von Kombinationen von Bedingungen und aus ihnen resultierender Aktionen.',
2,
'Laut Glossar V.3.3 "Testbedingung": Eine Einheit oder ein Ereignis, z.B. eine Funktion, eine Transaktion, ein Feature, ein Qualitätsmerkmal oder ein strukturelles Element einer Komponente oder eines Systems, welche bzw. welches durch einen oder mehrere Testfälle verifiziert werden kann.',
'',0,1],
['Welche der folgenden Aussagen beschreibt ein gültiges Ziel des Testens?',
'Der Test soll möglichst spät starten, damit die Entwicklung genug Zeit hatte, ein gutes Produkt zu erstellen.',
'Es soll validiert werden, ob das Testobjekt so funktioniert, wie es die Benutzer und andere Stakeholder erwarten.',
'Es soll nachgewiesen werden, dass alle möglichen Fehlerzustände identifiziert wurden.',
'Es soll nachgewiesen werden, dass alle verbleibenden Fehlerzustände keine Fehlerwirkungen verursachen werden.',
2,
'Ziele des Testens (Syllabus 1.1.1):\n· Arbeitsergebnisse wie Anforderungen, User-Stories, Architekturdesign und Code bewerten, um Fehler zu identifizieren und in Folgearbeitsergebnissen zu vermeiden\n\n· Verifizieren, ob alle spezifischen Anforderungen erfüllt sind\n\n· Prüfen, ob das Testobjekt vollständig ist und validieren, ob das Testobjekt so funktioniert, wie es die Benutzer und andere Stakeholder erwarten\n\n· Vertrauen in das Qualitätsniveau des Testobjekts schaffen\n\n· Fehlerwirkungen und Fehlerzustände aufdecken, wodurch man Risiken aufgrund einer unzureichenden Softwarequalität reduziert\n\n· Stakeholdern ausreichende Informationen zur Verfügung stellen, damit diese fundierte Entscheidungen treffen können, insbesondere bezüglich des Qualitätsniveaus des Testobjekts\n\n· Konform mit vertraglichen, rechtlichen oder regulatorischen Anforderungen oder Standards zu sein und/oder um die Konformität (compliance) des Testobjekts mit diesen Anforderungen oder Standards zu verifizieren',
'',1,1],
['Welche der folgenden Aussagen beschreibt den Unterschied zwischen Testen und Debugging zutreffend?',
'Testen identifiziert die Ursache von Fehlerzuständen. Debugging analysiert die Fehlerzustände und schlägt Präventionsmaßnahmen vor.',
'Dynamische Tests zeigen Fehlerwirkungen auf, die durch Fehlerzustände verursacht wurden. Debugging ist eine Entwicklungsaktivität, die Fehlerzustände beseitigt, die die Ursache von Fehlerwirkungen sind.',
'Testen entfernt Fehlerwirkungen; Debugging entfernt dagegen Fehlerzustände, die Fehlerwirkungen verursachen.',
'Dynamische Tests verhindern die Ursache von Fehlerwirkungen. Debugging entfernt die Fehlerwirkungen.',
2,
'Dynamisches Testen zeigt Fehlerwirkungen auf, die durch Fehlerzustände verursacht wurden. Durch Debugging können die Ursachen von Fehlerwirkungen analysiert und beseitigt werden (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.1.2).',
'',1,1],
['Nachfolgend finden Sie eine Liste von Problemen, die während des Testens oder im Betrieb beobachtet werden können. Welches Problem ist eine Fehlerwirkung?',
'Das Produkt stürzte ab, als der Benutzer eine Option in einer Dialogbox auswählte.',
'Eine kompilierte Quellcodedatei wurde in der falschen Version zum Build hinzugefügt.',
'Der Berechnungsalgorithmus verwendet die falschen Eingangsvariablen.',
'Der Entwickler hat die Anforderungen an den Algorithmus falsch interpretiert.',
1,
'a) KORREKT – Eine Fehlerwirkung ist das Sichtbarwerden eines Fehlerzustands während der Ausführung. Ein Absturz ist vom Anwender deutlich spürbar (siehe CTFL Lehrplan CORE 2018; Abschnitt 1.2.3)\n\nb) FALSCH – Diese Art von Fehlern (Fehlhandlungen) wird nicht unbedingt zu einer sichtbaren oder spürbaren Fehlerwirkung führen; zum Beispiel, wenn die Änderungen in der neuen Version der Quelldatei nur in den Kommentaren vorgenommen wurden. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.3)\n\nc) FALSCH – Es handelt sich um einen Fehlerzustand, nicht um eine Fehlerwirkung. Verwendung von falschen Eingabevariablen wird nicht unbedingt zu einer sichtbaren oder spürbaren Fehlerwirkung führen; zum Beispiel, wenn niemand diesen speziellen Algorithmus verwendet; oder wenn die falsche Eingabevariable einen ähnlichen Wert wie die richtige Eingabevariable hat; oder wenn das FALSCHE Resultat des Algorithmus nicht verwendet wird. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.3)\n\nd) FALSCH – Es handelt sich um eine Fehlhandlung, nicht um eine Fehlerwirkung. Diese Art von Fehlern wird nicht notwendigerweise zu einer Fehlerwirkung führen; zum Beispiel, wenn niemand diesen speziellen Algorithmus verwendet. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.3)',
'',1,1],
['Ein Tester hat über einen Zeitraum von 5 Jahren Software-Applikationen auf mobilen Geräten einem Test unterzogen. Er hat sich einen großen Erfahrungsschatz im Testen von mobilen Applikationen angeeignet und erzielt in kürzer Zeit bessere Ergebnisse als andere. Über einen längeren Zeitraum hat der Tester die existierenden automatisierten Testfälle nicht modifiziert und auch keine neuen Testfälle mehr erstellt. Dies führt dazu, dass durch Ausführung der Tests immer weniger Fehler gefunden werden. Welchen Grundsatz des Softwaretestens hat der Tester nicht beachtet?',
'Testen ist abhängig vom Umfeld',
'Vollständiges Testen ist nicht möglich',
'Wiederholungen haben keine Wirksamkeit',
'Häufung von Fehlerzuständen',
3,
'a) FALSCH – Test ist abhängig vom Umfeld, egal, ob manuell oder automatisiert (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.3; 6. Grundsatz), führt aber nicht dazu, dass - wie oben beschrieben - immer weniger Fehler aufgedeckt werden.\n\nb) FALSCH – Erschöpfendes vollständiges Testen ist unmöglich, egal wieviel Aufwand wir in den Test investieren (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.3; 2. Grundsatz), führt aber nicht dazu, dass - wie oben beschrieben - immer weniger Fehler aufgedeckt werden.\n\nc) KORREKT – Ein Grundsatz (gem. CTFL CORE Lehrplan 2018) besagt: “Vorsicht vor dem Pestizid-Paradoxon“ bzw. Wiederholungen haben keine Wirksamkeit (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.3; 5. Grundsatz), dass eine Ausführung immer der gleichen Testfälle keine neuen Erkenntnisse mehr bringt. Um neue Fehlerzustände zu finden, müssen bestehende Tests möglicherweise verändert werden und neue Tests erstellt werden.\n\nd) FALSCH – Oftmals ist eine “Häufung von Fehlerzuständen“ (CTFL CORE Lehrplan 2018; Abschnitt 1.3; 4. Grundsatz) in einer kleinen Anzahl von Modulen zu beobachten; das führt aber nicht dazu, dass - wie oben beschrieben - immer weniger Fehler aufgedeckt werden.',
'',1,1],
['Inwiefern leistet das Testen einen Beitrag zur Verbesserung von Qualität?',
'Testen stellt sicher, dass Anforderungen detailliert genug sind.',
'Testen verringert das Risiko von unzureichender Softwarequalität.',
'Testen stellt sicher, dass in der Organisation Standards befolgt werden.',
'Testen misst die Softwarequalität im Hinblick auf die Anzahl ausgeführter Testfälle.',
2,
'a) FALSCH – Durch statisches Testen (Reviews) kann dazu beigetragen werden, aber es kann nicht sichergestellt werden, dass die Anforderungen detailliert genug sind. (vgl. CTFL Lehrplan 2018; Abschnitt 1.2.2).\nb) KORREKT – Testen deckt Fehlerwirkungen und Fehlerzustände auf und verringert damit das Risiko von unzureichender Softwarequalität (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.1.1).\nc) FALSCH – Dies ist Qualitätssicherung, aber nicht Testen (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.2).\nd) FALSCH – Die Qualität kann nicht anhand der Anzahl ausgeführter Testfälle gemessen werden, ohne dass man das Ergebnis kennt (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.2).',
'',1,1],
['Welche der folgenden Aktivitäten ist Teil der Hauptaktivität „Testanalyse“ im Testprozess?',
'Identifikation der erforderlichen Infrastruktur und Werkzeuge',
'Erstellen von Testsuiten basierend auf den Testskripten',
'Analyse der „Lessons learned“ zur Prozessverbesserung',
'Bewerten der Testbasis hinsichtlich Testbarkeit',
4,
'a) FALSCH – diese Aktivität wird im “Testentwurf” durchgeführt (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.2; Testentwurf).\nb) FALSCH – diese Aktivität wird in der “Testrealisierung” durchgeführt (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.2; Testrealisierung).\nc) FALSCH – diese Aktivität wird im “Testabschluss“ durchgeführt (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.2; Testabschluss).\nd) KORREKT – diese Aktivität wird in der „Testanalyse“ durchgeführt (CTFL CORE Lehrplan 2018; Abschnitt 1.4.2: „Während der Testanalyse wird die Testbasis analysiert, um testbare Features zu identifizieren …“).',
'',1,1],
['Wählen Sie die richtige Kombination für die aufgeführten Beschreibungen von Testarbeitsergebnissen',
'1A, 2C, 3B, 4D',
'1D, 2B, 3A, 4C',
'1A, 2C, 3D, 4B',
'1D, 2C, 3B, 4A',
1,
'Begründung (nach CTFL CORE Lehrplan 2018, V.3.1, Glossar V.3.3)\nTestsuite: Eine Menge von Testskripten oder Testabläufen, die in einem bestimmten Testlauf ausgeführt werden sollen. gemäß Glossar V.3.3, wobei „Testabläufe“ durch „Testskripten“ ersetzt werden kann laut Glossar („See Also“ bei Testablauf bzw. Synonyms bei 3.3) (1A).\nTestfall: gemäß Glossar: Eine Menge von Vorbedingungen, Eingaben, Aktionen (falls anwendbar), erwarteten Ergebnissen und Nachbedingungen, welche auf Basis von Testbedingungen entwickelt wurden. (2C).\nTestskript: gemäß Glossar: Eine Abfolge von Anweisungen für die Durchführung eines Tests. (3B).\nTest-Charta: „Die Dokumentation eines Ziels und der Agenda einer Testsitzung.“ gemäß Glossar V.3.1 und Syllabus 4.4.2: Die Dokumentation von Testaktivitäten im Rahmen des sitzungsbasierten explorativen Testens. (4D).\na) KORREKT – s.o.\nb) FALSCH – s.o.\nc) FALSCH – s.o.\nd) FALSCH – s.o.',
'https://i.imgur.com/kkPcCzV.png',0,1],
['Wie kann der White-Box-Test während des Abnahmetests angewendet werden?',
'Um zu prüfen, ob große Datenmengen zwischen integrierten Systemen übertragen werden können.',
'Um zu prüfen, ob alle Code-Anweisungen und Code-Entscheidungspfade ausgeführt wurden.',
'Um zu prüfen, ob alle Abläufe der Arbeitsprozesse abgedeckt sind.',
'Um alle Webseiten-Navigationen abzudecken.',
3,
'a) FALSCH – Relevant für Integrationstests. (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.2.2)\nb) FALSCH – Relevant für Komponententests (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.2.1 und 2.3.5, Beispiele für White-Box-Tests)\nc) KORREKT – CTFL CORE Lehrplan 2018, Abschnitt 2.3.5: Für Abnahmetests sind die Tests so konzipiert, dass sie z. B. alle Dateistrukturen und Wertebereiche der Finanzdaten für Bank-zu-Bank-Überweisungen unterstützen.\nd) FALSCH – Relevant für Systemtests (vgl. CTFL CORE Lehrplan 2018; Abschnitt 2.2.3, Beispiele für White-Box-Tests)',
'',2,1],
['Welche der folgenden Aussagen zum Vergleich zwischen Komponententest und Systemtest ist WAHR?',
'Komponententests überprüfen die Funktion von Komponenten, Programmobjekten und Klassen, die separat prüfbar sind, während Systemtests die Schnittstellen zwischen den Komponenten und Wechselwirkungen mit anderen Teilen des Systems überprüfen.',
'Testfälle für den Komponententest werden in der Regel von Komponentenspezifikationen, Designspezifikationen oder Datenmodellen abgeleitet, während Testfälle für den Systemtest in der Regel von Anforderungsspezifikationen oder Anwendungsfällen abgeleitet werden.',
'Komponententests konzentrieren sich nur auf die funktionalen Eigenschaften, während Systemtests sich auf die funktionalen und nicht-funktionalen Eigenschaften konzentrieren.',
'Komponententests sind in der Verantwortung der Tester, während die Systemtests in der Regel in der Verantwortung der Benutzer des Systems liegen.',
2,
'FL-2.2.1 (K2) Die unterschiedlichen Teststufen unter den Aspekten der Testziele, Testbasis, Testobjekte, typischen Fehlerzustände und Fehlerwirkungen sowie der Testvorgehensweise und Verantwortlichkeiten vergleichen können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1, Glossar V.3.3)\n\na) FALSCH – Systemtests testen nicht die Schnittstellen und Wechselwirkungen zwischen den Komponenten und anderen Teilen des Systems; das ist Ziel von Integrationstests (siehe CTFL CORE Lehrplan 2018, Abschnitt 2.2.2).\n\nb) KORREKT – (siehe CTFL CORE Lehrplan 2018, Abschn. 2.2.1 (Komponententest): Beispiele für Arbeitsprodukte, die als Testbasis für Komponententests verwendet werden können, umfassen: detailliertes Design, Code, Datenmodell, Komponentenspezifikationen. CTFL CORE Lehrplan 2018; Abschn. 2.2.3: Beispiele für Arbeitsprodukte für Systemtests umfassen: System- und Softwareanforderungsspezifikationen (funktional und nicht funktionale), Anwendungsfälle.\n\nc) FALSCH – Komponententests konzentrieren sich nicht nur auf funktionale, sondern auch auf nicht-funktionale Aspekte (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.2.1, Komponententest).\n\nd) FALSCH – Komponententests werden auch von Entwicklern durchgeführt, wohin gegen sich (unabhängige) Tester mit Systemtests befassen (vgl. CTFL CORE Lehrplan 2018, Unterkapitel 2.2.1 und 2.2.3, jeweils Abschnitt „Spezifische Ansätze und Verantwortlichkeiten“).',
'',2,1],
['Welche der folgenden Aussagen ist zutreffend?',
'Der Zweck des Regressionstests ist es, zu überprüfen, ob die Korrektur erfolgreich implementiert wurde, während der Zweck der Fehlernachtests darin besteht, zu bestätigen, dass die Korrektur keine Seiteneffekte hat.',
'Der Zweck des Regressionstests ist es, unbeabsichtigte Seiteneffekte zu erkennen, während der Zweck des Fehlernachtests darin besteht zu prüfen, ob das System in einer neuen Umgebung noch funktioniert.',
'Der Zweck des Regressionstests ist es, unbeabsichtigte Seiteneffekte zu erkennen, während der Zweck des Fehlernachtests darin besteht zu prüfen, ob der ursprüngliche Fehlerzustand behoben wurde.',
'Der Zweck des Regressionstests ist es zu prüfen, ob die neue Funktionalität funktioniert, während der Zweck des Fehlernachtests darin besteht zu prüfen, ob der ursprüngliche Fehlerzustand behoben wurde.',
3,
'FL-2.3.3 (K2) Den Zweck von Fehlernachtests und Regressionstests vergleichen können.\nBegründung (nach CTFL CORE Lehrplan 2018, V3.1; Glossar V.3.3)\n\na) FALSCH – Regressionstests überprüfen nicht die erfolgreiche Implementierung einer Korrektur und Fehlernachtest prüfen nicht auf Seiteneffekte. (siehe CTFL CORE Lehrplan, Abschnitt 2.3.4).\n\nb) FALSCH – Die Aussage über Fehlernachtests sollte sich auf Regressionstests beziehen (siehe CTFL CORE Lehrplan 2018, Abschnitt 2.3.4).\n\nc) KORREKT – CTFL CORE Lehrplan 2018, Abschnitt 2.3.4.\n\nd) FALSCH – Test neuer Funktionalität ist nicht Bestandteil eines Regressionstests (siehe CTFL CORE Lehrplan 2018, Abschnitt 2.4 im Vergleich zu Abschn. 2.3.4 für Regressionstests).',
'',2,1],
['Welches ist die BESTE Definition eines inkrementellen Entwicklungsmodells?',
'Die Definition der Anforderungen, das Design der Software und das Testen erfolgen in einer Serie durch Hinzufügen von Teilen.',
'Eine Phase des Entwicklungsprozesses sollte beginnen, wenn die vorhergehende Phase abgeschlossen ist.',
'Das Testen wird als separate Phase betrachtet. Sie startet, wenn die Entwicklung abgeschlossen ist.',
'Das Testen wird der Entwicklung als Inkrement hinzugefügt.',
1,
'FL-2.1.1 (K2) Die Beziehungen zwischen Softwareentwicklungsaktivitäten und Testaktivitäten im Softwareentwicklungslebenszyklus erklären können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1 (9. Absatz): Bei der inkrementellen Entwicklung geht es um die Festlegung von Anforderungen, Entwurf, Entwicklung und Test eines Systems in Teilen.\n\nb) FALSCH – Dieses ist ein sequenzielles Modell (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).\n\nc) FALSCH – Dies beschreibt das Wasserfall-Modell (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).\n\nd) FALSCH – Das Testen für sich ist kein Inkrement/zusätzliche Stufe in der Entwicklung, sondern während der Entwicklung gibt es Inkremente (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).',
'',2,1],
['Welche der folgenden Entscheidungen sollte KEIN Auslöser für Wartungstests sein?',
'Die Entscheidung, die Wartbarkeit der Software zu testen',
'Die Entscheidung, das System nach der Migration auf einer neuen Betriebsplattform zu testen',
'Die Entscheidung zu testen, ob archivierte Daten abgerufen werden können',
'Die Entscheidung zum Testen nach "Hot Fixes"',
1,
'FL-2.4.1 (K2) Auslöser für Wartungstests zusammenfassen können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Dies ist ein Wartbarkeitstest und nicht ein Wartungstest. „... die meisten Wartbarkeitsfehler (können) nur durch statische Tests gefunden werden.“ (CTFL CORE Lehrplan 2018, Kap. 3.1.3, letzter Absatz)\n\nb) FALSCH – Dies ist ein Auslöser für Wartungstests, siehe CTFL CORE Lehrplan 2018, Kapitel 2.4.1: Betriebstests der neuen Umgebung, sowie der geänderten Software.\n\nc) FALSCH – Dies ist ein Auslöser für Wartungstests, siehe CTFL CORE Lehrplan 2018, Kapitel 2.4.1, 3. Absatz: Testen von Wiederherstellungs- und Rückhol-prozeduren nach der Archivierung mit langen Aufbewahrungszeiten.\n\nd) FALSCH – Dies ist ein Auslöser für Wartungstests, siehe CTFL CORE Lehrplan 2018, Kapitel 2.4, 2. Absatz, und Kap. 2.4.1: Reaktive Modifikation eines ausgelieferten Softwareproduktes zur Behebung von dringenden Fehlerzuständen, die zu tatsächlichen Fehlerwirkungen geführt haben.',
'',2,1],
['Welche der folgenden Optionen sind Rollen in einem formalen Review?',
'Entwickler, (Review-)Moderator, Reviewleiter, Gutachter, Tester',
'Autor, (Review-)Moderator, Manager, Gutachter, Entwickler',
'Autor, Manager, Reviewleiter, Gutachter, Designer',
'Autor, (Review-)Moderator, Reviewleiter, Gutachter, Protokollant',
4,
'FL-3.2.2 (K1) Die unterschiedlichen Rollen und Verantwortlichkeiten in einem formalen Review erkennen können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Tester und Entwickler sind KEINE Rollen im formalen Review gemäß CTFL CORE Lehrplan 2018, Kapitel 3.2.2.\n\nb) FALSCH – Entwickler ist KEINE Rolle im formalen Review gemäß CTFL CORE Lehrplan 2018, Kapitel 3.2.2.\n\nc) FALSCH – Designer ist KEINE Rolle im formalen Review gemäß CTFL CORE Lehrplan 2018, Kapitel 3.2.2.\n\nd) KORREKT – siehe CTFL CORE Lehrplan 2018, Kapitel 3.2.2.',
'',3,1],
['Welche Aktivitäten werden im Rahmen der Planung eines formalen Reviews durchgeführt?',
'Sammeln von Metriken für die Bewertung der Effektivität des Reviews.',
'Beantwortung von Fragen, die die Teilnehmer haben könnten.',
'Definition und Prüfung der Erfüllung von Eingangskriterien für das Review.',
'Bewertung der Reviewbefunde gegenüber den Endekriterien.',
3,
'FL-3.2.1 (K2) Die Aktivitäten des Reviewprozesses für Arbeitsergebnisse zusammenfassen können.\nBegründung: (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Das Sammeln von Metriken ist der Hauptaktivität „Fehlerbehebung und Bericht“ zugeordnet. (vgl. CTFL CORE Lehrplan 2018, Abschn. 3.2.1);\n\nb) FALSCH – Die Beantwortung von Fragen ist der Hauptaktivität „Reviewbeginn“ (Initiierung eines Reviews, KICKOFF) zugeordnet (vgl. CTFL CORE Lehrplan 2018, Abschn. 3.2.1);\n\nc) KORREKT – Sowohl die Definition als auch die Prüfung von Eingangskriterien erfolgt in der „Planung“ eines formalen Reviews (vgl. CTFL CORE Lehrplan 2018, Abschn. 3.2.1);\n\nd) FALSCH – Die Bewertung der Reviewbefunde gegenüber den Endekriterien ist der Hauptaktivität „Befundkommunikation und -analyse“ zugeordnet (vgl. CTFL CORE Lehrplan 2018, Abschn. 3.2.1);',
'',3,1],
['Welche der unten aufgeführten Reviewarten ist AM BESTEN geeignet, wenn das Review gemäß einem formalen bzw. definierten Prozess mit Regeln und unter Verwendung von Checklisten durchgeführt werden soll?',
'Informelles Review',
'Technisches Review',
'Inspektion',
'Walkthrough',
3,
'FL-3.2.3 (K2) Die Unterschiede zwischen den unterschiedlichen Reviewarten erklären können: informelles Review, Walkthrough, technisches Review und Inspektion.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – ein informelles Review verwendet keinen formalen Prozess (siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.3, 3. Absatz)\n\nb) FALSCH – die Verwendung von Checklisten ist optional (siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.3, 5. Absatz)\n\nc) KORREKT – Inspektion ist ein definierter Prozess mit Regeln und Checklisten (siehe CTFL CORE Lehrplan 2018; Abschnitt 3.2.3, 6. Absatz)\n\nd) FALSCH – erfordert nicht immer einen formalen Prozess und die Verwendung von Checklisten ist optional (siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.3, 4. Absatz)',
'',3,1],
['Welche der folgenden Aussagen zum statischen Test ist am EHESTEN zutreffend?',
'Statischer Test ist eine kostengünstige Möglichkeit, Fehlerzustände zu erkennen und zu beheben.',
'Statischer Test macht den dynamischen Test theoretisch überflüssig.',
'Statischer Test ermöglicht, Laufzeitprobleme frühzeitig im Lebenszyklus zu erkennen.',
'Bei der Prüfung sicherheitskritischer Systeme hat der statische Test einen geringen Stellenwert, da der dynamische Test den Fehlerzustand besser findet.',
1,
'FL-3.1.2 (K2) Beispiele nennen können, um den Wert des statischen Tests zu beschreiben.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – CTFL CORE Lehrplan 2018; Abschnitt 3.1.2, 3. Satz: Früh entdeckte Fehlerzustände sind oft viel kostengünstiger zu beheben als Fehlerzustände, die später im Lebenszyklus erkannt werden.\n\nb) FALSCH – Dynamische Tests haben ihre Berechtigung, da sie andere Fehlerarten finden als statische Tests (vgl. CTFL CORE Lehrplan 2018; Abschnitt 3.1.3, 1. Absatz).\n\nc) FALSCH – Dies geschieht beim dynamischen Testen (siehe Glossar V.3.2).\n\nd) FALSCH – Statischer Test ist wichtig für sicherheitskritische Computersysteme (vgl. CTFL CORE Lehrplan 2018; Abschnitt 3.1, 2. Absatz).',
'',3,1],
['Welche der Aussagen zu dem beschriebenen Review ist korrekt?',
'Punkt ii) der Checkliste wurde verletzt, da nicht klar ist, welche Bedingung erfüllt sein muss, damit zum Review eingeladen werden kann.',
'Ihnen fällt auf, dass neben dem Tester auch ein Experte für Validierung eingeladen werden muss. Da dieser Punkt aber nicht Bestandteil Ihrer Checkliste ist, erstellen Sie keinen entsprechenden Kommentar.',
'Punkt iii) der Checkliste wurde verletzt, da nicht klar ist, wodurch das Review als abgeschlossen gekennzeichnet ist.',
'Punkt i) der Checkliste wurde verletzt, da nicht klar ist, wer die Checkliste für die Einladung zum Review bereitstellt.',
4,
'FL-3.2.4 (K3) Ein Reviewverfahren auf ein Arbeitsergebnis anwenden können, um Fehlerzustände zu finden.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – es ist beschrieben, dass der Architekt die Systemspezifikation fertiggestellt haben muss.\n\nb) FALSCH – siehe CTFL CORE Lehrplan, Abschnitt 3.2.4, „Checklistenbasiert“: im letzten Satz des Absatzes steht, dass auch auf Punkte außerhalb der Checkliste geachtet werden muss.\n\nc) FALSCH – es ist beschrieben: jeder Gutachter hat seinen Review-done-Kommentar erstellt.\n\nd) KORREKT – es ist beschrieben: „Eine bereitgestellte Checkliste“ … aber wer stellt sie bereit?',
'https://i.imgur.com/PIhlxHz.png',3,1],
['Was ist checklistenbasiertes Testen?',
'Ein Testverfahren, bei dem Testfälle auf Basis des Wissens der Tester über frühere Fehler oder aus allgemeinem Wissen über Fehlerwirkungen abgeleitet werden.',
'Ein Testverfahren, das auf einer Analyse der Spezifikation einer Komponente oder eines Systems basiert.',
'Ein erfahrungsbasiertes Testverfahren, bei dem der erfahrene Tester z. B. eine Liste von Kontrollpunkten nutzt, welche beachtet, überprüft oder in Erinnerung gerufen werden müssen.',
'Ein Testansatz, bei dem die Tester dynamisch Tests entwerfen und durchführen, basierend auf ihrem Wissen, der Erkundung des Testelements und dem Ergebnis früherer Tests.',
3,
'FL-4.x (K1) Schlüsselbegriffe\nBegründung: (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Das ist die Definition für intuitive Testfallermittlung, siehe Glossar V.3.3.\n\nb) FALSCH – Das ist die Definition für Black-Box-Testverfahren, siehe Glossar V.3.3.\n\nc) KORREKT – siehe Glossar 3.3.\n\nd) FALSCH – Das ist (bis auf die Erwähnung des Testers) die Definition für exploratives Testen, siehe Glossar V.3.3.',
'',0,1],
['Welches der folgenden Verfahren kann der Kategorie Black-Box-Testverfahren zugeordnet werden?',
'Verfahren, das auf der Analyse der Architektur basiert.',
'Verfahren, das prüft, ob das Testobjekt entsprechend dem Feinentwurf umgesetzt ist.',
'Verfahren, das auf dem Wissen über frühere Fehler oder dem allgemeinen Wissen über Fehler basiert.',
'Verfahren, das z. B. auf formalen Anforderungsdokumenten basiert.',
4,
'FL-4.1.1 (K2) Die Eigenschaften, Gemeinsamkeiten und Unterschiede zwischen BlackBox-Testverfahren, White-Box-Testverfahren und erfahrungsbasierten Testverfahren erklären können.\nBegründung: (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Dies bezieht sich auf White-Box-Testverfahren. (vgl. CTFL CORE Lehrplan 2018, 4.1.2, 3. Absatz)\n\nb) FALSCH – Dies bezieht sich auf White-Box-Testverfahren. (vgl. CTFL CORE Lehrplan 2018; Abschnitte 4.1.2, 3. Absatz)\n\nc) FALSCH – Dies bezieht sich auf erfahrungsbasierte Testverfahren. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.4)\n\nd) KORREKT – CTFL CORE Lehrplan 2018; Abschnitt 4.1.2, 2. Absatz: Black-Box-Testverfahren basieren auf einer Analyse der zugehörigen Testbasis (z. B. formale Anforderungsdokumente, Spezifikationen, Anwendungsfälle, User-Stories).',
'',4,1],
['Welche der Aussagen zur Entscheidungsüberdeckung ist zutreffend?',
'Die Aussage ist wahr. Ein einzelner Testfall erzielt eine 100% Anweisungsüberdeckung und daher 50% Entscheidungsüberdeckung.',
'Die Aussage ist wahr. Bei einem einzelnen Testfall ist der Entscheidungsausgang der IF-Anweisung entweder wahr oder falsch.',
'Die Aussage ist falsch. Ein einzelner Testfall kann in diesem Fall nur eine Entscheidungsüberdeckung von 25% garantieren.',
'Die Aussage ist falsch. Die Aussage ist zu weit gefasst. Sie kann abhängig von der getesteten Software richtig sein oder nicht.',
2,
'FL-4.3.2 (K2) Entscheidungsüberdeckung erklären können.\nBegründung: (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na)  FALSCH – Während die gemachte Aussage wahr ist, ist die Erklärung falsch; weil die Beziehung zwischen Anweisungs- und Entscheidungsüberdeckung falsch dargestellt ist. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.3.3)\n\nb) KORREKT – Da jeder Testfall dazu führt, dass das Ergebnis der IF-Anweisung entweder WAHR oder FALSCH ist, haben wir definitiv 50% Entscheidungsüberdeckung erreicht.(vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.3.2, 2. Absatz)\n\nc) FALSCH – Ein einzelner Testfall kann mehr als 25% Entscheidungs-überdeckung erreichen; bei der obigen Aussage sind es 50% Entscheidungsüberdeckung (vgl. Begründung zu Antwort b)\n\nd) FALSCH – Die obige Aussage ist konkret und immer wahr; weil durch jeden einzelnen Testfall immer eine Entscheidungsüberdeckung von 50% erreicht wird. (vgl. Begründung  zu Antwort b)',
'https://i.imgur.com/x9zLxyC.png',4,1],
['Welche der folgenden Aussagen ist eine Beschreibung für Anweisungsüberdeckung?',
'Es handelt sich um eine Metrik zur Berechnung und Messung des prozentualen Anteils der ausgeführten Testfälle.',
'Es handelt sich um eine Metrik, die den Prozentsatz der ausgeführten Anweisungen im Code angibt.',
'Es handelt sich um eine Metrik zur Berechnung und Messung der Anzahl von Anweisungen im Code, die durch Testfälle ausgeführt wurden, die keine Fehlerwirkung aufgedeckt haben.',
'Es handelt sich um eine Metrik, die eine wahr/falsch-Bestätigung gibt, ob alle Anweisungen abgedeckt sind oder nicht.',
2,
'FL-4.3.1 (K2) Anweisungsüberdeckung erklären können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Anweisungsüberdeckung misst den prozentualen Anteil der durch Testfälle ausgeführten (überdeckten) Anweisungen und hat keinen Bezug zur Zahl ausgeführten Testfälle.\n\nb) KORREKT – CTFL CORE Lehrplan 2018; Abschnitt 4.3.1: Der Anweisungstest führt die  ausführbaren Anweisungen des Codes aus. Die Anweisungsüberdeckung wird als die Anzahl der von den Tests ausgeführten Anweisungen gemessen, geteilt durch die Gesamtzahl der ausführbaren Anweisungen im Testobjekt, normalerweise ausgedrückt in Prozent.\n\nc) FALSCH – Die Abdeckung misst nicht bestanden/fehlgeschlagen bzw. Anweisungsüberdeckung berücksichtigt nicht, ob ein Test erfolgreich ausgeführt wurde.\n\nd) FALSCH – Anweisungsüberdeckung ist eine Metrik, die Prozentwerte liefert und keinewahr/falsch-Aussage macht. Letzteres gilt nur für die Forderung nach 100% Anweisungsüberdeckung.',
'',4,1],
['Welche Aussage über die Beziehung zwischen der Anweisungsüberdeckung und der Entscheidungsüberdeckung ist wahr?',
'100% Entscheidungsüberdeckung schließt 100% Anweisungsüberdeckung ein.',
'100% Anweisungsüberdeckung schließt 100% Entscheidungsüberdeckung ein.',
'50% Entscheidungsüberdeckung schließt 50% Anweisungsüberdeckung ein.',
'Entscheidungsüberdeckung kann nie 100% erreichen.',
1,
'FL-4.3.3 (K2) Die Bedeutung von Anweisungs- und Entscheidungsüberdeckung erklären können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Die Aussage ist wahr, weil die Ausführung aller Entscheidungen zwangsläufig auch die Ausführung aller Anweisungen bedingt. (siehe CTFL CORE Lehrplan 2018; Abschnitt 4.3.3; 3. Absatz).\n\nb) FALSCH – Die Aussage ist falsch, weil die Ausführung aller Anweisungen nicht zwangsläufig auch eine Ausführung aller Entscheidungen bedingt (siehe CTFL CORE Lehrplan 2018, Abschnitt 4.3.3; 3. Absatz).\n\nc) FALSCH – Die Aussage ist falsch, weil z. B. bei dem Code aus Aufgabe 21 in einem Zweig 3 Anweisungen und in dem anderen Zweig 1 Anweisung vorkommen kann - und sonst keine Anweisungen im Code vorkommen. Führt nun ein Testfall den Zweig mit den 3 Anweisungen aus, ergibt sich 50% Entscheidungsüberdeckung und 75% Anweisungsüberdeckung, da 3 der 4 Anweisungen ausgeführt werden. (siehe auch CTFL CORE Lehrplan 2018, Abschnitt 4.3.3).\n\nd) FALSCH – Die Aussage ist falsch, weil z. B. für den Code von Aufgabe 21 zwei (2) Testfälle ausreichen, die einmal das Ergebnis der (einzigen) IF-Anweisung WAHR und einmal FALSCH machen. Dann liegt eine Entscheidungsüberdeckung von 2/2, also 100%, vor. (siehe auch CTFL CORE Lehrplan 2018, Abschnitt 4.3.3).',
'',4,1],
['Für welche der folgenden Situationen ist der Einsatz von explorativem Testen AM EHESTEN geeignet?',
'Wenn unter Zeitdruck die Durchführung bereits spezifizierter Tests beschleunigt werden muss.',
'Wenn das System inkrementell entwickelt und keine Test-Charta vorhanden ist.',
'Wenn Tester zur Verfügung stehen, die über ausreichende Kenntnisse von ähnlichen Anwendungen und Technologien verfügen',
'Wenn bereits ein vertieftes Wissen über das System vorhanden ist und der Nachweis erbracht werden soll, dass besonders intensiv getestet werden soll.',
3,
'FL-4.4.2 (K2) Exploratives Testen erklären können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH –Exploratives Testen ist nicht geeignet, die Durchführung bereits spezifizierter Test zu beschleunigen. Es ist am nützlichsten, wenn es nur wenige oder ungeeignete Spezifikationen der Anforderungen gibt oder einen erheblichen Zeitdruck beim Testen (vgl. CTFL CORE Lehrplan 2018, Abschnitt 4.4.2).\n\nb) FALSCH – Das Nichtvorhandensein einer möglicherweise in der Testanalyse abgeleiteten Test-Charta ist eine schlechte Vorbedingung für den Einsatz von explorativem Testen. (siehe CTFL CORE Lehrplan 2018; Abschnitte 1.4.3 und 4.4.2, 2. Absatz).\n\nc) KORREKT – Exploratives Testen sollte von Testern mit Kenntnissen über ähnliche Anwendungen und Technologien durchgeführt werden (siehe CTFL CORE Lehrplan 2018; Abschnitte 4.4, 2. Absatz, und 1.4.2, „Testanalyse“, zweitletzter Absatz, 1.4.3, Absatz „Arbeitsergebnisse der Testanalyse”).\n\nd) FALSCH – Exploratives Testen ist als alleinige Vorgehensweise nicht geeignet, den Nachweis zu erbringen, dass besonders intensiv getestet wurde, sondern der Nachweis wird in Kombination mit anderen Testverfahren erbracht (siehe CTFL CORE Lehrplan 2018; Abschnitt 4.4, 1. Absatz: „Die Überdeckung ist bei diesen Verfahren schwer zu beurteilen und möglicherweise nicht messbar.“).',
'',4,1],
['Wie viele Testfälle sind für eine vollständige Testabdeckung notwendig, wenn nur gültige Äquivalenzklassen herangezogen werden?',
'2',
'3',
'4',
'5',
3,
'FL-4.2.1 (K3) Die Äquivalenzklassenbildung anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – es werden zwei Äquivalenzklassen zu wenig geprüft (siehe die 4 KORREKTEN Äquivalenzklassen in c).\n\nb) FALSCH – es wird eine Äquivalenzklasse zu wenig geprüft (siehe die 4 KORREKTEN Äquivalenzklassen in c).\n\nc) KORREKT – Die 4 gültigen Äquivalenzklassen entsprechen der Beschreibung in der Frage; d. h. für jede Äquivalenzklasse ist mindestens ein Testfall zu erstellen:\n1. Äquivalenzklasse: 0 ≤ Beschäftigungszeit ≤ 2,\n2. Äquivalenzklasse: 2 < Beschäftigungszeit < 5,\n3. Äquivalenzklasse: 5 ≤ Beschäftigungszeit ≤ 10\n4. Äquivalenzklasse: 10 < Beschäftigungszeit\n\nd) FALSCH – das ist ein Testfall zu viel; d. h. es werden mehr Testfälle durchgeführt als gültige Äquivalenzklassen vorhanden sind (siehe die 4 KORREKTEN Äquivalenzklassen in c).',
'https://i.imgur.com/hO9R56c.png',4,1],
['Welcher wäre der notwendige Satz von Werten (km/h), der durch die Grenzwertanalyse identifiziert wird, wobei nur die Werte auf den Grenzen der Äquivalenzklassen zu wählen sind?',
'0, 49, 50, 54, 59, 60',
'50, 55, 60',
'49, 50, 54, 55, 60, 62',
'50, 51, 55, 56, 60, 61',
4,
'FL-4.2.2 (K3) Die Grenzwertanalyse anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\nDie folgenden Partitionen (Äquivalenzklassen) und Grenzwerte für die Geschwindigkeit (v) können identifiziert werden:\n\nÄquivalenzklasse 1: <= 50, Grenzwert 50\nÄquivalenzklasse 2: 51 – 55; Grenzwerte 51, 55\nÄquivalenzklasse 3: 56 – 60; Grenzwerte 56, 60\nÄquivalenzklasse 4. >=61; Grenzwert 61\n\nGrenzwert gem. Glossar V.3.3: Der kleinste oder der größte Wert einer geordneten Äquivalenzklasse.\n\na) FALSCH – Enthält nicht alle notwendigen Grenzwerte, dafür aber zusätzliche Werte hier: 0, 49, 54, 59, die keine Grenzwerte in diesen Äquivalenzklassen sind. (vgl. CTFL CORE Lehrplan 2018, Abschnitt 4.2.2)\n\nb) FALSCH – Enthält nicht alle notwendigen Grenzwerte. Es fehlen 51,56 und 61 (vgl. CTFL CORE Lehrplan 2018, Abschnitt 4.2.2)\n\nc) FALSCH – Enthält nicht alle notwendigen Grenzwerte, dafür aber zusätzliche Werte hier: 49, 54, 62, die keine Grenzwerte sind. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.2.2)\n\nd) KORREKT – Enthält alle notwendigen Grenzwerte. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.2.2)',
'https://i.imgur.com/jRvqCL9.png',4,1],
['Welcher der Testfälle beschreibt eine in der Praxis vorkommende Situation und fehlt in der Entscheidungstabelle?',
'Bedingung1 = JA, Bedingung2 = NEIN, Bedingung3 = JA, Aktion = NEIN',
'Bedingung1 = JA, Bedingung2 = JA, Bedingung3 = NEIN, Aktion = JA',
'Bedingung1 = NEIN, Bedingung2 = NEIN, Bedingung3 = JA, Aktion = NEIN',
'Bedingung1 = NEIN, Bedingung2 = JA, Bedingung3 = NEIN, Aktion = NEIN',
4,
'FL-4.2.3 (K3) Entscheidungstabellentests anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Wenn kein Ziel vereinbart wurde, kann das nicht vereinbarte Ziel auch nicht erreicht werden. Daher handelt es sich nicht um ein in der Praxis vorkommendes Szenario.\n\nb) FALSCH – Der Testfall ist fachlich falsch, da unter diese Bedingungen keine Prämie gezahlt wird, weil das vereinbarte Ziel nicht erreicht wurde.\n\nc) FALSCH – Wenn kein Ziel vereinbart wurde, kann das nicht vereinbarte Ziel auch nicht erreicht werden. Daher handelt es sich nicht um ein in der Praxis vorkommendes Szenario. (Vgl. Antwort a)\n\nd) KORREKT – Der Testfall beschreibt die Situation, dass sowohl die zu kurze Beschäftigungszeit als auch das Nichterreichen des vereinbarten Ziels zur Nichtauszahlung der Prämie führen. Diese Situation kann in der Praxis vorkommen, fehlt aber in der Entscheidungstabelle.',
'https://i.imgur.com/z8TBxvr.png',4,1],
['Welche der Aussagen zum Zustandsdiagramm und der Tabelle von Testfällen ist WAHR?',
'Die Testfälle decken sowohl gültige als auch ungültige (Zustands-)Übergänge im Zustands(übergangs)diagramm ab.',
'Die Testfälle decken alle gültigen (Zustands-) Übergänge im Zustands(übergangs)diagramm ab.',
'Die Testfälle decken nur einige der gültigen (Zustands-)Übergänge im Zustands(übergangs)diagramm ab.',
'Die Testfälle decken sequentielle Paare von (Zustands-)Übergängen im Zustands(übergangs)diagramm ab.',
2,
'FL-4.2.4 (K3) Zustandsübergangstests anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\nDie vorgeschlagenen Testfälle überdecken genau alle fünf möglichen gültigen (Zustands-)Übergänge im gegebenen Zustands(übergangs)diagramm (S1-> S2, S2-> S1, S2-> S3, S3-> S2, S3-> S1).\n\nDaher gilt:\na) FALSCH – da keine ungültigen (Zustands-)Übergänge, wie z. B. S1->S3, abgedeckt werden.\n\nb) KORREKT – da alle 5 gültigen (Zustands-)Übergänge abgedeckt werden.\n\nc) FALSCH – da alle gültigen (Zustands-)Übergänge abgedeckt werden (siehe b).\n\nd) FALSCH – da die Testfälle überhaupt keine Paare von (Zustands-)Übergängen enthalten',
'https://i.imgur.com/B6lvqp6.png',4,1],
['Welche Testfallmenge ist das Ergebnis der Anwendung der Äquivalenzklassenbildung zum Testen der dargestellten Anforderung, mit dem Ziel einer 100% Äquivalenzklassenüberdeckung?',
'Prüfe, ob die Anwendung ein Video auf einem Display der Auflösung 1920x1080 wiedergeben kann (1 Testfall).',
'Prüfe, ob die Anwendung ein Video auf einem Display der kleinsten (640x480) und größten Auflösung (1920x1080) wiedergeben kann (2 Testfälle).',
'Prüfe, ob die Anwendung ein Video auf jeder der geforderten Displayauflösungen wiedergeben kann (4 Testfälle).',
'Prüfe, ob die Anwendung ein Video auf einer beliebigen der geforderten Displayauflösungen wiedergeben kann (1 Testfall).',
3,
'FL-4.2.1 (K3) Die Äquivalenzklassenbildung anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – siehe c).\nb) FALSCH – siehe c).\nc) KORREKT – Dies ist ein Fall, in dem die Anforderung eine Aufzählung von einzelnen Werten beinhaltet. Jeder aufgezählte Wert ist für sich genommen eine Äquivalenzklasse, da diese Werte nicht „erwartungsgemäß in derselben Art und Weise verarbeitet werden“ müssen (CTFL CORE Lehrplan 2018, Abschnitt 4.2.1, 1. Satz). Deshalb wird jeder der 4 Werte bei Anwendung der Äquivalenzklassenbildung getestet.\nd) FALSCH – siehe c).',
'https://i.imgur.com/UtkxEQU.png',4,1],
['Welche der folgenden Aussagen beschreibt AM BESTEN, wie Aufgaben zwischen Testmanager und Tester aufgeteilt werden?',
'Der Testmanager plant Testaktivitäten und wählt die zu befolgenden Standards aus, während der Tester die Werkzeuge und die anzuwendenden Werkzeug-Nutzungsregeln auswählt',
'Der Testmanager plant, koordiniert und steuert die Testaktivitäten, während der Tester die Tests automatisiert.',
'Der Testmanager plant, überwacht und steuert die Testaktivitäten, während der Tester die Tests entwirft und über die Freigabe des Testobjekts entscheidet.',
'Der Testmanager plant und organisiert die Testdurchführung und entwirft die Testfälle, während die Tester die Tests durchführen.',
2,
'FL-5.1.2 (K1) Die Aufgaben eines Testmanagers und eines Testers benennen können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH: Auswahl der Werkzeuge ist eine Testmanager-Aufgabe (CTFL CORE Lehrplan 2018, Abschn. 5.1.2, 11. Aufzählungspunkt).\n\nb) KORREKT – Aufteilung der Aufgaben gem. CTFL CORE Lehrplan 2018, Abschnitt 5.1.2 (Testmanager 2.+ 4. + 8. Aufzählungspunkt; Tester 10. Aufzählungspunkt).\n\nc) FALSCH: Der Tester entscheidet nicht über die Freigabe des Testobjekts, sondern der Testmanager prüft den Stand der Endekriterien … und erstellt … Testabschlussberichte auf der Grundlage der gesammelten Informationen. Abschnitt 5.1.2 (Testmanager 6.+ 7.  Aufzählungspunkt)\n\nd) FALSCH: Der Tester entwirft die Testfälle (CTFL CORE Lehrplan 2018, Abschn. 5.1.2 (Tester 5. Aufzählungspunkt).',
'',5,1],
['Welche der folgenden Metriken ist am NÜTZLICHSTEN für die Messung des Testfortschritts während der Testdurchführung (beim dynamischen Test)?',
'Prozentualer Anteil der durchgeführten Testfälle',
'Anzahl der durchschnittlich an der Testdurchführung beteiligten Tester',
'Überdeckung der Anforderungen durch Code',
'Prozentualer Anteil der bereits erstellten und gereviewten Testfälle',
1,
'FL-5.3.1 (K1) Testmetriken wiedergeben können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – CTFL CORE Lehrplan 5.3.1, Testmetriken, 3. Aufzählungspunkt: „Testfalldurchführung (z. B. Anzahl ausgeführter/nicht ausgeführter Testfälle …)“.\n\nb) FALSCH – Diese Metrik kann zwar gemessen werden, ihre Aussagekraft ist jedoch verschwindend gering. Die Anzahl der Tester sagt nicht viel über die Qualität des Testobjekts oder über den Testfortschritt aus.\n\nc) FALSCH – Die Überdeckung der Anforderungen durch Code wird nicht während der Testdurchführung gemessen. Hierbei wird höchstens die TEST(!)überdeckung des Codes oder der Anforderungen gemessen.\n\nd) FALSCH – diese Metrik ist ein Aspekt des Fortschritts im Rahmen der Aktivitäten vor der Testdurchführung und nicht der Testdurchführung selbst.',
'',5,1],
['Welche der folgenden Antwortmöglichkeiten kann sich auf die (initiale) Testplanung auswirken oder Teil davon sein?',
'Budgetbeschränkungen',
'Testprotokoll',
'Ausfallrate',
'Anwendungsfälle aus dem aktuellen Projekt',
1,
'FL-5.2.1 (K2) Den Zweck und Inhalt eines Testkonzepts zusammenfassen können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Festlegen des Testbudgets ist Bestandteil der Testplanungsaktivitäten. Nach CTFL CORE Lehrplan 2018; Abschnitt 5.2.1: gehören zum Testplan die Budgetierung (7.Aufzählungspunkt) und die Entscheidung, was getestet werden soll (4. Aufzählungspunkt); d. h., wenn Sie den Test planen und es Budgeteinschränkungen gibt, sind Prioritäten darüber erforderlich, was getestet und was weggelassen werden soll."\n\nb) FALSCH – Das Testprotokoll entsteht erst während der Testdurchführung t (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.3, Arbeitsergebnisse der Testdurchführung, 2. Aufzählungspunkt). Es wird auch während der Testdurchführung überprüft (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.2; Testüberwachung undTeststeuerung, 1. Aufzählungspunkt).\n\nc) FALSCH – Die Ausfallrate ist eine Metrik, die im Rahmen der Aktivität „Testüberwachung“ und Steuerung natürlich erst bei der Testdurchführung gemessen wird; siehe CTFL CORE Lehrplan 2018; Abschnitt 5.3.1, Gängige Testmetriken, 4.Aufzählungspunkt.\n\nd) FALSCH – Anwendungsfälle werden erst im Rahmen der Aktivität „Testanalyse“verwendet, die erst nach der initialen Testplanung stattfindet. (Siehe z. B. CTFL CORE Lehrplan 2018; Abschnitt 1.4.2, Testanalyse, 1. Unterpunkt des 1. Aufzählungspunktes.)',
'',5,1],
['Welche der folgenden Listen enthält nur typische Endekriterien?',
'Kennzahlen zu Zuverlässigkeit, Kennzahlen zu Testüberdeckung, Status über Fehlerbehebung und Restrisiken',
'Kennzahlen zu Zuverlässigkeit, Kennzahlen zu Testüberdeckung, Grad der Unabhängigkeit der Tester, Grad der Produktvollständigkeit',
'Kennzahlen zu Zuverlässigkeit, Kennzahlen zu Testüberdeckung, Testkosten, Zeit bis Markteinführung („Time-to-Market“), Grad der Produktvollständigkeit',
'Zeit bis Markteinführung („Time-to-Market“), Restfehler, Qualifikation der Tester, Testüberdeckung und Testkosten',
1,
'FL-5.2.3 (K2) Beispiele für mögliche Eingangs- und Endekriterien geben können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – siehe CTFL Lehrplan 2018; Abschnitt 5.2.3 (4 der 5 Punkte, außer „geplante Tests wurden durchgeführt“)\n\nb) FALSCH – Der Grad der Unabhängigkeit der Tester spielt keine Rolle bei den Endekriterien (vgl. CTFL CORE Lehrplan 2018; Abschn. 5.2.3).\n\nc) FALSCH – „Grad der Produktvollständigkeit“ ist kein typisches Endekriterium (vgl. CTFL CORE Lehrplan 2018; Abschn. 5.2.3).\n\nd) FALSCH – Die „Qualifikation der Tester“ ist kein typisches Endekriterium (vgl. CTFL CORE Lehrplan 2018, Abschn. 5.2.3).',
'',5,1],
['Welches der folgenden Elemente ist NICHT in einem Testabschlussbericht enthalten?',
'Definition der Endekriterien (Definition-of-Done)',
'Abweichungen von der Testvorgehensweise',
'Messung des tatsächlichen Fortschritts im Vergleich zu den Endekriterien',
'Bewertung der Qualität des Testobjekts',
1,
'FL-5.3.2 (K2) Zweck, Inhalte und Zielgruppen für Testberichte zusammenfassen können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Diese Informationen wurden bereits vorher im Testkonzept definiert (Endekriterien in CTFL CORE Lehrplan 2018, Abschn. 1.4.3, Arbeitsergebnisse der Testplanung; sind aber nicht Bestandteil des Testabschlussberichts (CTFL CORE Lehrplan 2018, Abschn. 5.3.2, „Typische … Testabschlussberichte … enthalten“).\n\nb) FALSCH – Diese Informationen sind in einem Testbericht enthalten, siehe CTFL CORE Lehrplan 2018; Abschnitt 5.3.2, „Typische … Testabschlussberichte … enthalten“, Aufzählungspunkte 2 und 3: Informationen darüber, was während eines Testzeitraums passiert ist, und welche Abweichungen es gab.\n\nc) FALSCH – Diese Informationen sind in einem Testbericht enthalten, siehe CTFL CORE Lehrplan 2018; Abschnitt 5.3.2, Aufzählungspunkt 4 und 6:\n• Stand der Tests und Produktqualität in Bezug auf die Endekriterien oder die Definition-of-Done (Aufzählungspunkt 4)\n• Metriken über Fehlerzustände, Testfälle, Testüberdeckung, Aktivitätsfortschritt und Ressourcenverbrauch (bspw. wie in Abschnitt 5.3.1 Beim Testen verwendete Metriken beschrieben) (Aufzählungspunkt 6)\n\nd) FALSCH – Diese Informationen sind in einem Testbericht enthalten, siehe CTFL CORE Lehrplan 2018; Abschnitt 5.3.2, 1. Aufzählung, 4. Aufzählungspunkt, und 2. Aufzählung, 4. Aufzählungspunkt.',
'',5,1],
['Welche vier gängigen Arten von Teststrategien/Vorgehensweisen wurden in diesem Testkonzept umgesetzt?',
'analytisch, methodisch, regressionsvermeidend und reaktiv',
'analytisch, standardkonform, beratend und reaktiv',
'analytisch, methodisch, standardkonform und beratend',
'methodisch, beratend, regressionsvermeidend und reaktiv',
2,
'FL-5.2.2 (K2) Zwischen verschiedenen Teststrategien unterscheiden können.\nBegründung: (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\nDie Zuordnung der Punkte 1 bis 4 zu Vorgehensweisen/Ansätze gemäß Abschnitt 5.2.2 im CTFL CORE Syllabus 2018 ist nur bei Option b) KORREKT.\n\nDie Zuordnungen lassen sich wie folgt begründen:\n\n1.: Vorgehensweise/Ansatz 3 ist analytisch; siehe CTFL CORE Syllabus 2018, Abschnitt \n\n5.2.2, erster Aufzählungspunkt, 2. Satz: Risikobasiertes Testen ist ein Beispiel für eine analytische Vorgehensweise, bei der Tests auf Grundlage der Risikostufe entworfen und priorisiert werden.“\n\n2.: Vorgehensweise/Ansatz 2 ist standardkonform, denn die Regelungsalgorithmen wurden gegen den branchenspezifischen Standard der Energiesparverordnung geprüft (siehe CTFL CORE Syllabus 2018, Abschnitt 5.2.2, vierter Aufzählungspunkt).\n\n3.: Vorgehensweise/Ansatz 4 ist abgeleitet (oder beratend); siehe CTFL CORE Syllabus 2018, Abschnitt 5.2.2, 5. Aufzählungspunkt: „Diese Art der Teststrategie wird vorrangig durch Beratung, Anleitung oder Anweisungen von Stakeholdern, Fachexperten oder Technologieexperten bestimmt, die von außerhalb des Testteams oder sogar von außerhalb des Unternehmens kommen können.“\n\n4.: Vorgehensweise/Ansatz 1 ist reaktiv; siehe CTFL CORE Syllabus 2018, Abschnitt 5.2.2, 7. (letzter) Aufzählungspunkt, letzter Satz: „Exploratives Testen ist eine gängige Vorgehensweise in reaktiven Strategien.“, wobei das explorative Testen der Kategorie erfahrungsbasiertes Testen zugeordnet ist (siehe CTFL CORE Syllabus 2018, Abschnitte 4.4 und 4.4.2).',
'https://i.imgur.com/l3BspUz.png',5,1],
['Welcher der folgenden Punkte kennzeichnet einen auf Metriken basierenden Ansatz für die Testaufwandsschätzung?',
'Budget, das von einem früheren, ähnlichen Testprojekt verwendet wurde.',
'Übergreifende Erfahrung aus gesammelten Interviews mit Testmanagern.',
'Im Testteam abgestimmte Aufwandsschätzung für die Testautomatisierung.',
'Von den Fachexperten gesammelte durchschnittliche Kalkulationen.',
1,
'FL-5.2.6 (K2) Den Unterschied zwischen zwei Schätzverfahren erklären können: das metrikenbasierte Verfahren und das expertenbasierte Verfahren\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – siehe CTFL CORE Lehrplan 2018; Abschnitt 5.2.6, erster Aufzählungspunkt: „Das metrikbasierte Verfahren: Schätzung des Testaufwands auf Basis von Metriken früherer ähnlicher Projekte oder auf Basis von typischen Werten“.\n\nb) FALSCH – Dies ist das expertenbasierte Verfahren: „Schätzung des Testaufwands basierend auf der Erfahrung der für die Testaufgaben zuständigen Person oder von Experten“ (siehe CTFL CORE Lehrplan 2018; Abschnitt 5.2.6, zweiter Aufzählungspunkt).\n\nc) FALSCH – Dies ist ein expertenbasiertes Verfahren. „(…) ein Beispiel für das expertenbasierte Verfahren, da Teammitglieder den Aufwand schätzen …“ (vgl. CTFL CORE Lehrplan 2018; Abschnitt 5.2.6, 2. Absatz, letzter Satz).\n\nd) FALSCH – Dies ist das expertenbasierte Verfahren: „Schätzung des Testaufwands basierend auf der Erfahrung der für die Testaufgaben zuständigen Person oder von Experten“ (siehe CTFL CORE Lehrplan 2018; Abschnitt 5.2.6, zweiter Aufzählungspunkt).',
'',5,1],
['Welche Reihenfolge der Testausführung berücksichtigt die dargestellten Abhängigkeiten?',
'R1 -> R3 -> R4 -> R7 -> R2 -> R5 -> R6',
'R1 -> R3 -> R2 -> R4 -> R7 -> R5 -> R6',
'R1 -> R3 -> R2 -> R5 -> R6 -> R4 -> R7',
'R1 -> R2 -> R5 -> R6 -> R3 -> R4-> R7',
3,
'FL-5.2.4 (K3) Wissen über Priorisierung sowie technische und logische Abhängigkeiten anwenden können, um die Testdurchführung für ein gegebenes Testfallset zu planen.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3\n\na) FALSCH – R4 ist abhängig von R2, also sollte R2 vor R4 getestet werden.\n\nb) FALSCH – R4 ist abhängig von R2, R5 und R6, also sollten R5 und R6 vor R4 getestet werden.\n\nc) KORREKT – Die Tests sind in einer Reihenfolge festgelegt, welche alle 7 Abhängigkeiten berücksichtigt: R1 -> R3; R1 -> R2; R2 -> R5; R2 -> R6; R3 -> R2; R4 von R2, R5 und R6 abhängig; R7 von R2, R5 und R6 abhängig\n\nd) FALSCH – R2 ist abhängig von R3, also sollte R3 vor R2 getestet werden.',
'https://i.imgur.com/FL98A08.png',5,1],
['Welche Information wurde in dem dargestellten Fehlerbericht vergessen?',
'Tatsächliches Testergebnis',
'Identifikation der getesteten Softwareversion',
'Status des Fehlerzustands',
'Ideen zur Verbesserung des Testfalls',
2,
'FL-5.6.1 (K3) Einen Fehlerbericht schreiben können, der einen während des Testens gefundenen Fehler enthält.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Das Testergebnis („Temperatur des Getränks zu niedrig (weniger als 40 ºC)“) steht in der kurzen Zusammenfassung.\n\nb) KORREKT – Beim Testen verschiedener Softwareversionen sind die Informationen zur Identifizierung notwendig (vgl. CTFL CORE Lehrplan 2018; Abschnitt 5.6; Absatz „Ein Fehlerbericht … enthält …:“, 4.Aufzählungspunkt).\n\nc) FALSCH – Sie schreiben gerade den Fehlerbericht, daher ist der Status per Definitionautomatisch offen.\n\nd) FALSCH – Diese Informationen sind für den Tester nützlich, müssen aber nicht in den Fehlerbericht aufgenommen werden (vgl. CTFL CORE Lehrplan 2018; Abschnitt 5.6; Absatz „Ein Fehlerbericht … enthält …:“).',
'https://i.imgur.com/IHw4YGs.png',5,1],
['Welche der folgenden Aussagen beschreibt am EHESTEN einen Vorteil für die Nutzung eines Testausführungswerkzeugs.',
'Es ist einfach, Regressionstests zu erstellen.',
'Es ist einfach, die Versionen von Testobjekten zu kontrollieren.',
'Es ist einfach, Testfälle für Zugriffssicherheitstests zu entwerfen.',
'Es ist einfach, Regressionstests durchzuführen.',
4,
'FL-6.1.2 (K1) Nutzen und Risiken der Testautomatisierung identifizieren können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Die Vorteile liegen nicht in der Erstellung von Regressionstests, sondern in deren Ausführung.\n\nb) FALSCH – Dies geschieht mit Hilfe von Konfigurationsmanagementwerkzeugen.\n\nc) FALSCH – Dies erfordert spezielle Werkzeuge.\n\nd) KORREKT – CTFL CORE Lehrplan 2018; Abschnitt 6.1.2: Durch die „Reduktion von sich wiederholender manueller Arbeit (z. B.Durchführung von Regressionstests, Aufsetzen oder Abbau von Testumgebungen, wiederholte Eingabe der gleichen Testdaten und Prüfung gegen Programmierrichtlinien) und dadurch Zeiteinsparung.“',
'',6,1],
['Welche der folgenden Testwerkzeuge sind für Entwickler besser geeignet als für Tester?',
'Anforderungsmanagementwerkzeuge',
'Konfigurationsmanagementwerkzeuge',
'Statische Analysewerkzeuge',
'Performanztestwerkzeuge',
3,
'FL-6.1.1 (K2) Testwerkzeuge gemäß ihrem Zweck und den Testaktivitäten, die sie unterstützen, klassifizieren können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Anforderungsmanagementwerkzeuge sind gem. CTFL CORE Lehrplan 2018, Abschnitt 6.1.1 nicht insbesondere für Entwickler geeignet (kein Zusatz „(E)“).\n\nb) FALSCH – Konfigurationswerkzeuge sind gem. CTFL CORE Lehrplan 2018, Abschnitt 6.1.1 nicht insbesondere für Entwickler geeignet (kein Zusatz „(E)“).\n\nc) KORREKT – Statische Analysewerkzeuge sind gem. CTFL CORE Lehrplan 2018, Abschnitt 6.1.1 insbesondere für Entwickler geeignet, siehe Zusatz „(E)“.\n\nd) FALSCH – Performanztestwerkzeuge sind gem. CTFL CORE Lehrplan 2018; Abschnitt 6.1.1 nicht insbesondere für Entwickler geeignet (kein Zusatz „(E)“).',
'',6,1],


['Welche der folgenden Aussagen beschreibt AM BESTEN einen der sieben Grundsätze des Software-Testens?',
'Mit automatisiertem Testen ist es möglich alles zu testen.',
'Vollständiges Testen ist - mit genügend Anstrengung und Werkzeugunterstützung - für alle Arten von Software praktikabel.',
'Es ist normalerweise unmöglich, alle Ein-Ausgabe-Kombinationen für ein Software-System zu testen.',
'Der Zweck des Testens ist es, die Abwesenheit von Fehlern nachzuweisen.',
3,
'Begründung:\n\na) FALSCH – Erschöpfendes Testen ist unmöglich. Egal, ob manuell oder automatisiert. (Abschn. 1.3, Grundsatz 2). \n\nb) FALSCH – Erschöpfendes Testen ist unmöglich, egal wieviel Aufwand wir in den Test investieren. (Abschn. 1.3, Grundsatz 2). \n\nc) KORREKT – Grundsatz 2 (Abschn. 1.3) besagt: “Ein vollständiger Test, bei dem alle möglichen Eingabewerte und deren Kombinationen ... ausgeführt werden, ist nicht möglich, mit Ausnahme von sehr trivialen Testobjekten.” \n\nd) FALSCH – Diese Aussage widerspricht dem Grundsatz 1 (Abschn. 1.3): “Mit Testen wird das Vorhandensein von Fehlerzuständen nachgewiesen. Mit Testen lässt sich nicht beweisen, dass keine Fehlerzustände im Testobjekt vorhanden sind."',
'',1,2],
['Welche der folgenden Aussagen beschreibt ZUTREFFEND ein gültiges Ziel für ein Testteam?',
'Es soll ermittelt werden, ob genügend Komponententests im Systemtest ausgeführt wurden.',
'Es sollen so viele Fehlerwirkungen wie möglich aufgedeckt werden, so dass die Fehlerursachen lokalisiert und korrigiert werden können.',
'Es soll aufgezeigt werden, dass alle möglichen Fehlerzustände identifiziert wurden.',
'Es soll aufgezeigt werden, dass alle verbleibenden Fehlerzustände keine Fehlerwirkungen verursachen werden.',
2,
'Begründung:\n\na) FALSCH – Komponententest ist nicht Teil des Systemtest. (Abschn. 2.2.1 und 2.2.3).\n\nb) KORREKT – Diese ist die Hauptaufgabe eines Testteams. (Abschn. 1.2, Ziele, 1. dot).\n\nc) FALSCH – Grundsatz 1 besagt, dass vollständiges Testen unmöglich ist, und es kann nicht bewiesen werden, dass alle Fehlerzustände identifiziert wurden. \n\nd) FALSCH – Um eine Einschätzung treffen zu können, ob ein Defekt einen Fehler verursacht oder nicht, muss man den Fehlerzustand zunächst erkennen. Zu sagen, dass verbleibende Fehlerzustände keine Fehlerwirkungen verursachen, bedeutet implizit, dass alle Fehlerzustände gefunden wurden. Dies widerspricht erneut Grundsatz 1.',
'',1,2],
['Welche der folgenden Aktivitäten ist Teil der Hauptaktivität „Testanalyse und Testentwurf“ im Fundamentalen Testprozess?',
'Definition der Testziele',
'Review der Testbasis',
'Erstellen von Testsuiten basierend auf dem Testablauf',
'Analyse der „Lessons learned“ zur Prozessverbesserung',
2,
'Begründung:\n\na) FALSCH – diese Aktivität wird in der Hauptaktivität “Testplanung” durchgeführt (Abschnitt 1.4.1, Satz 1). \n\nb) KORREKT – diese Aktivität wird in der Hauptaktivität “Testanalyse und Design” durchgeführt. (Abschnitt 1.4.2; 1. dot)\n\nc) FALSCH – diese Aktivität wird in der Hauptaktivität “Testrealisierung und Testdurchführung“ durchgeführt (Abschnitt 1.4.3; 3. dot) \n\nd) FALSCH – diese Aktivität wird in der Hauptaktivität “Abschluss der Testaktivitäten” durchgeführt (Abschnitt 1.4.5); 6. dot)',
'',1,2],
['Nachfolgend finden Sie eine Liste von Problemen, die während des Testens oder im Betrieb beobachtet werden können. Welches Problem ist eine Fehlerwirkung?',
'Das Produkt stürzte ab, als der Benutzer eine Option in einer Dialogbox auswählte.',
'Eine kompilierte Quellcodedatei wurde in der falschen Version zum Build hinzugefügt.',
'Der Berechnungsalgorithmus verwendet die falschen Eingangsvariablen.',
'Der Entwickler hat die Anforderungen an den Algorithmus falsch interpretiert.',
1,
'Begründung:\n\na) KORREKT – Ein Absturz ist vom Anwender deutlich spürbar. Ein Ausfall ist eine äußere Manifestation eines Fehlerzustands, d.h. eine Fehlerwirkung.\n\nb) FALSCH – Diese Art von Fehlern (Fehlhandlungen) wird nicht unbedingt zu einer sichtbaren oder spürbaren Fehlerwirkung führen; zum Beispiel wenn die Änderungen in der neuen Version der Quelldatei nur in den Kommentaren vorgenommen wurden.\n\nc) FALSCH – Verwendung von falschen Eingabevariablen wird nicht unbedingt zu einer sichtbaren oder spürbaren Fehlerwirkung führen; zum Beispiel, wenn niemand diesen speziellen Algorithmus verwendet; oder wenn die falsche Eingabevariable einen ähnlichen Wert wie die richtige Eingabevariable hat; oder wenn das FALSCHE Resultat des Algorithmus nicht verwendet wird. "Fehler in Software, Systemen oder Dokumenten können, müssen aber nicht zu einer Fehlerwirkung führen." (Abschnitt 1.1.2, 1. Absatz, letzter Satz).\n\nd) FALSCH – Diese Art von Fehlern wird nicht notwendigerweise zu einer Fehlerwirkung führen; zum Beispiel, wenn niemand diesen speziellen Algorithmus verwendet.',
'',1,2],
['Welche der folgenden Einstellungen, Qualifikationen oder Handlungen führen zu Problemen (oder Konflikten) innerhalb von gemischten Tester-Entwickler-Teams, wenn sie in Reviews und Tests beobachtet werden?',
'Tester und Entwickler sind neugierig und fokussiert genug, um Fehler zu finden.',
'Tester und Entwickler sind genügend qualifiziert, um Fehlerwirkungen und Fehlerzustände zu finden',
'Tester und Entwickler kommunizieren Fehler als Kritik an Personen und nicht als Kritik an dem Software-Produkt.',
'Tester erwarten, dass Fehlerzustände im Software-Produkt existieren, welche von Entwicklern nicht gefunden und behoben wurden.',
3,
'Begründung:\n\na) FALSCH. Das ist keine Situation, die zu Konflikten führt. Tester und Entwickler sollten fokussiert sein, Fehler zu finden.\n\nb) FALSCH. Das stimmt, es gibt deswegen keine Probleme.\n\nc) KORREKT. Laut Lehrplan sollten Entwickler und Tester neutral und sachbezogen kommunizieren und Kritik an verantwortlichen Personen vermeiden (Abschn. 1.5, 9. Absatz, 2. dot), weil das zu Konflikten innerhalb des Teams führt.\n\nd) FALSCH. Die Rolle des Testers im Team ist es, Fehler im Softwareprodukt zu finden, die nicht von den Entwicklern gefunden und behoben wurden. Das ist bei sachbezogener Kommunikation kein Problem.',
'',1,2],
['Welche der folgenden Aussagen sind WAHR?',
'A, B und C sind wahr; D ist falsch.',
'A ist wahr; B, C und D sind falsch.',
'A und C sind wahr, B und D sind falsch.',
'C und D sind wahr, A und B sind falsch.',
1,
'Begründung:\n\nA. WAHR. Softwaretests sind erforderlich, um die vertraglichen und gesetzlichen Anforderungen zu erfüllen. (Abschn. 2.2.4, regulatorischer und vertraglicher Abnahmetest).\n\nB. WAHR. Softwaretests spielen bei der Beurteilung der Qualität eines Produktes eine wesentliche Rolle. (Lernziel LO-1.1.4; Abschn. 1.1.3, 1. Absatz; Abschn. 1.1.4, 2. Absatz; Abschn. 1.5, letzte Aufzählung, 1. dot).\n\nC. WAHR. Eines der Hauptziele ist es das Risiko von Fehlerzuständen (in der Betriebsumgebung) zu reduzieren. (Abschn. 1.2, Ziele 1 und 4).\n\nD. FALSCH. Es ist nicht möglich zu beweisen, dass keine Fehler vorhanden sind. (Abschn. 1.3, Grundsatz 1), insbesondere nicht für nicht triviale Testobjekte, bei denen kein „vollständiger Test“ möglich ist (Abschn. 1.3, Grundsatz 2).\n\nDeshalb gilt: \n\na.) ist korrekt. weil genau A, B und C wahr sind.\n\nb) ist falsch, weil B und C nicht falsch (sondern wahr) sind.\n\nc) ist falsch, weil B nicht falsch (sondern wahr) ist.\n\nd) ist falsch, weil D nicht wahr (sondern falsch) ist und weil A und B wahr (und nicht falsch) sind.',
'https://i.imgur.com/KaP4FeF.png',1,2],
['Welche der folgenden Aussagen beschreibt den Unterschied zwischen Testen und Debuggen richtig?',
'Testen identifiziert die Ursache von Fehlerwirkungen. Debuggen analysiert die Fehlerzustände und schlägt Präventionsmaßnahmen vor.',
'Dynamische Tests zeigen Fehlerwirkungen auf, die durch Fehlerzustände verursacht wurden. Debuggen findet, analysiert und beseitigt die Ursachen von Fehlerwirkungen.',
'Testen entfernt Fehlerzustände. Debugging identifiziert die Ursachen von Fehlerwirkungen.',
'Dynamische Tests verhindern die Ursache von Fehlerwirkungen. Debugging entfernt die Fehlerwirkungen.',
2,
'Begründung:\n\na) FALSCH. Durch Testen können nicht die Ursachen von Fehlerwirkungen identifiziert werden, sondern nur durch Debugging (Abschn. 1.2, 2.letzter Absatz, 3. Satz).\n\nb) KORREKT. Dynamisches Testen zeigt Fehlerwirkungen auf, die durch Fehlerzustände verursacht wurden. Durch Debuggen können die Ursachen von Fehlerwirkungen analysiert und beseitigt werden. (Abschn. 1.2, 2.letzter Absatz).\n\nc) FALSCH. Durch Testen werden keine Fehlerzustände entfernt, sondern nur durch Debugging (Abschn. 1.2, 2.letzter Absatz, 3. Satz).\n\nd) FALSCH. Durch dynamische Tests können die Ursachen von Fehlerwirkungen (d.h. Fehlerzustände) nicht verhindert werden, sondern nur das Vorhandensein von Fehlerzuständen nachgewiesen werden (Abschn. 1.3, Grundsatz 1).',
'',1,2],
['Welche der folgenden Aussagen beschreibt AM BESTEN nicht-funktionales Testen?',
'Nichtfunktionales Testen ist der Testprozess eines integrierten Systems, welcher prüft, ob das System die spezifizierten Anforderungen erfüllt.',
'Nichtfunktionales Testen ist der Testprozess zur Überprüfung der Konformität eines Systems mit den Programmierkonventionen.',
'Nichtfunktionales Testen ist das Testen ohne Kenntnis der internen Struktur eines Systems.',
'Nichtfunktionales Testen ist das Testen von Systemmerkmalen wie Benutzbarkeit, Zuverlässigkeit oder Änderbarkeit.',
4,
'Begründung:\n\na) FALSCH, dies ist die Definition für einen Systemtest. (Abschn. 2.2.3, Testbasis, 1. dot).\n\nb) FALSCH, dies ist die Aufgabe der werkzeuggestützten statischen Analyse (Abschn. 3.3, Typische Fehlerzustände, 2. dot, und Abschn. 6.1.4, statische Analysewerkzeuge, 1. Satz).\n\nc) FALSCH, dies ist die Definition für einen Black-Box Test (Abschn. 4.2, Hintergrund, 3. Absatz („Black-Box-Verfahren ...“)\n\nd) KORREKT, nicht-funktionales Testen beinhaltet u.a. das Testen gegen die Qualitätsmerkmale Benutzbarkeit, Zuverlässigkeit und Änderbarkeit. (Abschn. 2.3.2, 1. Satz).',
'',2,2],
['Was ist eine wichtige Tätigkeit bei der Arbeit mit Softwareentwicklungsmodellen?',
'Falls nötig, sollten die Modelle auf Projekt- und Produkteigenschaften angepasst werden.',
'Das Wasserfall-Modell auswählen, weil es das bewährteste Modell ist.',
'Mit dem V-Modell beginnen und dann entweder auf iterative oder inkrementelle Modelle wechseln.',
'Die Organisation auf das gewählte Modell anpassen und nicht umgekehrt.',
1,
'Begründung:\n\na) KORREKT – Modelle stellen generelle Richtlinien bereit – nicht einen Schritt-für-Schritt Prozess, der zu befolgen ist. (Abschn. 2.1, letzter Absatz).\n\nb) FALSCH – Das Wasserfallmodell ist nur eines der mögliche Modelle, die von einem Team ausgewählt werden können. Es kommt im Lehrplan nicht vor, wird also erst recht nicht „als bewährtes Modell“ empfohlen.\n\nc) FALSCH – Das V-Modell (Abschn. 2.1.1) als sequentielles Modell ist nicht kompatibel mit den iterativ-inkrementellen Modellen (Abschn. 2.1.2).. Deshalb macht die beschriebene Reihenfolge keinen Sinn.\n\nd) FALSCH – Modelle werden passend zu einer Situation und einem Projekt ausgewählt und nicht umgekehrt (Abschn. 2.1, letzter Absatz).',
'',2,2],
['Welches der folgenden Merkmale ist ein „Merkmal des guten Testens“ und gilt für alle Softwareentwicklungsmodelle?',
'Der Abnahmetest ist immer die letzte angewendete Teststufe.',
'Alle Teststufen sind für jedes einzelne entwickelte Feature geplant und abgeschlossen.',
'Sobald die erste Komponente ausgeführt werden kann, werden die Tester beteiligt.',
'Für jede Entwicklungstätigkeit gibt es eine korrespondierende Testaktivität.',
4,
'Begründung:\n\na) FALSCH – Dies ist richtig für Projekte mit Entwicklungsmodellen, die einen Akzeptanztest haben. Manche Projekte/Modelle haben diese Teststufe aber nicht (siehe Abschnitt 2.1 des Lehrplans); durch die Ergänzung „immer“ ist klar das die Aussage FALSCH ist.\n\nb) FALSCH – In einigen Fällen werden Teststufen in Entwicklungsmodellen nicht benötigt; weil es im konkreten Projekt eine Konstellation geben kann in der die Anwendung einer Teststufe keinen Sinn macht. Zum Beispiel: Wenn Komponenten von Lieferanten zugekauft wurden oder als Bibliothek zugekauft wurden, ist für diese Komponenten kein Komponententest durchzuführen.\n\nc) FALSCH – Tester sollten bereits früher involviert werden bevor die Implementierung abgeschlossen wurde. Zum Beispiel: Tester sollten in das Review der Anforderungsspezifikationen involviert werden. (vgl. Abschn. 1.4.2, 1. dot).\n\nd) KORREKT – “In jedem Entwicklungslebenszyklus findet man einige Charakteristika für gutes Testen: Zu jeder Entwicklungsaktivität gibt es eine zugehörige Aktivität im Testen.” (Abschnitt 2.1.3), 1. dot)',
'',2,2],
['Wozu werden beispielsweise Wartungstests verwendet?',
'Zur Fehlerkorrektur während der Entwicklungs- und Debugging-Phase eines neuen Systems.',
'Für Tests bei Erweiterungen eines produktiv eingesetzten Systems.',
'Für die Verfolgung von Beschwerden über die Systemqualität während des Anwender-Abnahmetests.',
'Zur Integration von Funktionen während der Entwicklung eines neuen Systems.',
2,
'Begründung:\n\na) FALSCH – Testen eines neuen Systems ist kein „Wartungstest” (Abschn. 2.4, Absätze 1 bis 3).\n\nb) KORREKT –Test eines Systems nach einer Änderung (z.B. der Umgebung) wird als „Wartungstest“ bezeichnet (Abschn. 2.4, 1. Absatz, letzter Satz, und 2. Absatz, 1. Satz).\n\nc) FALSCH – Der Umgang mit Beschwerden während eines Abnahmetest ist kein „Wartungstest“. Der setzt erst nach der Abnahme und Inbetriebnahme des Systems ein (vgl. Abschn. 2.4, 1. Absatz).\n\nd) FALSCH – Integration von neuen Funktionen während der Entwicklung ist kein „Wartungstest“. sondern erfordert Integrationstests (vgl. Abschn. 2.2.2).',
'',2,2],
['Welche der folgenden Aussagen sind WAHR?',
'I und II sind wahr;',
'I, III und V sind wahr;',
'III und IV sind wahr;',
'II, IV und V sind wahr;',
3,
'Begründung:\n\nAussage I ist FALSCH – Ein Regressionstest ist der wiederholte Test eines bereits getesteten Programms nach einer Änderung. Ziel ist es nachzuweisen, dass durch die Änderungen keine Fehlerzustände eingebaut wurden (Abschn. 2.3.4, Absatz 1).\n\nAussage II ist FALSCH: Sie beschreibt einen „Fehlernachtest”(Abschn. 2.3.4, 1. Absatz).\n\nAussage III ist WAHR: Regressionstestsuiten werden oft wiederholt und ändern sich eher selten. Daher sind Regressionstests bevorzugte Kandidaten für die Automatisierung (Abschn. 2.3.4, letzter Absatz).\n\nAussage IV ist WAHR: Dies ist die Definition von Regressionstests (Abschn. 2.3.4, 2. Absatz, Satz 2).\n\nAussage V ist FALSCH: “Regressionstests können in allen Teststufen durchgeführt werden ...“ (Abschn. 2.3.4, letzter Absatz)\n\nAlso gilt:\n\na) FALSCH, da I und II falsch sind\n\nb) FALSCH, da I und V falsch sind\n\nc) KORREKT, da III und IV wahr sind\n\nd) FALSCH, da II und V falsch sind',
'https://i.imgur.com/DiPtdU1.png',2,2],
['Welche der folgenden Aussagen zum Vergleich zwischen Komponententest und Systemtest ist WAHR?',
'Komponententests überprüfen die Funktion von Komponenten, Programmobjekten und Klassen, die separat prüfbar sind, während Systemtests die Schnittstellen zwischen den Komponenten und Wechselwirkungen mit anderen Teilen des Systems überprüfen.',
'Testfälle für den Komponententest werden z. B. von den Komponentenspezifikationen abgeleitet, während Testfälle für den Systemtest z. B. von Anforderungsspezifikationen, funktionalen Spezifikationen und Anwendungsfällen abgeleitet werden.',
'Komponententests konzentrieren sich nur auf die funktionalen Eigenschaften, während Systemtests sich auf die funktionalen und nicht-funktionalen Eigenschaften konzentrieren.',
'Komponententests sind in der Verantwortung der Tester, während die Systemtests in der Regel in der Verantwortung der Benutzer des Systems liegen.',
2,
'Begründung:\n\na) FALSCH: Systemtests testen nicht die Schnittstellen und Wechselwirkungen zwischen den Komponenten und anderen Teilen des Systems; das ist Ziel von Integrationstests (vgl. Abschn. 2.2.2).\n\nb) KORREKT: Abschn. 2.2.1 (Komponententest), Testbasis, 1. dot; Abschn. 2.2.3 (Systemtest), Testbasis, 1. bis 3. dot.\n\nc) FALSCH: Komponententests konzentrieren sich nicht nur auf funktionale, sondern auch auf nicht-funktionale Aspekte (vgl. Abschn. 2.2.1, 2. Absatz nach „Typische Testobjekte“).\n\nd) FALSCH: Komponententests werden auch von Entwicklern durchgeführt (Abschn. 2.2.1, 3. Absatz nach „Typische Testobjekte“, Satz 2), wohingegen sich Tester mit Systemtests befassen (vgl. Abschn. 2.2.3, 4. Absatz nach „Typische Testobjekte“, Satz 2)',
'',2,2],
['Welches sind die Hauptaktivitäten eines formalen Reviews?',
'Initialisierung, Nachverfolgung, Individuelle Vorbereitung, Reviewsitzung, Überarbeitung, Nachbereitung.',
'Planung, individuelle Vorbereitung, Reviewsitzung, Überarbeitung, Abschluss, Nachbereitung.',
'Planung, Kick-off, Individuelle Vorbereitung, Reviewsitzung, Überarbeitung, Nachbereitung.',
'Individuelle Vorbereitung, Reviewsitzung, Überarbeitung, Abschluss, Nachbereitung, Grundursachenanalyse.',
3,
'Begründung:\n\na) FALSCH: Planung und Kick-off fehlen (vgl. Abschn. 3.2.1), Initialisierung und Nachverfolgung (vgl. Abschn. . 3.2.1) gehören nicht dazu;\n\nb) FALSCH: Kick-off fehlt (vgl. Abschn. 3.2.1);\n\nc) KORREKT (vgl. Abschn. 3.2.1);\n\nd) FALSCH: Planung fehlt (vgl. Abschn. 3.2.1); Grundursachenanalyse (vgl. Advanced Level Syllabus Testmanager, Abschn. 2.3.1.4 „Risikomanagement im Softwarelebenszyklus“, Absatz 2, Satz 4) gehört z.B. nicht dazu.',
'',3,2],
['Welche der unten aufgeführten Reviewarten ist die GEEIGNETSTE zur Überprüfung sicherheitsrelevanter Komponenten in einem Software-Projekt, wenn zusätzlich auch das Review als formaler Prozess basierend auf Regeln und Checklisten nachgewiesen werden muss?',
'Informelles Review',
'Technisches Review',
'Inspektion',
'Walkthrough',
3,
'Begründung:\n\nFür die Überprüfung der sicherheitsrelevanten Komponenten in einem Software-Projekt ist ein stärker geregeltes und dokumentiertes Review als formaler Prozess basierend auf Regeln und Checklisten erforderlich, also eine Inspektion.\n\nDamit gilt:\n\na) FALSCH\n\nb) FALSCH\n\nc) KORREKT\n\nd) FALSCH',
'',3,2],
['Welche der folgenden Aussagen über die werkzeuggestützte statische Analyse ist FALSCH?',
'Die werkzeuggestützte statische Analyse kann als vorbeugende Maßnahme genutzt werden, wenn sie durch einen entsprechend angemessenen Prozess unterstützt wird.',
'Mit der werkzeuggestützten statischen Analyse können Fehlerzustände bzw. Anomalien aufgedeckt werden, die nicht so leicht durch dynamische Tests gefunden werden.',
'Die werkzeuggestützte statische Analyse kann durch frühe Fehlererkennung helfen, Kosten einzusparen.',
'Die werkzeuggestützte statische Analyse ist gut dazu geeignet, um Fehlerwirkungen in der Software zu erzwingen.',
4,
'Begründung:\n\na) FALSCH: Diese Aussage ist wahr, denn die werkzeuggestützte statische Analyse kann als vorbeugende Maßnahme verwendet werden (Abschn. 3.3, Vorteile, 2. und 6. dot).\n\nb) FALSCH: Diese Aussage ist wahr, denn werkzeuggestützte statische Analyse kann Fehlerzustände finden, die durch dynamische Tests schwer zu finden sind (Abschn. 3.3, Hintergrund, 1. Absatz, Satz 3).\n\nc) FALSCH: Diese Aussage ist wahr, denn werkzeuggestützte statische Analyse ist eine Methode, um Fehler(zustände) früh zu finden (Abschn. 3.3, Vorteile, 1. dot), was Kosten einspart.\n\nd) KORREKT: Dieser Satz ist falsch, denn während der statische Analyse können keine Fehlerwirkungen entstehen, da der Code nicht ausgeführt wird (Abschn. 3.3, Hintergrund, Satz 2).',
'',3,2],
['Welche der Aussagen ist in Bezug auf das Testziel Entscheidungsüberdeckung WAHR?',
'Die Entscheidung D wurde nicht vollständig getestet.',
'100% Entscheidungsüberdeckung ist erreicht worden.',
'Die Entscheidung E wurde nicht vollständig getestet.',
'Die Entscheidung F wurde nicht vollständig getestet.',
1,
'Begründung:\n\nIn dem Diagramm gibt es die folgenden vier Bedingungen/Entscheidungen: A, D, E, F.\n\nDer Test_1 deckt A-> B, D-> E und E-> G ab.\n\nDer Test_2 deckt A-> B, D-> E, E-> F und F-> G ab.\n\nDer Test_3 deckt A-> C, F-> C und F-> G ab.\n\nDaher wird Entscheidung A überdeckt (A-> B durch Test t_1 und A-> C durch Test_3),\n\nEntscheidung E ist überdeckt (E-> G durch Test_1 und E- > F durch Test_2),\n\nEntscheidung F ist überdeckt (F-> C durch Test_3 und F-> G durch Test_2 und Test_3).\n\nEntscheidung D ist nicht überdeckt: zwar D-> E durch Test_1 und Test_2, aber D-> F ist nicht überdeckt.\n\nDaher gilt:\n\na) KORREKT: D wurde nicht überdeckt (siehe oben);\n\nb) FALSCH: 1 von 4 Entscheidungen (D) wurde nicht überdeckt (s. oben), also gibt es nur 75% Entscheidungsüberdeckung;\n\nc) FALSCH: E wurde vollständig getestet/überdeckt (s. oben);\n\nd) FALSCH: F wurde vollständig getestet/überdeckt (s. oben)',
'https://i.imgur.com/CqJhL3L.png',4,2],
['Welche Arten von Tests sind erwähnt?',
'A und B sind erwähnt – C und D nicht.',
'A und C sind erwähnt – B und D nicht.',
'A, B und C sind erwähnt – D nicht.',
'B, C und D sind erwähnt – A nicht.',
3,
'Begründung:\n\nA) WAHR: Empfangen von Kundendaten (Satz 2) ist ein typischer funktionaler Test.\n\nB) WAHR: In der Problembeschreibung (Satz 4) heißt es: "Die bestehenden Testfälle decken 100% aller Anweisungen des entsprechenden Moduls ab"; Anweisungstest ist struktureller Test (vgl. Abschn. 4.4.1).\n\nC) WAHR: In der Problembeschreibung (Satz 5) heißt es: "Um die Korrektur zu überprüfen und eine höhere Testabdeckung zu erreichen, wurden einige neue Tests entwickelt und V ausgeführt"; das ist ein Fehlernachtest (vgl. Abschn. 2.3.4, 1. Absatz).\n\nD) FALSCH: In der Beschreibung des Problems gibt es keine Informationen über eine Leistungsüberprüfung.\n\nDaher gilt:\n\na) FALSCH, da C fehlt;\n\nb) FALSCH, da B fehlt; \n\nc) KORREKT, da A, B und C erwähnt sind;\n\nd) FALSCH, da A fehlt und D fälschlich erwähnt ist',
'https://i.imgur.com/iCC29Rt.png',4,2],
['Welche der folgenden Aussagen zum Zustandsübergangsdiagramm und der dargestellten Tabelle von Testfällen ist WAHR?',
'Die Testfälle decken sowohl gültige und ungültige Übergänge des Zustandsübergangsdiagramms ab.',
'Die Testfälle decken alle gültigen Übergänge des Zustandsübergangsdiagramms ab.',
'Die Testfälle decken nur einige der möglichen Übergänge im Zustandsübergangsdiagramm ab.',
'Die Testfälle decken Paare von Übergängen im Zustandsübergangsdiagramm ab.',
2,
'Begründung:\n\nDie vorgeschlagenen Testfälle überdecken genau alle fünf möglichen gültigen Übergänge im gegebenen Zustandsdiagramm (S1-> S2, S2-> S1, S2-> S3, S3-> S2, S3-> S1).\n\nDaher gilt:\n\na) FALSCH, da keine ungültigen Übergänge abgedeckt werden.\n\nb) KORREKT, da alle gültigen Übergänge abgedeckt werden.\n\nc) FALSCH, da alle gültigen Übergänge abgedeckt werden.\n\nd) FALSCH, da die Testfälle keine Paare von Übergängen enthalten.',
'https://i.imgur.com/2rndVdV.png',4,2],
['Welche der folgenden Aussagen zur Äquivalenzklassenbildung sind WAHR?',
'I, II und IV sind wahr; III ist falsch.',
'I ist wahr; II, III und IV sind falsch.',
'II und III sind wahr; I und IV sind falsch.',
'I und II sind wahr; III und IV sind falsch.',
4,
'Begründung:\n\nI ist wahr, denn Äquivalenzklassenbildung teilt mögliche Eingaben in Gruppen ein, bei denen erwartet wird, dass alle Elemente das gleiche Verhalten bewirken (Abschn. 4.3.1, 1. Satz).\n\nII ist wahr, denn Äquivalenzklassenbildung verwendet/bildet Klassen mit gültigen als auch mit ungültigen Daten (Abschn. 4.3.1, 2. Satz).\n\nIII ist falsch, denn Äquivalenzklassen müssen nur abgedeckt werden (Abschn. 4.3.1, 1. Absatz, 2.letzter Satz); dafür ist es genug, einen Wert aus jeder Klasse zu verwenden.\n\nIV ist falsch: Eingaben über eine GUI sind möglich, aber das ist nicht nötig.\n\nDaher gilt:\n\na) FALSCH, da IV nicht wahr ist;\n\nb) FALSCH, da II nicht falsch ist;\n\nc) FALSCH, da III nicht wahr und I nicht falsch ist;\n\nd) KORREKT, da I und II wahr und III und IV falsch sind.',
'https://i.imgur.com/IsqQgrQ.png',4,2],
['Welche der folgenden Antworten enthält nur Verfahren, die als Black-Box-Entwurfsverfahren kategorisiert werden können?',
'Äquivalenzklassenbildung, Entscheidungstabellentest, Zustandsbasierter Test und Grenzwertanalyse.',
'Äquivalenzklassenbildung, Entscheidungstabellentest, Anweisungsüberdeckungstest, Anwendungsfallbasierter Test.',
'Äquivalenzklassenbildung, Entscheidungsüberdeckungstest, Anwendungsfallbasierter Test.',
'Äquivalenzklassenbildung, Entscheidungsüberdeckungstest, Grenzwertanalyse.',
1,
'Begründung:\n\na) KORREKT, denn alle vier Verfahren sind Black-Box-Verfahren (vgl. Abschnitt 4.3).\n\nb) FALSCH, denn Anweisungsüberdeckung ist ein White-Box-Verfahren (Abschn. 4.4.1).\n\nc) FALSCH, denn Entscheidungsüberdeckung ist ein White-Box-Verfahren (Abschn. 4.4.2).\n\nd) FALSCH, denn Entscheidungsüberdeckung ist ein White-Box-Verfahren (Abschn. 4.4.2).',
'',4,2],
['Wie viele Testfälle sind notwendig?',
'3',
'5',
'2',
'4',
4,
'Begründung:\n\na) FALSCH, eine zu wenig (siehe die 4 KORREKTEN Äquivalenzklassen in d)\n\nb) FALSCH, eine zu viel (siehe die 4 KORREKTEN Äquivalenzklassen in d)\n\nc) FALSCH, zwei zu wenig (siehe die 4 KORREKTEN Äquivalenzklassen in d)\n\nd) KORREKT. Die 4 Äquivalenzklassen entsprechen der Beschreibung in der Frage; d. h. für jede Äquivalenzklasse ist mind. ein Testfall zu erstellen.\n\n1. Äquivalenzklasse: 0 ≤ Beschäftigungszeit ≤ 2,\n\n2. Äquivalenzklasse: 2 < Beschäftigungszeit < 5,\n\n3. Äquivalenzklasse: 5 ≤ Beschäftigungszeit ≤ 10\n\n4. Äquivalenzklasse: 10 < Beschäftigungszeit',
'https://i.imgur.com/YBlfdSA.png',4,2],
['Welche der folgenden Aussagen über die Vorteile der Ableitung von Testfällen aus Anwendungsfällen sind wahr und welche sind falsch?',
'A und D sind wahr; B und C sind falsch.',
'A ist wahr; B, C und D sind falsch.',
'B und D sind wahr; A und C sind falsch.',
'A, C und D sind wahr; B ist falsch.',
1,
'Begründung:\n\nSatz A ist WAHR: Anwendungsfälle beschreiben, wie Benutzer mit dem fertigen System interagieren, passen daher am besten für die Definition von Tests auf der Systemebene (Abschn. 4.3.5, 1. Absatz). Darüber hinaus gilt: „Anwendungsfälle sind für den Entwurf von Abnahmetests mit Kunden-/Anwenderbeteiligung sehr hilfreich“ (Abschn. 4.3.5, 2. Absatz, Satz 3).\n\nSatz B ist FALSCH: Anwendungsfälle können manuell ausgeführt werden, nicht nur automatisch. (Jedenfalls wird das im Lehrplan, Abschn. 4.3.5, nicht behauptet.)\n\nSatz C ist FALSCH: Auf der Komponenten-Ebene werden Testfälle „von Entwicklungsdokumenten wie einer Komponententestspezifikation, dem Softwareentwurf oder dem Datenmodell abgeleitet.“ (Abschn. 2.2.1, 2. Absatz nach „Typische Testobjekte“, Satz 2).\n\nSatz D ist WAHR, denn die Anwendungsfälle „können ... auch Fehlerzustände im Umfeld der Integration aufdecken, die durch den Test der einzelnen Komponenten nicht gefunden werden könnten“ (Abschn. 4.3.5, 2. Absatz, Satz 4).\n\nDaher gilt:\na) KORREKT, da genau A UND D wahr sind;\n\nb) FALSCH, da D wahr (und NICHT falsch) ist;\n\nc) FALSCH, da B falsch (und NICHT wahr) ist und A wahr (und nicht falsch) ist;\n\nd) FALSCH, da C falsch (und NICHT wahr) ist.',
'https://i.imgur.com/uOwnSYO.png',4,2],
['Was ist die empfohlene Grundlage für das Testen mit Fehlerangriffen?',
'Erfahrung, gesammelte Daten und Wissen über Fehlerwirkungen und -zustände',
'Eine zu Beginn des Projekts durchgeführte Risikoidentifikation',
'Von Fachexperten abgeleitete, anwendungsfallbasierte Tests',
'Erwartete Ergebnisse aus dem Vergleich mit einem bestehenden System',
1,
'Begründung:\n\na) KORREKT: "Die Liste der Fehlerzustände und Fehlerwirkungen kann erstellt werden auf der Basis von Erfahrungen, verfügbaren Daten über Fehlerzustände und Fehlerwirkungen ...“ (Abschn. 4.5, 2. Absatz, letzter Satz).\n\nb) FALSCH : Risikoidentifikation wählt die betreffenden Bereiche des Projekts aus - nicht, wie sie zu testen sind.\n\nc) FALSCH: Das Testen auf der Basis von Geschäftsprozessen zielt nicht auf mögliche Schwächen in der Software, die aus Erfahrung und Allgemeinwissen bekannt sind, was beim Test mit Fehlerangriffen der Ansatz ist (Abschn. 4.5, 2. Absatz, letzter Satz). Es versucht nur zu überprüfen, ob bestimmte Anwendungsfälle ausgeführt werden können.\n\nd) FALSCH: Der Satz beschreibt eine der Möglichkeiten, Testfälle zu ermitteln. Der Ansatz hat aber nichts spezifisches mit dem Ansatz „Fehlerangriffe“ zu tun, bei dem eine Liste der möglichen Fehlerzustände und Fehlerwirkungen auf der Basis von Erfahrungen erstellt wird (Abschn. 4.5, 2. Absatz, letzter Satz).',
'',4,2],
['Welches der folgenden Testverfahren ist AM BESTEN geeignet, wenn unzureichende Spezifikationen und Zeitdruck gegeben sind?',
'Anwendungsfallbasierter Test',
'Anweisungstest',
'Exploratives Testen',
'Entscheidungstest',
3,
'Begründung:\n\na) FALSCH, das Projekt hat eine schlechte Spezifikationen, daher gibt es nur eine geringe Möglichkeit, dass irgendwelche Anwendungsfälle bestehen.\n\nb) FALSCH: Anweisungstest ist zeitaufwendig, und es gibt Zeitdruck im Projekt.\n\nc) KORREKT: Das explorative Testen ist angebracht, wenn es schlechte Dokumentation und Zeitdruck gibt (Abschn. 4.5, Hintergrund, 3. Absatz, Satz 3).\n\nd) FALSCH: Entscheidungstest ist zeitaufwendig, und es gibt Zeitdruck im Projekt.',
'',4,2],
['Welches der folgenden Testverfahren ist ein White-Box-Testverfahren?',
'Entscheidungstests',
'Grenzwertanalyse',
'Äquivalenzklassenbildung',
'Zustandsbasierter Test',
1,
'Begründung:\n\na) KORREKT: Entscheidungstests sind ein White-Box-Verfahren (siehe Abschn. 4.4.2).\n\nb) FALSCH: Grenzwertanalyse ist ein Black-Box-Verfahren (siehe Abschn. 4.3.2).\n\nc) FALSCH: Äquivalenzklassenbildung ist ein Black-Box-Verfahren (siehe Abschn. 4.3.1).\n\nd) FALSCH: Zustandsbasierter Test ist ein Black-Box-Verfahren (siehe Abschn. 4.3.4).',
'',4,2],
['Welches Testverfahren wurde angewandt?',
'Grenzwertanalyse',
'Zustandsbasierter Test',
'Anwendungsfallbasierter Test',
'Entscheidungstabellentest',
1,
'Begründung:\n\na) KORREKT: Die angegebenen Werte sind Grenzwerte an der unteren Grenze (1) und an der oberen Grenze (INT_MAX) des gültigen Bereichs 1 bis INT_MAX bzw. Grenzwerte der ungültigen Bereiche „<1“ (0) bzw. „>INT_MAX“ (INT_MAX-1) (s. Abschn. 4.3.2, 1. Absatz).\n\nb) FALSCH: Die angegebenen Werte sind keine Zustandswerte, es gibt keine Zustandsübergänge (Abschn. 4.3.4, 1. Absatz).\n\nc) FALSCH: Die angegebenen Werte sind keine Anwendungsfälle mit Vor- und Nachbedingungen. (Abschn. 4.3.5, 1. Absatz).\n\nd) FALSCH: Die angegebenen Werte sind keine logischen Bedingungen. (Abschn. 4.3.3, 1. Satz).',
'https://i.imgur.com/IkAl3bq.png',4,2],
['Welche Testfälle können in der aufgeführten Entscheidungstabelle entfernt werden?',
'T1 und T2',
'T3 und T4',
'T7 und T8',
'T5 und T6',
4,
'Begründung:\n\na) FALSCH: Es ist mit T1 und T2 zu prüfen, ob die Prämie nicht gezahlt wird, wenn keine Ziele vereinbart/abgestimmt sind (und natürlich nicht erreicht wurden).\n\nb) FALSCH: Es ist mit T3 und T4 zu prüfen, ob die Prämie nicht gezahlt wird, wenn vereinbarte/abgestimmte Ziele nicht erreicht wurden.\n\nc) FALSCH: Es ist mit T7 und T8 zu prüfen, ob die Prämie gezahlt oder nicht gezahlt wird, wenn Ziele vereinbart und erreicht wurden und die Beschäftigungszeit länger als 1 Jahr (T7) (oder nicht, T8) ist.\n\nd) KORREKT: Die Testfälle T5 und T6 beschrieben die Situation, wobei das Ziel erreicht ist - allerdings nicht vereinbart/abgestimmt wurde. Diese Situation kann nicht auftreten, deshalb können wir die entsprechenden Tests T5 und T6 weglassen.',
'https://i.imgur.com/iYduOnj.png',4,2],
['Welche der folgenden Aussagen beschreibt AM BESTEN die Aufgabenteilung zwischen Testmanager und Tester?',
'Der Testmanager plant Testaktivitäten und wählt die Normen aus, die befolgt werden müssen, während der Tester die Werkzeuge und Steuerelemente auswählt, die verwendet werden.',
'Der Testmanager plant, organisiert und steuert die Testaktivitäten, während der Tester Testfälle spezifiziert und ausführt',
'Der Testmanager plant, überwacht und steuert die Testaktivitäten, während der Tester die Tests entwirft und über die Freigabe des Testobjekts entscheidet.',
'Der Testmanager plant und organisiert die Testdurchführung und spezifiziert die Testfälle, während die Tester die Tests priorisieren und durchführen.',
2,
'Begründung:\n\na) FALSCH: Auswahl der Werkzeuge ist eine Testmanager-Aufgabe (Abschn. 5.1.2, 10./ drittletzter dot).\n\nb) KORREKT - siehe Abschnitt 5.1.2 (Testmanager, 4. dot, Tester, 3.+5. dot).\n\nc) FALSCH: Die Entscheidung über die Freigabe des Testobjekts ist ein Aufgabe des Testmanagers (Abschn. 5.1.2, 5. dot).\n\nd) FALSCH: Der Tester muss die Testfälle spezifizieren (Abschn. 5.1.2, 3. dot).',
'',5,2],
['Welche der folgenden Risiken können als Produktrisiken kategorisiert werden?',
'Geringe Qualität der Anforderungen, des Designs, des Codes und der Testfälle.',
'Politische Probleme und Verzögerungen bei besonders komplexen Teilen des Produkts.',
'Fehleranfällige Komponenten, möglicher Schaden für den Menschen, schlechte Softwareeigenschaften.',
'Probleme bei der Definition korrekter Anforderungen, fehleranfällige Bereiche der Software oder des Systems.',
3,
'Begründung:\n\na) FALSCH: Geringe Qualitätsanforderungen sind ein Projektrisiko (Abschnitt 5.5.1, technische Aspekte, 5. dot)\n\nb) FALSCH: Alle Angaben in dieser Option sind Projektrisiken (Abschnitt 5.5.1, organisatorische Faktoren, 3. dot; technische Aspekte, 3.+4. dot)\n\nc) KORREKT: Alle Angaben sind Produktrisiken (Abschnitt 5.5.2, 1. bis 3. dot)\n\nd) FALSCH: Anforderungs-, Software- und System-Probleme sind Projektrisiken (Abschnitt 5.5.1, technische Aspekte, 1.+5. dot)',
'',5,2],
['Welche der folgenden Listen enthält nur typische Endekriterien?',
'Kennzahlen zu Zuverlässigkeit und Testüberdeckung, Testkosten, Zeitplan, Status über Fehlerbehebung und Restrisiken',
'Kennzahlen zu Zuverlässigkeit und Testüberdeckung, Grad der Unabhängigkeit der Tester und Grad der Produktvollständigkeit',
'Kennzahlen zu Zuverlässigkeit und Testüberdeckung, Testkosten, Verfügbarkeit von testbarem Code, Zeit bis Markteinführung, Grad der Produktvollständigkeit',
'Zeit bis Markteinführung, Restfehler, Qualifikation der Tester, Grad der Unabhängigkeit der Tester, Testüberdeckung und Testkosten',
1,
'Begründung:\n\na) KORREKT: siehe Abschnitt 5.2.4 (alle 5 Punkte).\n\nb) FALSCH: Der Grad der Unabhängigkeit der Tester spielt keine Rolle bei den Endekriterien (vgl. Abschn. 5.2.4).\n\nc) FALSCH: Die "Verfügbarkeit von testbarem Code" ist ein Testeingangskriterium (Abschn. 5.2.3, 3. dot).\n\nd) FALSCH: Der Grad der Unabhängigkeit der Tester sowie die Qualifikation der Tester spielt keine Rolle bei den Endekriterien (vgl. Abschn. 5.2.4).',
'',5,2],
['Wie würden Sie den Testausführungsplan, entsprechend der Abhängigkeiten der Anforderungen, aufbauen?',
'R3 -> R2 -> R1 -> R7 -> R5 -> R6 -> R4',
'R2 -> R5 -> R6 -> R4 -> R7 -> R1 -> R3',
'R1 -> R3 -> R2 -> R5 -> R6 -> R4 -> R7',
'R1 -> R2 -> R5 -> R6 -> R3 -> R4 -> R7',
3,
'Begründung:\n\na) FALSCH: Alles hängt von R1 ab, also ist jeder Testlauf, der nicht mit R1 beginnt, falsch.\n\nb) FALSCH: Begründung wie bei a).\n\nc) KORREKT: Die Tests sind in einer Reihenfolge festgelegt, welche alle Abhängigkeiten berücksichtigt.\n\nd) FALSCH: R2 ist abhängig von R3, also sollte R3 vor R2 getestet werden.',
'https://i.imgur.com/SovKcPG.png',5,2],
['Identifizieren Sie einen möglichen Vorteil des unabhängigen Testens.',
'Die Arbeit ist effizienter, da die Tester die Entwickler nicht ständig stören.',
'Unabhängige Tester sind tendenziell unvoreingenommen und finden andere Fehler als die Entwickler.',
'Unabhängige Tester brauchen keine zusätzliche Ausbildung oder Schulung.',
'Unabhängige Tester reduzieren den Ressourcen-Engpass im Fehler- und Abweichungsmanagementprozess.',
2,
'Begründung:\n\na) FALSCH: Unabhängigkeit bedeutet nicht „keine Zusammenarbeit“.\n\nb) KORREKT: Dies ist ein Grund für die Unabhängigkeit (Abschn. 5.1.1, erster Vorteil).\n\nc) FALSCH: Natürlich benötigen Tester Ausbildung und Schulung.\n\nd) FALSCH: Es gibt keine Verbindung zwischen der Unabhängigkeit der Tester und dem Engpass im Fehlermanagement- und Abweichungsmanagement-Prozess.',
'',5,2],
['Welches der folgenden Elemente wird als ein Projektrisiko eingestuft?',
'Mangel an sachkundigem Personal',
'Schlechte Softwareeigenschaften (z. B. Benutzbarkeit)',
'Fehleranfällige Software wurde geliefert.',
'Mangelhafte Zuverlässigkeit',
1,
'Begründung:\n\na) KORREKT: Knappheit von Sachkunde und Personal ist ein typisches Projektrisiko (Abschn. 5.5.1, Organisatorische Faktoren, 1. dot).\n\nb) FALSCH: Schlechte SW-Eigenschaften sind ein Produktrisiko (Abschn. 5.5.2, 3. dot).\n\nc) FALSCH: Lieferung fehleranfälliger SW ist ein Produktrisiko (Abschn. 5.5.2, 1. dot).\n\nd) FALSCH: Mangelhafte Zuverlässigkeit ist ein Produktrisiko (Abschn. 5.5.2, 3. dot).',
'',5,2],
['Als Testmanager sind Sie aufgefordert, einen Testabschlussbericht abzuliefern. Was sollten Sie gemäß IEEE-829 bezüglich Testaktivitäten in Ihrem Bericht als besonders relevant berücksichtigen?',
'Die Anzahl der ausgeführten Testfälle und Ihre Ergebnisse.',
'Eine Zusammenfassung der wichtigsten Testaktivitäten, Ereignisse und deren Status in Bezug auf die vereinbarten Ziele',
'Eine Gesamtbewertung aller Entwicklungsartefakte',
'Das empfohlene Training der Mitglieder des Testteams, um die Effektivität des Testens zu erhöhen.',
2,
'Begründung:\n\na) FALSCH: Die Anzahl der durchgeführten Testfälle und ihre Ergebnisse können in einem Testabschlussbericht nach IEEE 829 enthalten sein, aber sind kein wichtiger Teil.\n\nb) KORREKT: Der Testabschlussbericht muss Informationen zu den wichtigsten Testaktivitäten, Ereignissen und ihren Status in Bezug auf die vereinbarten Ziele enthalten (vgl. auch Lehrplan, Abschn. 5.3.2, 1. dot und dort zu Metriken, 3. dot).\n\nc) FALSCH: Die Bewertung der einzelnen Entwicklungsarbeiten ist NICHT Teil des Testabschlussberichts nach IEEE 829.\n\nd) FALSCH: Zusätzliche Ausbildung ist nicht die Information, die in dem Testabschlussbericht nach IEEE 829 enthalten sein sollte.',
'',5,2],
['Sie sind Tester in einem sicherheitskritischen Software-Entwicklungs-Projekt. Bei der Ausführung eines Tests trifft eines der erwarteten Ergebnisse nicht zu. Sie erstellen dazu einen Fehlerbericht. Welche Informationen sind am wichtigsten im Kontext einer sicherheitskritischen Entwicklung?',
'Beschreibung der Auswirkung, Problembeschreibung, Datum, Ihr Name',
'Eindeutige ID des Abweichungsberichtes, speziell benötigte Ausgangslage, Fehlerverursacher',
'Übertragene Gegenstände, Ihren Namen und Ihre Vermutung der möglichen Fehlerursachen',
'Problembeschreibung, Entwicklungsumgebung, erwartete Testergebnisse',
1,
'Begründung:\n\na) KORREKT: Die wichtigste Information, die in den Fehler- und Abweichungsbericht für kritische Software aufgenommen werden sollte, ist die Auswirkung (auf das System und die Stakeholder-Interessen, Abschn. 5.6, Informationen, dot 6 und 7). Des weiteren werden im Lehrplan genannt: meldende Organisation und Autor“ (Abschnitt 5.6) und „Beschreibung der Abweichung“ (Abschnitt 5.6).\n\nb) FALSCH: Diese Informationen können im Fehler- und Abweichungsbericht stehen, aber sie sind nicht so wichtig wie die Auswirkungen (und daher auch nicht in Abschn. 5.6 enthalten). „Fehlerverursacher“ wird lt. Lehrplan nicht erfasst. Korrekt wäre "Fehlerursache", kann bei der Fehlererfassung nicht dokumentiert werden.\n\nc) FALSCH: Der Fehler- und Abweichungsbericht sollte Sachinformationen enthalten, nicht des Testers Vermutungen über die möglichen Fehlerursachen (was daher auch nicht in Abschn. 5.6 enthalten ist). „Vermutung der möglichen Fehlerursachen“ ist nicht Bestandteil eines Fehlerberichts nach Lehrplan (Abschnitt 5.6).\n\nd) FALSCH: Diese Informationen können im Fehler- und Abweichungsbericht stehen (Abschn. 5.6, Informationen, dot 2 (erwartete Testergebnisse), dot 5 (Beschreibung der Abweichung)), aber sie sind nicht so wichtig wie die Auswirkungen. Entwicklungsumgebung“ wird gem. Lehrplan nicht bei der Fehlererfassung dokumentiert.',
'',5,2],
['Wählen Sie aus der Liste die empfohlenen Vorgehensweisen aus, um ein ausgewähltes Testwerkzeug in eine Organisation einzuführen.',
'1,3,4,5',
'2,5,6',
'2,3,4,7',
'1,6,7',
3,
'Begründung:\n\nSatz 1 ist inkorrekt: Es wird empfohlen, zunächst ein Pilotprojekt durchzuführen, bevor das Testwerkzeug schrittweise in der gesamten Organisation in Betrieb genommen wird (Abschnitt 6.3, Erfolgsfaktoren, 1. dot).\n\nSatz 2 ist KORREKT: Siehe Abschn. 6.3, 2. Absatz, Satz 1: „ Die Einführung des ausgewählten Werkzeugs in einer Organisation beginnt mit einem Pilotprojekt“. Satz 3 ist KORREKT: "Bewertung, wie das Werkzeug mit den existierenden Werkzeugen und Prozessen zusammenpasst" (Abschn. 6.3, Pilotprojekt-Ziele, 2. dot).\n\nSatz 6 ist inkorrekt: Die Kosten für den Einsatz eines Werkzeuges sind mehr als nur die Anschaffungskosten für das Werkzeug. Dies nicht zu realisieren ist eines der Risiken, die der Werkzeugbereitstellung zugeordnet sind (Abschnitt 6.2.1, Risiken, 2. dot). Satz 7 ist KORREKT: "Es wird ein Erfahrungskatalog erstellt, basierend auf den Erfahrungen aller Teams." ist einer der Erfolgsfaktoren für den Einsatz (Abschnitt 6.3, 8. Erfolgsfaktor).\n\nDaher gilt: \n\na) (1,3,4,5): FALSCH wg. 1 und 5,\n\nb) (2,5,6): FALSCH wg. 5 und 6,\n\nc) (2,3,4,7): KORREKT,\n\nd) (1,6,7): FALSCH wg. 1 und 6.',
'https://i.imgur.com/CfERLVS.png',6,2],
['Welche der folgenden Eigenschaften beschreiben AM BESTEN ein schlüsselwortgetriebenes Testausführungswerkzeug?',
'Eine Tabelle mit Testeingangsdaten, Schlüsselwörtern und den erwarteten Ergebnissen steuert die Ausführung des zu testenden Systems.',
'Aktionen von Testern, die in einem Skript aufgezeichnet wurden und mehrfach ausgeführt werden.',
'Aktionen von Testern, die in einem Skript aufgezeichnet wurden, das danach mit mehreren Sets von Test-Eingabedaten ausgeführt wird.',
'Die Möglichkeit, Testergebnisse aufzuzeichnen und sie danach mit den erwarteten Ergebnissen zu vergleichen, welche in einer Textdatei gespeichert sind.',
1,
'Begründung:\n\na) KORREKT - "In einem schlüsselwortgetriebenen Testansatz ... enthält ein Tabellenblatt zusätzlich zu den Testdaten Schlüsselwörter (auch Aktionswörter genannt), welche die auszuführenden Aktionen beschreiben" (Abschnitt 6.2.2, 5. Absatz).\n\nb) FALSCH: Das ist eine Beschreibung der Skript-Testautomatisierung (Abschn. 6.2.2, 2. Absatz).\n\nc) FALSCH: Das ist eine Beschreibung der datengetriebenen Testautomatisierung (Abschn. 6.2.2, 3. Absatz).\n\nd) FALSCH: Dies beschreibt einen Teil dessen, was ein Testautomatisierungsrahmen oder ein Vergleichswerkzeug/Komparator tut (Abschn. 6.1.6).',
'',6,2],
['Welche der folgenden Aussagen ist KEIN Ziel eines Pilotprojekts zur Werkzeug-Evaluierung?',
'Beurteilen, wie das Werkzeug mit den bestehenden Prozessen und Praktiken zusammenpasst.',
'Feststellen wie das Werkzeug und die damit verwalteten Testmittel verwendet, verwaltet, gespeichert und archiviert sowie gewartet werden.',
'Beurteilen, ob der Nutzen bei vertretbaren Kosten erreicht wird.',
'Reduzieren der Fehlerrate im Pilotprojekt.',
4,
'Begründung:\n\na) FALSCH: Der Satz ist WAHR (Abschnitt 6.3, Ziele, 2. dot)\n\nb) FALSCH: Der Satz ist WAHR (Abschnitt 6.3, Ziele, 3. dot)\n\nc) FALSCH: Der Satz ist WAHR (Abschnitt 6.3, Ziele, 4. dot)\n\nd) KORREKT: Verringerung der Zahl der Mängel ist NICHT das Ziel eines Pilotprojekts (vgl. Abschn. 6.3, Ziele).',
'',6,2],
['Unten finden Sie eine Liste möglicher Ziele zur Effizienzsteigerung einer Software-Entwicklungs- und Testorganisation. Welches dieser Ziele wird AM BESTEN durch ein Testmanagementwerkzeug unterstützt?',
'Die Rückverfolgbarkeit zwischen Anforderungen, Testfällen und Fehlerzuständen herstellen.',
'Die Fähigkeit der Tests optimieren, Fehlerwirkungen zu identifizieren.',
'Die Fehlerzustände schneller beheben.',
'Die Auswahl von Testfällen für die Testausführung automatisieren.',
1,
'Begründung:\n\na) KORREKT - denn die Rückverfolgbarkeit zwischen Anforderungen und Tests ist i.d. R. eine Funktionalität eines Testmanagementwerkzeugs (Abschn. 6.1.3, Testmanagementwerkzeuge, Satz 1).\n\nb) FALSCH - weil das nicht mit Testmanagement-Werkzeugen möglich ist, eher durch Vergleichswerkzeuge/Komparatoren (Abschn. 6.1.6).\n\nc) FALSCH - weil das nicht in erster Linie durch Testmanagement-Werkzeuge gelöst wird, sondern nur ein wenig durch Rückverfolgbarkeit unterstützt wird (Abschn. 6.1.3, Testmanagementwerkzeuge, Satz 2).\n\nd) FALSCH - weil die Auswahl der Testfälle nicht durch Testmanagementwerkzeuge unterstützt wird, sondern durch Testentwurfs- und Testausführungswerkzeuge Abschn. 6.1.5 und 6.1.6).',
'',6,2],


['Die statische Analyse kann höchstwahrscheinlich NICHT finden:',
'Die Verwendung einer Variablen bevor diese definiert wurde.',
'Unerreichbaren (“toten”) Code.',
'Speicherlecks.',
'Überschreiten der Array-Grenzen (array bound violations).',
3,
'Die Statische Analyse ist ein Prozess der ein Testobjekts (Komponente oder System) basierend auf seiner Form, seiner Struktur, seines Inhalts oder seiner Dokumentation bewertet, ohne es auszuführen.\nSpeicherlecks findet man eher bei der Ausführung des Programms, es sind jedenfalls keine typischen Fehler die man bei der statischen Analyse findet. Man kann jedoch Überschreitungen der Array-Grenzen finden, was potentiell bei der Ausführung der Software später zu Speicherlecks führen kann.',
'',3,3],
['TYPISCHERWEISE wer benutzt die statischen Analysewerkzeuge?',
'Kunden und Benutzer.',
'Entwickler und Testentwerfer.',
'Geschäfts- und System Analysten.',
'System und Abnahme Tester.',
2,
'Statische Analysewerkzeuge sind Werkzeuge für Software-Entwickler.',
'',3,3],
['Kann das Review oder die Inspektion als ein Teil des Testens betrachtet werden?',
'Nein, da sie zur Entwicklungsdokumentation gehören.',
'Nein, da sie meistens vor dem eigentlichen Test durchgeführt werden.',
'Ja, da beide helfen können Fehlerzustände zu identifizieren und die Qualität zu erhöhen.',
'Ja, Testen beinhaltet auch destruktive Tätigkeiten.',
3,
'Reviews können als ein Teil des Testens benutzt werden.',
'',3,3],
['Die Äquivalenzklassenbildung ist ________',
'ein Black-Box-Verfahren, welches von den Entwicklern verwendet wird.',
'ein Black-Box-Verfahren, welches nur im Systemtest verwendet werden kann.',
'ein Black-Box-Verfahren, welches in jeder Teststufe verwendet werden kann.',
'ein White-Box-Verfahren, welches im Komponententest verwendet werden kann.',
3,
'Äquivalenzklassenbildung\nEin Black-Box-Testentwurfsverfahren, bei dem die Testfälle im Hinblick auf Äquivalenzklassenüberdeckung entworfen werden. Grundsätzlich werden Testfälle so ausgewählt, dass jede Äquivalenzklasse mindestens einmal abgedeckt wird.',
'',4,3],
['In welcher Reihenfolge sollten Testfälle durchgeführt werden?',
'Die wichtigsten Testfälle zuerst.',
'Zunächst die schwierigsten Testfälle, damit genügend Zeit für die Behebung der Fehler bleibt.',
'Zuerst die einfachsten Testfälle, damit zunächst ein Vertrauen aufgebaut wird.',
'In der Reihenfolge wie die Testfälle ausgedacht worden sind.',
1,
'Die wichtigsten Testfälle mit der höchsten Priorität sollten zuerst ausgeführt werden. Besonders wenn andere, weitere Testfälle davon abhängen.',
'',5,3],
['6. Welcher der folgenden Punkte ist KEIN Bestandteil eines Testabschlussberichts nach IEEE Std. 829:1998?',
'Zusammenfassung und eindeutige Bezeichner',
'Zusammenfassung',
'Abweichungen',
'Anomalien',
4,
'Der Testabschlussbericht enthält:\n• Zusammenfassung der durchgeführten Tests\n• Abweichungen gegenüber den geplanten Tests\n• Auswertung der Testendekriterien\n• blockierende Faktoren\n• Testmetriken\n• verbleibende Risiken\n• Arbeitsergebnisse des Testens\n• Wiederverwendbares aus dem Test (Assets)\n• Lessons Learned',
'',5,3],
['Welcher der folgenden Punkte gilt üblicherweise NICHT als Testziel?',
'Fehlerzustände in der Software finden.',
'Wartungskosten reduzieren.',
'Vertrauen in das System erzeugen.',
'Geplante Meilensteine erreichen.',
4,
'Testziel\nEin Grund oder Zweck für den Entwurf und die Ausführung von Tests.\n\nEin Meilenstein (englisch milestone, umgangssprachlich Markstein) ist ein Ereignis von besonderer Bedeutung im Projektmanagement.',
'',5,3],
['Welche der folgenden Aussagen über unabhängiges Testen ist FALSCH?',
'Unabhängige Tester können extern organisiert sein.',
'Unabhängige Tester können ein Teil des Entwicklungsteams sein.',
'Unabhängige Tester können aus der Benutzer-Gemeinde kommen.',
'Entwickler, die den Code erstellen, können als unabhängige Tester eingesetzt werden.',
4,
'Entwickler die den Code erstellt haben sind nicht unabhängig.',
'',5,3],
['Welcher der folgenden Punkte hat KEINEN Bezug zu einem Betriebstest (operational testing)?',
'Regelmäßige Überprüfungen von Sicherheitslücken.',
'Testen der Datensicherung und Wiederherstellung.',
'Wiederherstellung nach einem Desaster (disaster recovery).',
'Zustandsbasierter Test (state transition testing).',
4,
'Betriebstest\nTest, der durchgeführt wird, um eine Komponente oder ein System in ihrer operativen Umgebung (Arbeits- bzw. Produktivumgebung) zu bewerten.\n\nDer Betriebstest soll nachweisen, dass die Software den Bedürfnissen des Unternehmens entspricht und korrekt arbeitet.',
'',0,3],
['Welcher Testwerkzeugstyp wird AM WAHRSCHEINLICHSTEN in der Entwicklung eingesetzt?',
'Testmanagementwerkzeuge.',
'Werkzeuge zur statischen Analyse.',
'Sicherheitstest-Werkzeuge.',
'Werkzeuge zur Messung der Performance.',
2,
'Testmanagementwerkzeug\nEin Werkzeug, das das Management und die Steuerung eines Testprozesses unterstützt und verschiedene Leistungsmerkmale umfasst: Management der Testmittel, zeitliche Planung der Reihenfolge der durchzuführenden Tests, Protokollierung der Ergebnisse, Fortschrittsüberwachung, Fehler- und Abweichungsmanagement und Testabschlussberichterstattung.\n\nPerformanztestwerkzeug\nEin Testwerkzeug, das Last für ein bestimmtes Testelement erzeugt, und dessen Performanz während der Testdurchführung misst und aufzeichnet.\n\nSicherheitstest-Werkzeuge\nWerden für spezielle nicht-funktionale Tests verwendet, meistens von externen Experten.',
'',6,3],
['Bei welchem der folgenden Punkte handelt es sich um einen funktionalen Test?',
'Grenzwertanalyse.',
'Benutzbarkeitstest.',
'Performanztest.',
'Wartbarkeitstest.',
1,
'Benutzerbarkeitstests, Performanztests und Wartbarkeitstests sind nicht-funktionale Tests.',
'',2,3],
['Ein Unternehmen kaufte kürzlich eine Standardanwendung (COTS -commercial off-the-shelf) um ihren Bezahldienst-Prozess zu automatisieren. Sie planen nun eine Abnahme vor der Produktivsetzung. Welcher der folgenden Punkte ist der WAHRSCHEINLICHSTE Grund für die Prüfung?',
'Um Vertrauen in die neue Anwendung zu bekommen.',
'Um Fehler in der Anwendung zu finden.',
'Um Beweise für eine Klage zu sammeln.',
'Zur Schulung der Anwender.',
1,
'Abnahmetest\nFormales Testen hinsichtlich der Benutzeranforderungen und -bedürfnisse bzw. der Geschäftsprozesse. Es wird durchgeführt, um einem Auftraggeber oder einer bevollmächtigten Instanz die Entscheidung auf der Basis der Abnahmekriterien zu ermöglichen, ob ein System anzunehmen ist oder nicht.',
'',2,3],
['Welche Testentwurfsverfahren sollte ein Tester anwenden um die abgebildeten Testziele zu erreichen? Wählen Sie aus den Antwortmöglichkeiten die RICHTIGE Kombination.',
'1Y, 2Z, 3X, 4Z.',
'1W, 2X, 3Y, 4Z.',
'1W, 2Z, 3Y, 4X.',
'1Y, 2X, 3Z, 4W.',
2,
'100% Anweisungsüberdeckung erreicht man durch "Strukturelle Testfallableitung".\n\nEine effiziente Prüfung der dokumentierten Funktionalitäten des Systems erreicht man durch "Spezifikationsbasierte Testfallableitung".\n\n"Datengetriebene Testtechniken" können die Effizienz von "Capture und Playback"-Testwerkzeugen verbessern.\n\nBei der "Erfahrungsbasierten Testfallableitung" erstellt der Tester Testfälle, die auf Erfahrungen mit dem System basieren.',
'https://i.imgur.com/Rnbr2uv.png',4,3],
['Wenn Sie in der Touristenklasse fliegen, besteht die Möglichkeit, auf die Businessklasse umzusteigen. Insbesondere dann, wenn Sie im Besitz einer Gold-Karte des Vielflieger-Programms der Fluggesellschaft sind. Wenn Sie keine Gold-Karte besitzen, dann besteht die Gefahr, dass Sie vom Flieger geworfen werden, falls dieser voll ist und Sie Ihren Check-In zu spät durchgeführt haben. Die Abbildung visualisiert diese Zusammenhänge. Folgende drei Tests wurden bereits durchgeführt: TEST EINS: "Fluggast mit einer Gold-Karte steigt zur Businessklasse auf." TEST ZWEI: "Fluggast ohne Gold-Karte bleibt in der Touristenklasse." TEST DREI: "Fluggast der aus dem Flieger geworfen wird." Welche zusätzlichen Tests werden benötigt, um eine 100%-ige Entscheidungsüberdeckung zu erreichen?',
'Ein Fluggast mit einer "Gold-Karte", der in der Touristenklasse verbleibt, und ein Fluggast ohne "Gold-Karte", der aber auf die Businessklasse umsteigt.',
'Ein Fluggast mit einer "Gold-Karte" und ein Fluggast ohne "Gold-Karte". Beide steigen auf die Businessklasse um.',
'Ein Fluggast mit "Gold-Karte" und ein Fluggast ohne "Gold-Karte". Beide verbleiben in der Touristenklasse.',
'Ein Fluggast mit "Gold-Karte", der auf Businessklasse umsteigt, und ein Fluggast ohne "Gold-Karte", der in der Touristenklasse verbleibt.',
1,
'Der Fluggast mit Gold-Karte der in der Touristenklasse verbleibt (weil die Business Class voll ist, Entscheidung #2), sowie der Fluggast ohne Gold-Karte, der auf die Businessklasse umsteigt (Entscheidung 8) sind nicht überdeckt, und müssen als Testfälle hinzugefügt werden..',
'https://i.imgur.com/dffqlMD.png',4,3],
['Welcher ist der WICHTIGSTE Unterschied zwischen metrikbasierter und expertenbasierter Testschätzung?',
'Die metrikbasierte Schätzung ist genauer als die expertenbasierte Schätzung.',
'Die metrikbasierte Schätzung verwendet historische Projektdaten, während eine expertenbasierte Schätzung auf den Erfahrungen des Projektteams beruht.',
'Die metrikbasierte Schätzung kann verwendet werden, um eine expertenbasierte Schätzung zu überprüfen, aber nicht umgekehrt.',
'Die expertenbasierte Schätzung dauert länger als die metrikbasierte.',
2,
'Metrikbasierter Ansatz: Schätzen des Testaufwands basierend auf Metriken früherer ähnlicher Projekte oder basierend auf typischen Werten.\n\nBeim expertenbasierten Ansatz werden Experten beauftragt den Testaufwand zu schätzen. Zum Beispiel die für die verschiedenen Testaktivitäten verantwortlichen Testmanager, die als Experten für ihr jeweiliges Gebiet betrachtet werden. Und daher in der Lage sind, den erwarteten Testaufwand zu schätzen.',
'',5,3],
['Welche der folgenden Aussagen ist NICHT RICHTIG? Ein Black-Box-Tester _______',
'soll fähig sein, die funktionale Spezifikation, oder Anforderungsdokumentation verstehen zu können.',
'soll fähig sein, den Code zu verstehen.',
'ist höchst motiviert, die Fehler zu finden.',
'ist kreativ, die Schwäche des Systems zu finden.',
2,
'Bei Black-Box-Tests hat man keinen Einblick in den Code.',
'',4,3],
['Welcher der folgenden Punkte trifft für ein Risiko gemäß dem ISTQB Glossar zu?',
'Positive Rückmeldung an den Tester.',
'Negative Folgen, die eintreten werden.',
'Negative Folgen, die eintreten könnten.',
'Negative Folgen für das Testobjekt.',
3,
'Risiko nach ISTQB-Glossar: "Ein Faktor, der zu negativen Konsequenzen in der Zukunft führen könnte, gewöhnlich ausgedrückt durch das Schadensausmaß und die Eintrittswahrscheinlichkeit."',
'',0,3],
['Wie viele Testfälle sind mindestens notwendig, um bei folgendem Codeausschnitt eine 100%ige Anweisungsüberdeckung zu erreichen (unter der Voraussetzung, dass die beiden Bedingungen voneinander unabhängig sind)?',
'3 Testfälle',
'1 Testfall',
'2 Testfälle',
'Nicht erreichbar',
2,
'1 Testfall, bei dem Bedingung 1 und Bedingung 2 beide WAHR sind.',
'https://i.imgur.com/v3mVnqS.png',4,3],
['Welche der folgenden Aussagen beschreibt einen möglichen Grund für einen Wartungstest?',
'Die Dokumentation der Software soll überarbeitet werden.',
'Die Software befindet sich seit längerer Zeit im Einsatz.',
'Die Software ist in eine andere Umgebung migriert worden.',
'Die Projektleitung möchte den Anweisungsüberdeckungsgrad ermitteln.',
3,
'Wartungstests werden notwendig bei: Modifikation, \nMigrationen,\nEinzug\n...der Software/Systems.',
'',2,3],
['Welche der folgenden Aussagen ist zutreffend?',
'Testtreiber werden ausschließlich beim Systemtest verwendet.',
'Testtreiber bieten sehr eingeschränkte Funktionalität und sind folglich ohne Entwicklungs-Know-how herstellbar.',
'Testtreiber können leicht durch Mitschnittwerkzeuge (capture/replay) aufgezeichnet werden.',
'Zur Erstellung von Testtreibern ist Entwicklungs-Know-how erforderlich.',
4,
'Testtreiber nach ISTQB Glossar: "Ein Testwerkzeug, das eine zu testende Komponente/ein System aufruft und/oder steuert." Zur Erstellung sind Kenntnisse in der entsprechenden Programmier-/Skriptsprache erforderlich.',
'',0,3]
        ];
        //Format Array:
        //[Frage 1 #Falsch beantwortet, Frage 1 #Richtig beantwortet, Frage 2 #Falsch... , Anzahl begonnene Durchgänge, Anzahl beendete Durchgänge]
        function prepareAnswers()
        {
            if (localStorage.getItem('AnswersCorrect') === null || localStorage.getItem('AnswersWrong') === null || localStorage.getItem('Runs') === null)
            {
                lsAnswersCorrect = new Array(qanda_original.length).fill(0);
                lsAnswersWrong = new Array(qanda_original.length).fill(0);
                lsRuns = new Array(2).fill(0);
            }
            else
            {
                lsAnswersCorrect = JSON.parse(localStorage.getItem('AnswersCorrect'));
                lsAnswersWrong = JSON.parse(localStorage.getItem('AnswersWrong'));
                lsRuns = JSON.parse(localStorage.getItem('Runs'));
            }
        }
        prepareAnswers();

        function updateCounter()
        {
            document.getElementById("counter").innerText = q + counterOutput + qanda.length;
        }

        function storeModeSettingsInLocalStorage()
        { //Read mode values from the form and store them in localStorage.
            var wr = document.getElementById("onlywrong").checked;
            var mh = document.getElementById("hidecorrect").checked;
            shuffle = document.getElementById("shuffleon").checked;
            // mode: 1 = Normal (mode is stored at index 0 in lsModeSettings),
            //2 = Only questions that were wrong #(modewrongcount = index 1) times,
            //3 = Don't show questions that were correct #(modehidecount = index 2) times
            //4 = mode 2&3
            mode = 1;
            if (!(wr && mh) && (wr || mh)) //XOR
            {
                if (wr)
                {
                    mode = 2;
                }
                else
                {
                    mode = 3;
                }
            }
            else if (wr && mh)
            {
                mode = 4
            }
            modewrongcount = document.getElementById("cntonlywrong").value;
            modehidecount = document.getElementById("cnthidecorrect").value;
            lsModeSettings = new Array(mode, modewrongcount, modehidecount, shuffle);
            localStorage.setItem('Modes',JSON.stringify(lsModeSettings));
        }

        function calcChapterQ()
        { //Calculate correct/wrong questions per chapter, and update the overview.
            var sQstart = "("; var sQmiddle = "|"; var sQend = ")";
            var correct = new Array(7).fill(0); //correct answers per chapter
            var wrong = new Array(7).fill(0); //wrong answers per chapter

            for (var i = 0; i < lsAnswersCorrect.length; i = i + 1)
            {
                for (var j = 0; j <= 6; j++)
                {
                    if (qanda_original[i][8] == j)
                    {
                        correct[j] += lsAnswersCorrect[i];
                    }
                }
            }

            for (var i = 0; i < lsAnswersWrong.length; i = i + 1)
            {
                for (var j = 0; j <= 6; j++)
                {
                    if (qanda_original[i][8] == j)
                    {
                        wrong[j] += lsAnswersWrong[i];
                    }
                }
            }

            document.getElementById("c1").innerText = sQstart + correct[1] + sQmiddle + wrong[1] + sQend;
            document.getElementById("c2").innerText = sQstart + correct[2] + sQmiddle + wrong[2] + sQend;
            document.getElementById("c3").innerText = sQstart + correct[3] + sQmiddle + wrong[3] + sQend;
            document.getElementById("c4").innerText = sQstart + correct[4] + sQmiddle + wrong[4] + sQend;
            document.getElementById("c5").innerText = sQstart + correct[5] + sQmiddle + wrong[5] + sQend;
            document.getElementById("c6").innerText = sQstart + correct[6] + sQmiddle + wrong[6] + sQend;
            document.getElementById("c0").innerText = sQstart + correct[0] + sQmiddle + wrong[0] + sQend;
        }

        function applyModeSettingsFromLocalStorage()
        { //Read settings from local storage, and apply them in the form shown on the page.
            //Mode-array "lsModeSettings" stores [mode, modewrongcount, modehidecount, shuffle]
            // mode: 1 = Normal (mode is stored at index 0 in lsModeSettings),
            //2 = Only questions that were wrong #(modewrongcount = index 1) times,
            //3 = Don't show questions that were correct #(modehidecount = index 2) times
            //4 = mode 2&3
            if (localStorage.getItem('Modes') === null)
            {
                lsModeSettings = new Array(mode, modewrongcount, modehidecount, shuffle);
            }
            else
            {
                lsModeSettings = JSON.parse(localStorage.getItem('Modes'));
            }
            mode = lsModeSettings[0];
            modewrongcount = lsModeSettings[1];
            modehidecount = lsModeSettings[2];
            shuffle = lsModeSettings[3];

            if (mode == 1)
            {
                document.getElementById("onlywrong").checked = false;
                document.getElementById("hidecorrect").checked = false;
            }
            else if (mode == 2)
            {
                document.getElementById("onlywrong").checked = true;
                document.getElementById("hidecorrect").checked = false;
            }
            else if (mode == 3)
            {
                document.getElementById("hidecorrect").checked = true;
                document.getElementById("onlywrong").checked = false;
            }
            else if (mode == 4)
            {
                document.getElementById("onlywrong").checked = true;
                document.getElementById("hidecorrect").checked = true;
            }
            document.getElementById("cntonlywrong").value = modewrongcount;
            document.getElementById("cnthidecorrect").value = modehidecount;
            if (shuffle)
            {
                document.getElementById("shuffleon").checked = true;
            }
            else
            {
                document.getElementById("shuffleon").checked = false;
            }
        }

        function validate()
        { //Validate answer, show explanation
            var a1 = document.getElementById("check1").checked;
            var a2 = document.getElementById("check2").checked;
            var a3 = document.getElementById("check3").checked;
            var a4 = document.getElementById("check4").checked;
            if (a1 + a2 + a3 + a4 != 1)
            { //Error, there is not only exactly one answer selected.
                alert(msgAlertOnlyOne);
                return;
            }
            var correctAnswer = qanda[q-1][5];
            var iAnswerId = qanda[q-1][10];
            if (a1 && correctAnswer == 1 || a2 && correctAnswer == 2 || a3 && correctAnswer == 3 || a4 && correctAnswer == 4)
            { //Correct
                if (a1) document.getElementById("answer1").classList.add("correct");
                if (a2) document.getElementById("answer2").classList.add("correct");
                if (a3) document.getElementById("answer3").classList.add("correct");
                if (a4) document.getElementById("answer4").classList.add("correct");
                correctAnswers++;
                lsAnswersCorrect[iAnswerId] = parseInt(lsAnswersCorrect[iAnswerId]) + 1;
                localStorage.setItem('AnswersCorrect',JSON.stringify(lsAnswersCorrect));
            }
            else
            { //Wrong
                if (correctAnswer == 1) document.getElementById("answer1").classList.add("correct");
                if (correctAnswer == 2) document.getElementById("answer2").classList.add("correct");
                if (correctAnswer == 3) document.getElementById("answer3").classList.add("correct");
                if (correctAnswer == 4) document.getElementById("answer4").classList.add("correct");
                lsAnswersWrong[iAnswerId] = parseInt(lsAnswersWrong[iAnswerId]) + 1;
                localStorage.setItem('AnswersWrong',JSON.stringify(lsAnswersWrong));
            }
            document.getElementById("submit").style.visibility = "hidden";
            document.getElementById("next").style.visibility = "visible";
            document.getElementById("explanation").style.visibility = "visible";
            document.getElementById("explanation").value = qanda[q-1][6];
            calcChapterQ();
        }

        function selectQuestions()
        { //Select questions based on selection.
            prepareAnswers();
            var iCnt = document.getElementById("numquestions").value;
            var iCntOnlywrong = document.getElementById("cntonlywrong").value;
            var iCntHidecorrect = document.getElementById("cnthidecorrect").value;
            var qandatemp = new Array();
            var onlywrong = document.getElementById("onlywrong").checked;
            var hidecorrect = document.getElementById("hidecorrect").checked;
            var chap1 = document.getElementById("chap1").checked;
            var chap2 = document.getElementById("chap2").checked;
            var chap3 = document.getElementById("chap3").checked;
            var chap4 = document.getElementById("chap4").checked;
            var chap5 = document.getElementById("chap5").checked;
            var chap6 = document.getElementById("chap6").checked;
            var chap0 = document.getElementById("chap0").checked;

            var exam1 = document.getElementById("exam1").checked;
            var exam2 = document.getElementById("exam2").checked;
            var exam3 = document.getElementById("exam3").checked;
            var exam4 = document.getElementById("exam4").checked;

            var additem;
            for (var i = 0; i < qanda_original.length; i++)
            {
                additem = true;
                if (onlywrong && lsAnswersWrong[i] < iCntOnlywrong) additem = false;
                if (hidecorrect && lsAnswersCorrect[i] >= iCntHidecorrect) additem = false;
                if (!chap1 && qanda_original[i][8] == 1) additem = false;
                if (!chap2 && qanda_original[i][8] == 2) additem = false;
                if (!chap3 && qanda_original[i][8] == 3) additem = false;
                if (!chap4 && qanda_original[i][8] == 4) additem = false;
                if (!chap5 && qanda_original[i][8] == 5) additem = false;
                if (!chap6 && qanda_original[i][8] == 6) additem = false;
                if (!chap0 && qanda_original[i][8] == 0) additem = false;

                if (!exam1 && qanda_original[i][9] == 0) additem = false;
                if (!exam2 && qanda_original[i][9] == 1) additem = false;
                if (!exam3 && qanda_original[i][9] == 2) additem = false;
                if (!exam4 && qanda_original[i][9] == 3) additem = false;

                if (additem)
                {
                    var qa = qanda_original[i];
                    qa.push(i);
                    qandatemp.push(qa);

                }
            }
            if (shuffle)
            { //Very simple shuffling.
                qandatemp.sort(() => Math.random() - 0.5);
            }
            if (iCnt < qandatemp.length)
            {
                qandatemp = qandatemp.slice(0,iCnt);
            }
            return qandatemp;
        }

        function countQuestions()
        {
            var q = selectQuestions();
            return q.length;
        }

        function End()
        {
            running = false;
            alert(msgCorrectAnswers + correctAnswers + msgCorrectAnswersOf + qanda.length);
            q = 0;
            correctAnswers  = 0;
            lsRuns[1] = parseInt(lsRuns[1]) + 1;
            localStorage.setItem('Runs',JSON.stringify(lsRuns));
            //Show overview
            updateOverview();
            showOverview();
        }

        function start()
        {
            hideOverview();
            running = true;
            qanda = selectQuestions();
            //Enter new attempt in the list.
            lsRuns[0] = parseInt(lsRuns[0]) + 1;
            localStorage.setItem('Runs',JSON.stringify(lsRuns));
            localStorage.setItem('AnswersCorrect',JSON.stringify(lsAnswersCorrect));
            localStorage.setItem('AnswersWrong',JSON.stringify(lsAnswersWrong));

            //Start the practice
            moveon();
        }

        function restart()
        {
            q = 0;
            correctAnswers  = 0;
            //Start the next round of practice
            if (countQuestions() <= 0)
            {
                alert(msgIllegalSelection);
            }
            else
            {
                start();
            }
        }

        function moveon()
        { //Move to the next question
            q++;
            updateCounter();
            if (q > qanda.length)
            { //Last question reached.
                End();
            }
            else
            {
                document.getElementById("next").style.visibility = "hidden";
                document.getElementById("submit").style.visibility = "visible";
                document.getElementById("explanation").style.visibility = "hidden";
                document.getElementById("check1").checked = false;
                document.getElementById("check2").checked = false;
                document.getElementById("check3").checked = false;
                document.getElementById("check4").checked = false;
                document.getElementById("answer1").innerHTML = qanda[q-1][1];
                document.getElementById("answer2").innerHTML = qanda[q-1][2];
                document.getElementById("answer3").innerHTML = qanda[q-1][3];
                document.getElementById("answer4").innerHTML = qanda[q-1][4];
                document.getElementById("explanation").value = "";
                document.getElementById("question").innerHTML = qanda[q-1][0];
                document.getElementById("answer1").classList.remove("correct");
                document.getElementById("answer2").classList.remove("correct");
                document.getElementById("answer3").classList.remove("correct");
                document.getElementById("answer4").classList.remove("correct");
                document.getElementById("check1").style="outline-style:none";
                document.getElementById("check2").style="outline-style:none";
                document.getElementById("check3").style="outline-style:none";
                document.getElementById("check4").style="outline-style:none";
                if (qanda[q-1][7] == "")
                {
                    document.getElementById("image").style.display = "none";
                }
                else
                {
                    document.getElementById("image").style.display = "inline";
                    document.getElementById("image").src = qanda[q-1][7];
                }
            }
        }

        function updateOverview()
        {
            document.getElementById("current").innerText = q + counterOutput + qanda.length;
            document.getElementById("runs").innerText = lsRuns[1];
            var correct = 0;
            for (var i = 1; i < lsAnswersCorrect.length; i = i + 1)
            {
                if (lsAnswersCorrect[i] > 0)
                {
                    correct++;
                }
            }
            var wrong = 0
            for (var i = 0; i < lsAnswersWrong.length; i = i + 1)
            {
                if (lsAnswersWrong[i] > 0)
                {
                    wrong++;
                }
            }
            document.getElementById("correct").innerText = correct;
            document.getElementById("wrong").innerText = wrong;
        }

        function updateCount()
        {
            document.getElementById('labelnumq').innerHTML=countQuestions();
            storeModeSettingsInLocalStorage();
        }

        function showOverview()
        {
            updateCount();
            if(running)
            {
                document.getElementById('startbutton').style.visibility='hidden';
                document.getElementById('resetbutton').style.visibility='visible';
                document.getElementById('backbutton').style.visibility='visible';
            }
            else
            {
                document.getElementById('backbutton').style.visibility='hidden';
                document.getElementById('startbutton').style.visibility='visible';
                document.getElementById('resetbutton').style.visibility='hidden';
            }
            document.getElementById('overview').style.visibility='visible';
        }

        function hideOverview()
        {
            document.getElementById('startbutton').style.visibility='hidden';
            document.getElementById('backbutton').style.visibility='hidden';
            document.getElementById('overview').style.visibility='hidden';
            document.getElementById('resetbutton').style.visibility='hidden';
        }
    </script>
    </head>
    <body style="font: normal 12px Verdana, Arial, sans-serif">
    <form action="#">
        <div id="question"></div>
        <br/>
        <img id="image" src="empty.gif" style="display:none;" width="500" alt="Aufgabe">
        <fieldset>
        <div>
        <input type="checkbox" id="check1">&nbsp;<label for="check1" id="answer1" ></label>
        </div>
        <br/>
        <div>
        <input type="checkbox" id="check2">&nbsp;<label for="check2" id="answer2" ></label>
        </div>
        <br/>
        <div>
        <input type="checkbox" id="check3">&nbsp;<label for="check3" id="answer3"></label>
        </div>
        <br/>
        <div>
        <input type="checkbox" id="check4" >&nbsp;<label for="check4" id="answer4"></label>
        </div>
        </fieldset>
        <br/>
        <br/>
        <input id="submit" type="button" value="Absenden" onclick="validate()">
        <input id="next" type="button" value="Nächste Frage" onclick="moveon()" style="visibility:hidden;">
        <div style="float:right; margin-right:75px;"><span id="counter" style="font-size:smaller;"></span>&nbsp;<input type="button" value="Übersicht" onclick="updateOverview();showOverview();"></div>
        <br/>
        <br/>
        <textarea id="explanation" style="visibility:hidden;border:none;resize:none;"></textarea>
        </form>
        <div id="overview" style="position: absolute; z-index: 2400; width: 74vw; top: 1vh; min-height: 800px; background-color: white; padding: 5px; border: 1px solid grey; visibility: visible;" onkeyup="updateCount()" onchange="updateCount()">
            <span style="font-weight: bold">Fortschritt:</span>
            <br><br>Aktuell: <span id="current">0 / 2</span>
            <br><br>Durchläufe: <span id="runs">0</span>
            <br><br>Fragen richtig beantwortet (in allen Durchläufen): <span id="correct">0</span>
            <br><br>Fragen falsch beantwortet  (in allen Durchläufen): <span id="wrong">0</span>
            <br><br>
            <span style="font-weight: bold;">Modus:</span><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="onlywrong">&nbsp;<label for="onlywrong">Zeige nur Fragen die so oft falsch beantwortet wurden: </label><input type="text" value="0" style="width:90px;" id="cntonlywrong"> Mal</div><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="hidecorrect">&nbsp;<label for="hidecorrect">Blende Fragen aus die so oft richtig beantwortet wurden: </label><input type="text" value="0" style="width:90px;" id="cnthidecorrect"> Mal</div><br><br>
            <div style="position:relative; left:50px">Anzahl Fragen: <input type="text" id="numquestions" value="40" style="width:90px;"> Aktuell:&nbsp;<label for="numquestions" id="labelnumq"></label></div>
            <br>
            <div style="position:relative; left:50px"><input type="checkbox" id="shuffleon">&nbsp;<label for="shuffleon">Shuffle</label></div>
            <br><br>
            <span style="font-weight: bold;">Kapitel:</span>&nbsp;<span>(Richtig | Falsch)</span><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="chap1" checked>&nbsp;<label for="chap1">Kapitel 1 - Grundlagen des Testens</label>&nbsp<span id="c1" style="font-size:smaller;">(0|0)</span></div><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="chap2" checked>&nbsp;<label for="chap2">Kapitel 2 - Testen im Softwareentwicklungslebenszyklus</label>&nbsp<span id="c2" style="font-size:smaller;">(0|0)</span></div><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="chap3" checked>&nbsp;<label for="chap3">Kapitel 3 - Statischer Test</label>&nbsp<span id="c3" style="font-size:smaller;">(0|0)</span></div><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="chap4" checked>&nbsp;<label for="chap4">Kapitel 4 - Testverfahren</label>&nbsp<span id="c4" style="font-size:smaller;">(0|0)</span></div><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="chap5" checked>&nbsp;<label for="chap5">Kapitel 5 - Testmanagement</label>&nbsp<span id="c5" style="font-size:smaller;">(0|0)</span></div><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="chap6" checked>&nbsp;<label for="chap6">Kapitel 6 - Werkzeugunterstützung für das Testen</label>&nbsp<span id="c6" style="font-size:smaller;">(0|0)</span></div><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="chap0" checked>&nbsp;<label for="chap0">Fragen aus dem Glossar</label>&nbsp<span id="c0" style="font-size:smaller;">(0|0)</span></div><br><br>
            
            <span style="font-weight: bold;">Examen:</span><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="exam1" checked>&nbsp;<label for="exam1">ISTQB Sample Exam 1.3</label></div><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="exam2" checked>&nbsp;<label for="exam2">ISTQB Sample Exam 1.6</label></div><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="exam3" checked>&nbsp;<label for="exam3">ISTQB Sample Exam 2016B</label></div><br><br>
            <div style="position:relative; left:50px"><input type="checkbox" id="exam4" checked>&nbsp;<label for="exam4">HTB Sample Exam</label></div><br><br>
            
            <span>Reset des Fortschritts:</span>
            <input type="button" value="Zurücksetzen" onclick="if (confirm('Alle gespeicherten Werte zurücksetzen. Sind Sie sicher?')){localStorage.removeItem('AnswersCorrect');localStorage.removeItem('AnswersWrong');localStorage.removeItem('Runs');localStorage.removeItem('Modes');location.reload();}">
            <br><br>
            <input type="button" value="Start" id="startbutton" onclick="if (countQuestions() <= 0){alert(msgIllegalSelection);}else{start();}">&nbsp;<input type="button" value="Zur&uuml;ck" id="backbutton" onclick="hideOverview();">&nbsp;<input type="button" value="Neustart" id="resetbutton" onclick="if (confirm('Neustart. Sind Sie sicher?')){restart();}">
        </div>
        <script>
            applyModeSettingsFromLocalStorage();
            updateOverview();
            showOverview();
            updateCount();
            calcChapterQ();
        </script>
    </body>
</html>