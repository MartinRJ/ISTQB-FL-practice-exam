<!DOCTYPE html>
<html lang="de">
    <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ISTQB FL Übungsfragen</title>

    <style>
        body {
    display:flex;
    justify-content: center;
    align-items: center;
    scroll-behavior: smooth;
}

form {
    border:2px solid gainsboro;
    margin-top:.5vh;
    width:75vw;
}

textarea{
    padding-left: 2rem;
    width:67vw;
    height:450px;
}

form img{
    padding-left: 5rem;
}

label {
    
    position: relative;
    width:100%;
    font: 14px Verdana, Arial, sans-serif
}

form fieldset div {
    transform-origin: center;
    margin-left:7rem;
    margin-top: .5rem;
    margin-bottom: .5rem;
}

#submit{
    margin-left:5rem;
}

input[type='checkbox'],label {
    margin-top:2rem;
    border-width: 1rem;
    position: relative;
}

input[type='checkbox'] {
    display:none;
}

input[type='checkbox'] + label::before,
input[type='checkbox'] + label::after {

content: "";
position: absolute;
left:-2rem;
top:0;
aspect-ratio: 1/1;
border-radius: 50%;
}

input[type='checkbox'] + label::after {
    background-color: white;
    border:2px solid white;
    height:24px;
    transform: translate(-6px,-6px);
}

input[type='checkbox'] + label::before {
    background-color: midnightblue;
    border-width:20px;
    height:32px;
    transform: translate(-8px,-8px);
    
}

div:hover  label::before {
    background-color: gold;
}

div:hover  label::after {
    background-color: gold;
}

input[type='checkbox']:checked + label::after {
    background-color: midnightblue;
}

fieldset {
    border: none;
    width:68vw;
}

#question {
    align-items: center;
    color: white;
    background-color: midnightblue;
    
    padding: 1em;
    font-size:1rem;
}

input[type='button'] {
    border:none;
    color: white;
    background-color: midnightblue;
    padding: 1rem 2rem;
    border-radius: 25% / 50%;
}

input[type='button']:active {
    transform: translatey(.2rem);
}

input[type='button']:hover

{
    transform: scale(1.02);
}

input[type='checkbox'] + .correct::after {
    background-color: orange;
}

input[type='checkbox'] + .correct::before {
    background-color: orange;
    height:36px;
    transform: translate(-10px,-10px);
}

input[type='checkbox']:checked + .correct::after {
    background-color: green;
}

input[type='checkbox']:checked + .correct::before {
    background-color: green;
    height:36px;
    transform: translate(-10px,-10px);
}

input[type='checkbox']+ .correct {
    font-weight:700;

}
    </style>
    <script>
        var msgAlertOnlyOne = "Bitte wählen Sie genau eine Antwort aus.";
        var msgCorrectAnswers = "Fertig. Richtige Antworten: ";
        var msgCorrectAnswersOf = " von ";
        var q = 0;
        var correctAnswers = 0;
        let qanda = [
        ['Welche der folgenden Definitionen entspricht dem Begriff „Testbedingung“ gemäß Glossar?',
        'Ein kennzeichnendes Merkmal einer Komponente oder eines Systems.',
        'Ein testbarer Aspekt einer Komponente oder eines Systems, der als Grundlage für das Testen identifiziert wurde.',
        'Der Grad, zu dem eine Komponente oder ein System Funktionen zur Verfügung stellt, welche unter festgelegten Bedingungen explizit genannte und implizite Bedürfnisse erfüllen.',
        'Testfälle entworfen im Hinblick auf die Ausführung von Kombinationen von Bedingungen und aus ihnen resultierender Aktionen.',
        2,
        'Laut Glossar V.3.3 "Testbedingung": Eine Einheit oder ein Ereignis, z.B. eine Funktion, eine Transaktion, ein Feature, ein Qualitätsmerkmal oder ein strukturelles Element einer Komponente oder eines Systems, welche bzw. welches durch einen oder mehrere Testfälle verifiziert werden kann.',
        ''],
        ['Welche der folgenden Aussagen beschreibt ein gültiges Ziel des Testens?',
        'Der Test soll möglichst spät starten, damit die Entwicklung genug Zeit hatte, ein gutes Produkt zu erstellen.',
        'Es soll validiert werden, ob das Testobjekt so funktioniert, wie es die Benutzer und andere Stakeholder erwarten.',
        'Es soll nachgewiesen werden, dass alle möglichen Fehlerzustände identifiziert wurden.',
        'Es soll nachgewiesen werden, dass alle verbleibenden Fehlerzustände keine Fehlerwirkungen verursachen werden.',
        2,
        'Ziele des Testens (Syllabus 1.1.1):\n· Arbeitsergebnisse wie Anforderungen, User-Stories, Architekturdesign und Code bewerten, um Fehler zu identifizieren und in Folgearbeitsergebnissen zu vermeiden\n\n· Verifizieren, ob alle spezifischen Anforderungen erfüllt sind\n\n· Prüfen, ob das Testobjekt vollständig ist und validieren, ob das Testobjekt so funktioniert, wie es die Benutzer und andere Stakeholder erwarten\n\n· Vertrauen in das Qualitätsniveau des Testobjekts schaffen\n\n· Fehlerwirkungen und Fehlerzustände aufdecken, wodurch man Risiken aufgrund einer unzureichenden Softwarequalität reduziert\n\n· Stakeholdern ausreichende Informationen zur Verfügung stellen, damit diese fundierte Entscheidungen treffen können, insbesondere bezüglich des Qualitätsniveaus des Testobjekts\n\n· Konform mit vertraglichen, rechtlichen oder regulatorischen Anforderungen oder Standards zu sein und/oder um die Konformität (compliance) des Testobjekts mit diesen Anforderungen oder Standards zu verifizieren',
        ''],
        ['Welche der folgenden Aussagen beschreibt den Unterschied zwischen Testen und Debugging zutreffend?',
        'Testen identifiziert die Ursache von Fehlerzuständen. Debugging analysiert die Fehlerzustände und schlägt Präventionsmaßnahmen vor.',
        'Dynamische Tests zeigen Fehlerwirkungen auf, die durch Fehlerzustände verursacht wurden. Debugging ist eine Entwicklungsaktivität, die Fehlerzustände beseitigt, die die Ursache von Fehlerwirkungen sind.',
        'Testen entfernt Fehlerwirkungen; Debugging entfernt dagegen Fehlerzustände, die Fehlerwirkungen verursachen.',
        'Dynamische Tests verhindern die Ursache von Fehlerwirkungen. Debugging entfernt die Fehlerwirkungen.',
        2,
        'Dynamisches Testen zeigt Fehlerwirkungen auf, die durch Fehlerzustände verursacht wurden. Durch Debugging können die Ursachen von Fehlerwirkungen analysiert und beseitigt werden (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.1.2).',
        ''],
        ['Nachfolgend finden Sie eine Liste von Problemen, die während des Testens oder im Betrieb beobachtet werden können. Welches Problem ist eine Fehlerwirkung?',
        'Das Produkt stürzte ab, als der Benutzer eine Option in einer Dialogbox auswählte.',
        'Eine kompilierte Quellcodedatei wurde in der falschen Version zum Build hinzugefügt.',
        'Der Berechnungsalgorithmus verwendet die falschen Eingangsvariablen.',
        'Der Entwickler hat die Anforderungen an den Algorithmus falsch interpretiert.',
        1,
        'a) KORREKT – Eine Fehlerwirkung ist das Sichtbarwerden eines Fehlerzustands während der Ausführung. Ein Absturz ist vom Anwender deutlich spürbar (siehe CTFL Lehrplan CORE 2018; Abschnitt 1.2.3)\n\nb) FALSCH – Diese Art von Fehlern (Fehlhandlungen) wird nicht unbedingt zu einer sichtbaren oder spürbaren Fehlerwirkung führen; zum Beispiel, wenn die Änderungen in der neuen Version der Quelldatei nur in den Kommentaren vorgenommen wurden. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.3)\n\nc) FALSCH – Es handelt sich um einen Fehlerzustand, nicht um eine Fehlerwirkung. Verwendung von falschen Eingabevariablen wird nicht unbedingt zu einer sichtbaren oder spürbaren Fehlerwirkung führen; zum Beispiel, wenn niemand diesen speziellen Algorithmus verwendet; oder wenn die falsche Eingabevariable einen ähnlichen Wert wie die richtige Eingabevariable hat; oder wenn das FALSCHE Resultat des Algorithmus nicht verwendet wird. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.3)\n\nd) FALSCH – Es handelt sich um eine Fehlhandlung, nicht um eine Fehlerwirkung. Diese Art von Fehlern wird nicht notwendigerweise zu einer Fehlerwirkung führen; zum Beispiel, wenn niemand diesen speziellen Algorithmus verwendet. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.3)',
        ''],
        ['Ein Tester hat über einen Zeitraum von 5 Jahren Software-Applikationen auf mobilen Geräten einem Test unterzogen. Er hat sich einen großen Erfahrungsschatz im Testen von mobilen Applikationen angeeignet und erzielt in kürzer Zeit bessere Ergebnisse als andere. Über einen längeren Zeitraum hat der Tester die existierenden automatisierten Testfälle nicht modifiziert und auch keine neuen Testfälle mehr erstellt. Dies führt dazu, dass durch Ausführung der Tests immer weniger Fehler gefunden werden. Welchen Grundsatz des Softwaretestens hat der Tester nicht beachtet?',
        'Testen ist abhängig vom Umfeld',
        'Vollständiges Testen ist nicht möglich',
        'Wiederholungen haben keine Wirksamkeit',
        'Häufung von Fehlerzuständen',
        3,
        'a) FALSCH – Test ist abhängig vom Umfeld, egal, ob manuell oder automatisiert (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.3; 6. Grundsatz), führt aber nicht dazu, dass - wie oben beschrieben - immer weniger Fehler aufgedeckt werden.\n\nb) FALSCH – Erschöpfendes vollständiges Testen ist unmöglich, egal wieviel Aufwand wir in den Test investieren (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.3; 2. Grundsatz), führt aber nicht dazu, dass - wie oben beschrieben - immer weniger Fehler aufgedeckt werden.\n\nc) KORREKT – Ein Grundsatz (gem. CTFL CORE Lehrplan 2018) besagt: “Vorsicht vor dem Pestizid-Paradoxon“ bzw. Wiederholungen haben keine Wirksamkeit (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.3; 5. Grundsatz), dass eine Ausführung immer der gleichen Testfälle keine neuen Erkenntnisse mehr bringt. Um neue Fehlerzustände zu finden, müssen bestehende Tests möglicherweise verändert werden und neue Tests erstellt werden.\n\nd) FALSCH – Oftmals ist eine “Häufung von Fehlerzuständen“ (CTFL CORE Lehrplan 2018; Abschnitt 1.3; 4. Grundsatz) in einer kleinen Anzahl von Modulen zu beobachten; das führt aber nicht dazu, dass - wie oben beschrieben - immer weniger Fehler aufgedeckt werden.',
        ''],
        ['Inwiefern leistet das Testen einen Beitrag zur Verbesserung von Qualität?',
        'Testen stellt sicher, dass Anforderungen detailliert genug sind.',
        'Testen verringert das Risiko von unzureichender Softwarequalität.',
        'Testen stellt sicher, dass in der Organisation Standards befolgt werden.',
        'Testen misst die Softwarequalität im Hinblick auf die Anzahl ausgeführter Testfälle.',
        2,
        'a) FALSCH – Durch statisches Testen (Reviews) kann dazu beigetragen werden, aber es kann nicht sichergestellt werden, dass die Anforderungen detailliert genug sind. (vgl. CTFL Lehrplan 2018; Abschnitt 1.2.2).\nb) KORREKT – Testen deckt Fehlerwirkungen und Fehlerzustände auf und verringert damit das Risiko von unzureichender Softwarequalität (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.1.1).\nc) FALSCH – Dies ist Qualitätssicherung, aber nicht Testen (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.2).\nd) FALSCH – Die Qualität kann nicht anhand der Anzahl ausgeführter Testfälle gemessen werden, ohne dass man das Ergebnis kennt (vgl. CTFL CORE Lehrplan 2018; Abschnitt 1.2.2).',
        ''],
        ['Welche der folgenden Aktivitäten ist Teil der Hauptaktivität „Testanalyse“ im Testprozess?',
        'Identifikation der erforderlichen Infrastruktur und Werkzeuge',
        'Erstellen von Testsuiten basierend auf den Testskripten',
        'Analyse der „Lessons learned“ zur Prozessverbesserung',
        'Bewerten der Testbasis hinsichtlich Testbarkeit',
        4,
        'a) FALSCH – diese Aktivität wird im “Testentwurf” durchgeführt (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.2; Testentwurf).\nb) FALSCH – diese Aktivität wird in der “Testrealisierung” durchgeführt (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.2; Testrealisierung).\nc) FALSCH – diese Aktivität wird im “Testabschluss“ durchgeführt (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.2; Testabschluss).\nd) KORREKT – diese Aktivität wird in der „Testanalyse“ durchgeführt (CTFL CORE Lehrplan 2018; Abschnitt 1.4.2: „Während der Testanalyse wird die Testbasis analysiert, um testbare Features zu identifizieren …“).',
        ''],
        ['Wählen Sie die richtige Kombination für die aufgeführten Beschreibungen von Testarbeitsergebnissen',
        '1A, 2C, 3B, 4D',
        '1D, 2B, 3A, 4C',
        '1A, 2C, 3D, 4B',
        '1D, 2C, 3B, 4A',
        1,
        'Begründung (nach CTFL CORE Lehrplan 2018, V.3.1, Glossar V.3.3)\nTestsuite: Eine Menge von Testskripten oder Testabläufen, die in einem bestimmten Testlauf ausgeführt werden sollen. gemäß Glossar V.3.3, wobei „Testabläufe“ durch „Testskripten“ ersetzt werden kann laut Glossar („See Also“ bei Testablauf bzw. Synonyms bei 3.3) (1A).\nTestfall: gemäß Glossar: Eine Menge von Vorbedingungen, Eingaben, Aktionen (falls anwendbar), erwarteten Ergebnissen und Nachbedingungen, welche auf Basis von Testbedingungen entwickelt wurden. (2C).\nTestskript: gemäß Glossar: Eine Abfolge von Anweisungen für die Durchführung eines Tests. (3B).\nTest-Charta: „Die Dokumentation eines Ziels und der Agenda einer Testsitzung.“ gemäß Glossar V.3.1 und Syllabus 4.4.2: Die Dokumentation von Testaktivitäten im Rahmen des sitzungsbasierten explorativen Testens. (4D).\na) KORREKT – s.o.\nb) FALSCH – s.o.\nc) FALSCH – s.o.\nd) FALSCH – s.o.',
        'https://i.imgur.com/kkPcCzV.png'],
        ['Wie kann der White-Box-Test während des Abnahmetests angewendet werden?',
        'Um zu prüfen, ob große Datenmengen zwischen integrierten Systemen übertragen werden können.',
        'Um zu prüfen, ob alle Code-Anweisungen und Code-Entscheidungspfade ausgeführt wurden.',
        'Um zu prüfen, ob alle Abläufe der Arbeitsprozesse abgedeckt sind.',
        'Um alle Webseiten-Navigationen abzudecken.',
        3,
        'a) FALSCH – Relevant für Integrationstests. (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.2.2)\nb) FALSCH – Relevant für Komponententests (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.2.1 und 2.3.5, Beispiele für White-Box-Tests)\nc) KORREKT – CTFL CORE Lehrplan 2018, Abschnitt 2.3.5: Für Abnahmetests sind die Tests so konzipiert, dass sie z. B. alle Dateistrukturen und Wertebereiche der Finanzdaten für Bank-zu-Bank-Überweisungen unterstützen.\nd) FALSCH – Relevant für Systemtests (vgl. CTFL CORE Lehrplan 2018; Abschnitt 2.2.3, Beispiele für White-Box-Tests)',
        ''],
        ['Welche der folgenden Aussagen zum Vergleich zwischen Komponententest und Systemtest ist WAHR?',
        'Komponententests überprüfen die Funktion von Komponenten, Programmobjekten und Klassen, die separat prüfbar sind, während Systemtests die Schnittstellen zwischen den Komponenten und Wechselwirkungen mit anderen Teilen des Systems überprüfen.',
        'Testfälle für den Komponententest werden in der Regel von Komponentenspezifikationen, Designspezifikationen oder Datenmodellen abgeleitet, während Testfälle für den Systemtest in der Regel von Anforderungsspezifikationen oder Anwendungsfällen abgeleitet werden.',
        'Komponententests konzentrieren sich nur auf die funktionalen Eigenschaften, während Systemtests sich auf die funktionalen und nicht-funktionalen Eigenschaften konzentrieren.',
        'Komponententests sind in der Verantwortung der Tester, während die Systemtests in der Regel in der Verantwortung der Benutzer des Systems liegen.',
        2,
        'FL-2.2.1 (K2) Die unterschiedlichen Teststufen unter den Aspekten der Testziele, Testbasis, Testobjekte, typischen Fehlerzustände und Fehlerwirkungen sowie der Testvorgehensweise und Verantwortlichkeiten vergleichen können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1, Glossar V.3.3)\n\na) FALSCH – Systemtests testen nicht die Schnittstellen und Wechselwirkungen zwischen den Komponenten und anderen Teilen des Systems; das ist Ziel von Integrationstests (siehe CTFL CORE Lehrplan 2018, Abschnitt 2.2.2).\n\nb) KORREKT – (siehe CTFL CORE Lehrplan 2018, Abschn. 2.2.1 (Komponententest): Beispiele für Arbeitsprodukte, die als Testbasis für Komponententests verwendet werden können, umfassen: detailliertes Design, Code, Datenmodell, Komponentenspezifikationen. CTFL CORE Lehrplan 2018; Abschn. 2.2.3: Beispiele für Arbeitsprodukte für Systemtests umfassen: System- und Softwareanforderungsspezifikationen (funktional und nicht funktionale), Anwendungsfälle.\n\nc) FALSCH – Komponententests konzentrieren sich nicht nur auf funktionale, sondern auch auf nicht-funktionale Aspekte (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.2.1, Komponententest).\n\nd) FALSCH – Komponententests werden auch von Entwicklern durchgeführt, wohin gegen sich (unabhängige) Tester mit Systemtests befassen (vgl. CTFL CORE Lehrplan 2018, Unterkapitel 2.2.1 und 2.2.3, jeweils Abschnitt „Spezifische Ansätze und Verantwortlichkeiten“).',
        ''],
        ['Welche der folgenden Aussagen ist zutreffend?',
        'Der Zweck des Regressionstests ist es, zu überprüfen, ob die Korrektur erfolgreich implementiert wurde, während der Zweck der Fehlernachtests darin besteht, zu bestätigen, dass die Korrektur keine Seiteneffekte hat.',
        'Der Zweck des Regressionstests ist es, unbeabsichtigte Seiteneffekte zu erkennen, während der Zweck des Fehlernachtests darin besteht zu prüfen, ob das System in einer neuen Umgebung noch funktioniert.',
        'Der Zweck des Regressionstests ist es, unbeabsichtigte Seiteneffekte zu erkennen, während der Zweck des Fehlernachtests darin besteht zu prüfen, ob der ursprüngliche Fehlerzustand behoben wurde.',
        'Der Zweck des Regressionstests ist es zu prüfen, ob die neue Funktionalität funktioniert, während der Zweck des Fehlernachtests darin besteht zu prüfen, ob der ursprüngliche Fehlerzustand behoben wurde.',
        3,
        'FL-2.3.3 (K2) Den Zweck von Fehlernachtests und Regressionstests vergleichen können.\nBegründung (nach CTFL CORE Lehrplan 2018, V3.1; Glossar V.3.3)\n\na) FALSCH – Regressionstests überprüfen nicht die erfolgreiche Implementierung einer Korrektur und Fehlernachtest prüfen nicht auf Seiteneffekte. (siehe CTFL CORE Lehrplan, Abschnitt 2.3.4).\n\nb) FALSCH – Die Aussage über Fehlernachtests sollte sich auf Regressionstests beziehen (siehe CTFL CORE Lehrplan 2018, Abschnitt 2.3.4).\n\nc) KORREKT – CTFL CORE Lehrplan 2018, Abschnitt 2.3.4.\n\nd) FALSCH – Test neuer Funktionalität ist nicht Bestandteil eines Regressionstests (siehe CTFL CORE Lehrplan 2018, Abschnitt 2.4 im Vergleich zu Abschn. 2.3.4 für Regressionstests).',
        ''],
        ['Welches ist die BESTE Definition eines inkrementellen Entwicklungsmodells?',
        'Die Definition der Anforderungen, das Design der Software und das Testen erfolgen in einer Serie durch Hinzufügen von Teilen.',
        'Eine Phase des Entwicklungsprozesses sollte beginnen, wenn die vorhergehende Phase abgeschlossen ist.',
        'Das Testen wird als separate Phase betrachtet. Sie startet, wenn die Entwicklung abgeschlossen ist.',
        'Das Testen wird der Entwicklung als Inkrement hinzugefügt.',
        1,
        'FL-2.1.1 (K2) Die Beziehungen zwischen Softwareentwicklungsaktivitäten und Testaktivitäten im Softwareentwicklungslebenszyklus erklären können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1 (9. Absatz): Bei der inkrementellen Entwicklung geht es um die Festlegung von Anforderungen, Entwurf, Entwicklung und Test eines Systems in Teilen.\n\nb) FALSCH – Dieses ist ein sequenzielles Modell (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).\n\nc) FALSCH – Dies beschreibt das Wasserfall-Modell (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).\n\nd) FALSCH – Das Testen für sich ist kein Inkrement/zusätzliche Stufe in der Entwicklung, sondern während der Entwicklung gibt es Inkremente (vgl. CTFL CORE Lehrplan 2018, Abschnitt 2.1.1).',
        ''],
        ['Welche der folgenden Entscheidungen sollte KEIN Auslöser für Wartungstests sein?',
        'Die Entscheidung, die Wartbarkeit der Software zu testen',
        'Die Entscheidung, das System nach der Migration auf einer neuen Betriebsplattform zu testen',
        'Die Entscheidung zu testen, ob archivierte Daten abgerufen werden können',
        'Die Entscheidung zum Testen nach "Hot Fixes"',
        1,
        'FL-2.4.1 (K2) Auslöser für Wartungstests zusammenfassen können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Dies ist ein Wartbarkeitstest und nicht ein Wartungstest. „... die meisten Wartbarkeitsfehler (können) nur durch statische Tests gefunden werden.“ (CTFL CORE Lehrplan 2018, Kap. 3.1.3, letzter Absatz)\n\nb) FALSCH – Dies ist ein Auslöser für Wartungstests, siehe CTFL CORE Lehrplan 2018, Kapitel 2.4.1: Betriebstests der neuen Umgebung, sowie der geänderten Software.\n\nc) FALSCH – Dies ist ein Auslöser für Wartungstests, siehe CTFL CORE Lehrplan 2018, Kapitel 2.4.1, 3. Absatz: Testen von Wiederherstellungs- und Rückhol-prozeduren nach der Archivierung mit langen Aufbewahrungszeiten.\n\nd) FALSCH – Dies ist ein Auslöser für Wartungstests, siehe CTFL CORE Lehrplan 2018, Kapitel 2.4, 2. Absatz, und Kap. 2.4.1: Reaktive Modifikation eines ausgelieferten Softwareproduktes zur Behebung von dringenden Fehlerzuständen, die zu tatsächlichen Fehlerwirkungen geführt haben.',
        ''],
        ['Welche der folgenden Optionen sind Rollen in einem formalen Review?',
        'Entwickler, (Review-)Moderator, Reviewleiter, Gutachter, Tester',
        'Autor, (Review-)Moderator, Manager, Gutachter, Entwickler',
        'Autor, Manager, Reviewleiter, Gutachter, Designer',
        'Autor, (Review-)Moderator, Reviewleiter, Gutachter, Protokollant',
        4,
        'FL-3.2.2 (K1) Die unterschiedlichen Rollen und Verantwortlichkeiten in einem formalen Review erkennen können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Tester und Entwickler sind KEINE Rollen im formalen Review gemäß CTFL CORE Lehrplan 2018, Kapitel 3.2.2.\n\nb) FALSCH – Entwickler ist KEINE Rolle im formalen Review gemäß CTFL CORE Lehrplan 2018, Kapitel 3.2.2.\n\nc) FALSCH – Designer ist KEINE Rolle im formalen Review gemäß CTFL CORE Lehrplan 2018, Kapitel 3.2.2.\n\nd) KORREKT – siehe CTFL CORE Lehrplan 2018, Kapitel 3.2.2.',
        ''],
        ['Welche Aktivitäten werden im Rahmen der Planung eines formalen Reviews durchgeführt?',
        'Sammeln von Metriken für die Bewertung der Effektivität des Reviews.',
        'Beantwortung von Fragen, die die Teilnehmer haben könnten.',
        'Definition und Prüfung der Erfüllung von Eingangskriterien für das Review.',
        'Bewertung der Reviewbefunde gegenüber den Endekriterien.',
        3,
        'FL-3.2.1 (K2) Die Aktivitäten des Reviewprozesses für Arbeitsergebnisse zusammenfassen können.\nBegründung: (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Das Sammeln von Metriken ist der Hauptaktivität „Fehlerbehebung und Bericht“ zugeordnet. (vgl. CTFL CORE Lehrplan 2018, Abschn. 3.2.1);\n\nb) FALSCH – Die Beantwortung von Fragen ist der Hauptaktivität „Reviewbeginn“ (Initiierung eines Reviews, KICKOFF) zugeordnet (vgl. CTFL CORE Lehrplan 2018, Abschn. 3.2.1);\n\nc) KORREKT – Sowohl die Definition als auch die Prüfung von Eingangskriterien erfolgt in der „Planung“ eines formalen Reviews (vgl. CTFL CORE Lehrplan 2018, Abschn. 3.2.1);\n\nd) FALSCH – Die Bewertung der Reviewbefunde gegenüber den Endekriterien ist der Hauptaktivität „Befundkommunikation und -analyse“ zugeordnet (vgl. CTFL CORE Lehrplan 2018, Abschn. 3.2.1);',
        ''],
        ['Welche der unten aufgeführten Reviewarten ist AM BESTEN geeignet, wenn das Review gemäß einem formalen bzw. definierten Prozess mit Regeln und unter Verwendung von Checklisten durchgeführt werden soll?',
        'Informelles Review',
        'Technisches Review',
        'Inspektion',
        'Walkthrough',
        3,
        'FL-3.2.3 (K2) Die Unterschiede zwischen den unterschiedlichen Reviewarten erklären können: informelles Review, Walkthrough, technisches Review und Inspektion.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – ein informelles Review verwendet keinen formalen Prozess (siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.3, 3. Absatz)\n\nb) FALSCH – die Verwendung von Checklisten ist optional (siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.3, 5. Absatz)\n\nc) KORREKT – Inspektion ist ein definierter Prozess mit Regeln und Checklisten (siehe CTFL CORE Lehrplan 2018; Abschnitt 3.2.3, 6. Absatz)\n\nd) FALSCH – erfordert nicht immer einen formalen Prozess und die Verwendung von Checklisten ist optional (siehe CTFL CORE Lehrplan 2018, Abschnitt 3.2.3, 4. Absatz)',
        ''],
        ['Welche der folgenden Aussagen zum statischen Test ist am EHESTEN zutreffend?',
        'Statischer Test ist eine kostengünstige Möglichkeit, Fehlerzustände zu erkennen und zu beheben.',
        'Statischer Test macht den dynamischen Test theoretisch überflüssig.',
        'Statischer Test ermöglicht, Laufzeitprobleme frühzeitig im Lebenszyklus zu erkennen.',
        'Bei der Prüfung sicherheitskritischer Systeme hat der statische Test einen geringen Stellenwert, da der dynamische Test den Fehlerzustand besser findet.',
        1,
        'FL-3.1.2 (K2) Beispiele nennen können, um den Wert des statischen Tests zubeschreiben.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – CTFL CORE Lehrplan 2018; Abschnitt 3.1.2, 3. Satz: Früh entdeckte Fehlerzustände sind oft viel kostengünstiger zu beheben als Fehlerzustände, die später im Lebenszyklus erkannt werden.\n\nb) FALSCH – Dynamische Tests haben ihre Berechtigung, da sie andere Fehlerarten finden als statische Tests (vgl. CTFL CORE Lehrplan 2018; Abschnitt 3.1.3, 1. Absatz).\n\nc) FALSCH – Dies geschieht beim dynamischen Testen (siehe Glossar V.3.2).\n\nd) FALSCH – Statischer Test ist wichtig für sicherheitskritische Computersysteme (vgl. CTFL CORE Lehrplan 2018; Abschnitt 3.1, 2. Absatz).',
        ''],
        ['Welche der Aussagen zu dem beschriebenen Review ist korrekt?',
        'Punkt ii) der Checkliste wurde verletzt, da nicht klar ist, welche Bedingung erfüllt sein muss, damit zum Review eingeladen werden kann.',
        'Ihnen fällt auf, dass neben dem Tester auch ein Experte für Validierung eingeladen werden muss. Da dieser Punkt aber nicht Bestandteil Ihrer Checkliste ist, erstellen Sie keinen entsprechenden Kommentar.',
        'Punkt iii) der Checkliste wurde verletzt, da nicht klar ist, wodurch das Review als abgeschlossen gekennzeichnet ist.',
        'Punkt i) der Checkliste wurde verletzt, da nicht klar ist, wer die Checkliste für die Einladung zum Review bereitstellt.',
        4,
        'FL-3.2.4 (K3) Ein Reviewverfahren auf ein Arbeitsergebnis anwenden können, um Fehlerzustände zu finden.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – es ist beschrieben, dass der Architekt die Systemspezifikation fertiggestellt haben muss.\n\nb) FALSCH – siehe CTFL CORE Lehrplan, Abschnitt 3.2.4, „Checklistenbasiert“: im letzten Satz des Absatzes steht, dass auch auf Punkte außerhalb der Checkliste geachtet werden muss.\n\nc) FALSCH – es ist beschrieben: jeder Gutachter hat seinen Review-done-Kommentar erstellt.\n\nd) KORREKT – es ist beschrieben: „Eine bereitgestellte Checkliste“ … aber wer stellt sie bereit?',
        'https://i.imgur.com/PIhlxHz.png'],
        ['Was ist checklistenbasiertes Testen?',
        'Ein Testverfahren, bei dem Testfälle auf Basis des Wissens der Tester über frühere Fehler oder aus allgemeinem Wissen über Fehlerwirkungen abgeleitet werden.',
        'Ein Testverfahren, das auf einer Analyse der Spezifikation einer Komponente oder eines Systems basiert.',
        'Ein erfahrungsbasiertes Testverfahren, bei dem der erfahrene Tester z. B. eine Liste von Kontrollpunkten nutzt, welche beachtet, überprüft oder in Erinnerung gerufen werden müssen.',
        'Ein Testansatz, bei dem die Tester dynamisch Tests entwerfen und durchführen, basierend auf ihrem Wissen, der Erkundung des Testelements und dem Ergebnis früherer Tests.',
        3,
        'FL-4.x (K1) Schlüsselbegriffe\nBegründung: (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Das ist die Definition für intuitive Testfallermittlung, siehe Glossar V.3.3.\n\nb) FALSCH – Das ist die Definition für Black-Box-Testverfahren, siehe Glossar V.3.3.\n\nc) KORREKT – siehe Glossar 3.3.\n\nd) FALSCH – Das ist (bis auf die Erwähnung des Testers) die Definition für exploratives Testen, siehe Glossar V.3.3.',
        ''],
        ['Welches der folgenden Verfahren kann der Kategorie Black-Box-Testverfahren zugeordnet werden?',
        'Verfahren, das auf der Analyse der Architektur basiert.',
        'Verfahren, das prüft, ob das Testobjekt entsprechend dem Feinentwurf umgesetzt ist.',
        'Verfahren, das auf dem Wissen über frühere Fehler oder dem allgemeinen Wissen über Fehler basiert.',
        'Verfahren, das z. B. auf formalen Anforderungsdokumenten basiert.',
        4,
        'FL-4.1.1 (K2) Die Eigenschaften, Gemeinsamkeiten und Unterschiede zwischen BlackBox-Testverfahren, White-Box-Testverfahren und erfahrungsbasierten Testverfahren erklären können.\nBegründung: (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Dies bezieht sich auf White-Box-Testverfahren. (vgl. CTFL CORE Lehrplan 2018, 4.1.2, 3. Absatz)\n\nb) FALSCH – Dies bezieht sich auf White-Box-Testverfahren. (vgl. CTFL CORE Lehrplan 2018; Abschnitte 4.1.2, 3. Absatz)\n\nc) FALSCH – Dies bezieht sich auf erfahrungsbasierte Testverfahren. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.4)\n\nd) KORREKT – CTFL CORE Lehrplan 2018; Abschnitt 4.1.2, 2. Absatz: Black-BoxTestverfahren basieren auf einer Analyse der zugehörigen Testbasis (z. B. formale Anforderungsdokumente, Spezifikationen, Anwendungsfälle, User-Stories).',
        ''],
        ['Welche der Aussagen zur Entscheidungsüberdeckung ist zutreffend?',
        'Die Aussage ist wahr. Ein einzelner Testfall erzielt eine 100% Anweisungsüberdeckung und daher 50% Entscheidungsüberdeckung.',
        'Die Aussage ist wahr. Bei einem einzelnen Testfall ist der Entscheidungsausgang der IF-Anweisung entweder wahr oder falsch.',
        'Die Aussage ist falsch. Ein einzelner Testfall kann in diesem Fall nur eine Entscheidungsüberdeckung von 25% garantieren.',
        'Die Aussage ist falsch. Die Aussage ist zu weit gefasst. Sie kann abhängig von der getesteten Software richtig sein oder nicht.',
        2,
        'FL-4.3.2 (K2) Entscheidungsüberdeckung erklären können.\nBegründung: (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na)  FALSCH – Während die gemachte Aussage wahr ist, ist die Erklärung falsch; weil die Beziehung zwischen Anweisungs- und Entscheidungsüberdeckung falsch dargestellt ist. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.3.3)\n\nb) KORREKT – Da jeder Testfall dazu führt, dass das Ergebnis der IF-Anweisung entweder WAHR oder FALSCH ist, haben wir definitiv 50% Entscheidungsüberdeckung erreicht.(vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.3.2, 2. Absatz)\n\nc) FALSCH – Ein einzelner Testfall kann mehr als 25% Entscheidungs-überdeckung erreichen; bei der obigen Aussage sind es 50% Entscheidungsüberdeckung (vgl. Begründung zu Antwort b)\n\nd) FALSCH – Die obige Aussage ist konkret und immer wahr; weil durch jeden einzelnen Testfall immer eine Entscheidungsüberdeckung von 50% erreicht wird. (vgl. Begründung  zu Antwort b)',
        'https://i.imgur.com/x9zLxyC.png'],
        ['Welche der folgenden Aussagen ist eine Beschreibung für Anweisungsüberdeckung?',
        'Es handelt sich um eine Metrik zur Berechnung und Messung des prozentualen Anteils der ausgeführten Testfälle.',
        'Es handelt sich um eine Metrik, die den Prozentsatz der ausgeführten Anweisungen im Code angibt.',
        'Es handelt sich um eine Metrik zur Berechnung und Messung der Anzahl von Anweisungen im Code, die durch Testfälle ausgeführt wurden, die keine Fehlerwirkung aufgedeckt haben.',
        'Es handelt sich um eine Metrik, die eine wahr/falsch-Bestätigung gibt, ob alle Anweisungen abgedeckt sind oder nicht.',
        2,
        'FL-4.3.1 (K2) Anweisungsüberdeckung erklären können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Anweisungsüberdeckung misst den prozentualen Anteil der durch Testfälle ausgeführten (überdeckten) Anweisungen und hat keinen Bezug zur Zahl ausgeführten Testfälle.\n\nb) KORREKT – CTFL CORE Lehrplan 2018; Abschnitt 4.3.1: Der Anweisungstest führt die  ausführbaren Anweisungen des Codes aus. Die Anweisungsüberdeckung wird als die Anzahl der von den Tests ausgeführten Anweisungen gemessen, geteilt durch die Gesamtzahl der ausführbaren Anweisungen im Testobjekt, normalerweise ausgedrückt in Prozent.\n\nc) FALSCH – Die Abdeckung misst nicht bestanden/fehlgeschlagen bzw. Anweisungsüberdeckung berücksichtigt nicht, ob ein Test erfolgreich ausgeführt wurde.\n\nd) FALSCH – Anweisungsüberdeckung ist eine Metrik, die Prozentwerte liefert und keinewahr/falsch-Aussage macht. Letzteres gilt nur für die Forderung nach 100% Anweisungsüberdeckung.',
        ''],
        ['Welche Aussage über die Beziehung zwischen der Anweisungsüberdeckung und der Entscheidungsüberdeckung ist wahr?',
        '100% Entscheidungsüberdeckung schließt 100% Anweisungsüberdeckung ein.',
        '100% Anweisungsüberdeckung schließt 100% Entscheidungsüberdeckung ein.',
        '50% Entscheidungsüberdeckung schließt 50% Anweisungsüberdeckung ein.',
        'Entscheidungsüberdeckung kann nie 100% erreichen.',
        1,
        'FL-4.3.3 (K2) Die Bedeutung von Anweisungs- und Entscheidungsüberdeckung erklären können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Die Aussage ist wahr, weil die Ausführung aller Entscheidungen zwangsläufig auch die Ausführung aller Anweisungen bedingt. (siehe CTFL CORE Lehrplan 2018; Abschnitt 4.3.3; 3. Absatz).\n\nb) FALSCH – Die Aussage ist falsch, weil die Ausführung aller Anweisungen nicht zwangsläufig auch eine Ausführung aller Entscheidungen bedingt (siehe CTFL CORE Lehrplan 2018, Abschnitt 4.3.3; 3. Absatz).\n\nc) FALSCH – Die Aussage ist falsch, weil z. B. bei dem Code aus Aufgabe 21 in einem Zweig 3 Anweisungen und in dem anderen Zweig 1 Anweisung vorkommen kann - und sonst keine Anweisungen im Code vorkommen. Führt nun ein Testfall den Zweig mit den 3 Anweisungen aus, ergibt sich 50% Entscheidungsüberdeckung und 75% Anweisungsüberdeckung, da 3 der 4 Anweisungen ausgeführt werden. bedingt (siehe auch CTFL CORE Lehrplan 2018, Abschnitt 4.3.3).\n\nd) FALSCH – Die Aussage ist falsch, weil z. B. für den Code von Aufgabe 21 zwei (2) Testfälle ausreichen, die einmal das Ergebnis der (einzigen) IF-Anweisung WAHR und einmal FALSCH machen. Dann liegt eine Entscheidungsüberdeckung von 2/2, also 100%, vor. bedingt (siehe auch CTFL CORE Lehrplan 2018, Abschnitt 4.3.3).',
        ''],
        ['Für welche der folgenden Situationen ist der Einsatz von explorativem Testen AM EHESTEN geeignet?',
        'Wenn unter Zeitdruck die Durchführung bereits spezifizierter Tests beschleunigt werden muss.',
        'Wenn das System inkrementell entwickelt und keine Test-Charta vorhanden ist.',
        'Wenn Tester zur Verfügung stehen, die über ausreichende Kenntnisse von ähnlichen Anwendungen und Technologien verfügen',
        'Wenn bereits ein vertieftes Wissen über das System vorhanden ist und der Nachweis erbracht werden soll, dass besonders intensiv getestet werden soll.',
        3,
        'FL-4.4.2 (K2) Exploratives Testen erklären können.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH –Exploratives Testen ist nicht geeignet, die Durchführung bereits spezifizierter Test zu beschleunigen. Es ist am nützlichsten, wenn es nur wenige oder ungeeignete Spezifikationen der Anforderungen gibt oder einen erheblichen Zeitdruck beim Testen (vgl. CTFL CORE Lehrplan 2018, Abschnitt 4.4.2).\n\nb) FALSCH – Das Nichtvorhandensein einer möglicherweise in der Testanalyse abgeleiteten Test-Charta ist eine schlechte Vorbedingung für den Einsatz von explorativem Testen. (siehe CTFL CORE Lehrplan 2018; Abschnitte 1.4.3 und 4.4.2, 2. Absatz).\n\nc) KORREKT – Exploratives Testen sollte von Testern mit Kenntnissen über ähnliche Anwendungen und Technologien durchgeführt werden (siehe CTFL CORE Lehrplan 2018; Abschnitte 4.4, 2. Absatz, und 1.4.2, „Testanalyse“, zweitletzter Absatz, 1.4.3, Absatz „Arbeitsergebnisse der Testanalyse”).\n\nd) FALSCH – Exploratives Testen ist als alleinige Vorgehensweise nicht geeignet, den Nachweis zu erbringen, dass besonders intensiv getestet wurde, sondern der Nachweis wird in Kombination mit anderen Testverfahren erbracht (siehe CTFL CORE Lehrplan 2018; Abschnitt 4.4, 1. Absatz: „Die Überdeckung ist bei diesen Verfahren schwer zu beurteilen und möglicherweise nicht messbar.“).',
        ''],
        ['Wie viele Testfälle sind für eine vollständige Testabdeckung notwendig, wenn nur gültige Äquivalenzklassen herangezogen werden?',
        '2',
        '3',
        '4',
        '5',
        3,
        'FL-4.2.1 (K3) Die Äquivalenzklassenbildung anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten.\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – es werden zwei Äquivalenzklassen zu wenig geprüft (siehe die 4 KORREKTEN Äquivalenzklassen in c).\n\nb) FALSCH – es wird eine Äquivalenzklasse zu wenig geprüft (siehe die 4 KORREKTEN Äquivalenzklassen in c).\n\nc) KORREKT – Die 4 gültigen Äquivalenzklassen entsprechen der Beschreibung in der Frage; d. h. für jede Äquivalenzklasse ist mindestens ein Testfall zu erstellen:\n1. Äquivalenzklasse: 0 ≤ Beschäftigungszeit ≤ 2,\n2. Äquivalenzklasse: 2 < Beschäftigungszeit < 5,\n3. Äquivalenzklasse: 5 ≤ Beschäftigungszeit ≤ 10\n4. Äquivalenzklasse: 10 < Beschäftigungszeit\n\nd) FALSCH – das ist ein Testfall zu viel; d. h. es werden mehr Testfälle durchgeführt als gültige Äquivalenzklassen vorhanden sind (siehe die 4 KORREKTEN Äquivalenzklassen in c).',
        'https://i.imgur.com/hO9R56c.png'],
        ['Welcher wäre der notwendige Satz von Werten (km/h), der durch die Grenzwertanalyse identifiziert wird, wobei nur die Werte auf den Grenzen der Äquivalenzklassen zu wählen sind?',
        '0, 49, 50, 54, 59, 60',
        '50, 55, 60',
        '49, 50, 54, 55, 60, 62',
        '50, 51, 55, 56, 60, 61',
        4,
        'FL-4.2.2 (K3) Die Grenzwertanalyse anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\nDie folgenden Partitionen (Äquivalenzklassen) und Grenzwerte für die Geschwindigkeit (v) können identifiziert werden:\n\nÄquivalenzklasse 1: <= 50, Grenzwert 50\nÄquivalenzklasse 2: 51 – 55; Grenzwerte 51, 55\nÄquivalenzklasse 3: 56 – 60; Grenzwerte 56, 60\nÄquivalenzklasse 4. >=61; Grenzwert 61\n\nGrenzwert gem. Glossar V.3.3: Der kleinste oder der größte Wert einer geordneten Äquivalenzklasse.\n\na) FALSCH – Enthält nicht alle notwendigen Grenzwerte, dafür aber zusätzliche Werte hier: 0, 49, 54, 59, die keine Grenzwerte in diesen Äquivalenzklassen sind. (vgl. CTFL CORE Lehrplan 2018, Abschnitt 4.2.2)\n\nb) FALSCH – Enthält nicht alle notwendigen Grenzwerte. Es fehlen 51,56 und 61 (vgl. CTFL CORE Lehrplan 2018, Abschnitt 4.2.2)\n\nc) FALSCH – Enthält nicht alle notwendigen Grenzwerte, dafür aber zusätzliche Werte hier: 49, 54, 62, die keine Grenzwerte sind. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.2.2)\n\nd) KORREKT – Enthält alle notwendigen Grenzwerte. (vgl. CTFL CORE Lehrplan 2018; Abschnitt 4.2.2)',
        'https://i.imgur.com/jRvqCL9.png'],
        ['Welcher der Testfälle beschreibt eine in der Praxis vorkommende Situation und fehlt in der Entscheidungstabelle?',
        'Bedingung1 = JA, Bedingung2 = NEIN, Bedingung3 = JA, Aktion = NEIN',
        'Bedingung1 = JA, Bedingung2 = JA, Bedingung3 = NEIN, Aktion = JA',
        'Bedingung1 = NEIN, Bedingung2 = NEIN, Bedingung3 = JA, Aktion = NEIN',
        'Bedingung1 = NEIN, Bedingung2 = JA, Bedingung3 = NEIN, Aktion = NEIN',
        4,
        'FL-4.2.3 (K3) Entscheidungstabellentests anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Wenn kein Ziel vereinbart wurde, kann das nicht vereinbarte Ziel auch nicht erreicht werden. Daher handelt es sich nicht um ein in der Praxis vorkommendes Szenario.\n\nb) FALSCH – Der Testfall ist fachlich falsch, da unter diese Bedingungen keine Prämie gezahlt wird, weil das vereinbarte Ziel nicht erreicht wurde.\n\nc) FALSCH – Wenn kein Ziel vereinbart wurde, kann das nicht vereinbarte Ziel auch nicht erreicht werden. Daher handelt es sich nicht um ein in der Praxis vorkommendes Szenario. (Vgl. Antwort a)\n\nd) KORREKT – Der Testfall beschreibt die Situation, dass sowohl die zu kurze Beschäftigungszeit als auch das Nichterreichen des vereinbarten Ziels zur Nichtauszahlung der Prämie führen. Diese Situation kann in der Praxis vorkommen, fehlt aber in der Entscheidungstabelle.',
        'https://i.imgur.com/z8TBxvr.png'],
        ['Welche der Aussagen zum Zustandsdiagramm und der Tabelle von Testfällen ist WAHR?',
        'Die Testfälle decken sowohl gültige als auch ungültige (Zustands-)Übergänge im Zustands(übergangs)diagramm ab.',
        'Die Testfälle decken alle gültigen (Zustands-)Übergänge im Zustands(übergangs)diagramm ab.',
        'Die Testfälle decken nur einige der gültigen (Zustands-)Übergänge im Zustands(übergangs)diagramm ab.',
        'Die Testfälle decken sequentielle Paare von (Zustands-)Übergängen im Zustands(übergangs)diagramm ab.',
        2,
        'FL-4.2.4 (K3) Zustandsübergangstests anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\nDie vorgeschlagenen Testfälle überdecken genau alle fünf möglichen gültigen (Zustands-) \n\nÜbergänge im gegebenen Zustands(übergangs)diagramm (S1-> S2, S2-> S1, S2-> S3, S3-> S2, S3-> S1).\nDaher gilt:\na) FALSCH – da keine ungültigen (Zustands-)Übergänge, wie z. B. S1->S3, abgedeckt werden.\n\nb) KORREKT – da alle 5 gültigen (Zustands-)Übergänge abgedeckt werden.\n\nc) FALSCH – da alle gültigen (Zustands-)Übergänge abgedeckt werden (siehe b).\n\nd) FALSCH – da die Testfälle überhaupt keine Paare von (Zustands-)Übergängen enthalten',
        'https://i.imgur.com/B6lvqp6.png'],
        ['Welche Testfallmenge ist das Ergebnis der Anwendung der Äquivalenzklassenbildung zum Testen der dargestellten Anforderung, mit dem Ziel einer 100% Äquivalenzklassenüberdeckung?',
        'Prüfe, ob die Anwendung ein Video auf einem Display der Auflösung 1920x1080 wiedergeben kann (1 Testfall).',
        'Prüfe, ob die Anwendung ein Video auf einem Display der kleinsten (640x480) und größten Auflösung (1920x1080) wiedergeben kann (2 Testfälle).',
        'Prüfe, ob die Anwendung ein Video auf jeder der geforderten Displayauflösungen wiedergeben kann (4 Testfälle).',
        'Prüfe, ob die Anwendung ein Video auf einer beliebigen der geforderten Displayauflösungen wiedergeben kann (1 Testfall).',
        3,
        'FL-4.2.1 (K3) Die Äquivalenzklassenbildung anwenden können, um Testfälle aus vorgegebenen Anforderungen abzuleiten.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – siehe c).\nb) FALSCH – siehe c).\nc) KORREKT – Dies ist ein Fall, in dem die Anforderung eine Aufzählung von einzelnen Werten beinhaltet. Jeder aufgezählte Wert ist für sich genommen eine Äquivalenzklasse, da diese Werte nicht „erwartungsgemäß in derselben Art und Weise verarbeitet werden“ müssen (CTFL CORE Lehrplan 2018, Abschnitt 4.2.1, 1. Satz). Deshalb wird jeder der 4 Werte bei Anwendung der Äquivalenzklassenbildung getestet.\nd) FALSCH – siehe c).',
        'https://i.imgur.com/UtkxEQU.png'],
        ['Welche der folgenden Aussagen beschreibt AM BESTEN, wie Aufgaben zwischen Testmanager und Tester aufgeteilt werden?',
        'Der Testmanager plant Testaktivitäten und wählt die zu befolgenden Standards aus, während der Tester die Werkzeuge und die anzuwendenden Werkzeug-Nutzungsregeln auswählt',
        'Der Testmanager plant, koordiniert und steuert die Testaktivitäten, während der Tester die Tests automatisiert.',
        'Der Testmanager plant, überwacht und steuert die Testaktivitäten, während der Tester die Tests entwirft und über die Freigabe des Testobjekts entscheidet.',
        'Der Testmanager plant und organisiert die Testdurchführung und entwirft die Testfälle, während die Tester die Tests durchführen.',
        2,
        'FL-5.1.2 (K1) Die Aufgaben eines Testmanagers und eines Testers benennen können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH: Auswahl der Werkzeuge ist eine Testmanager-Aufgabe (CTFL CORE Lehrplan 2018, Abschn. 5.1.2, 11. Aufzählungspunkt).\n\nb) KORREKT – Aufteilung der Aufgaben gem. CTFL CORE Lehrplan 2018, Abschnitt 5.1.2 (Testmanager 2.+ 4. + 8. Aufzählungspunkt; Tester 10. Aufzählungspunkt).\n\nc) FALSCH: Der Tester entscheidet nicht über die Freigabe des Testobjekts, sondern der Testmanager prüft den Stand der Endekriterien … und erstellt … Testabschlussberichte auf der Grundlage der gesammelten Informationen Abschnitt 5.1.2 (Testmanager 6.+ 7.  Aufzählungspunkt)\n\nd) FALSCH: Der Tester entwirft die Testfälle (CTFL CORE Lehrplan 2018, Abschn. 5.1.2 (Tester 5. Aufzählungspunkt).',
        ''],
        ['Welche der folgenden Metriken ist am NÜTZLICHSTEN für die Messung des Testfortschritts während der Testdurchführung (beim dynamischenTest)?',
        'Prozentualer Anteil der durchgeführten Testfälle',
        'Anzahl der durchschnittlich an der Testdurchführung beteiligten Tester',
        'Überdeckung der Anforderungen durch Code',
        'Prozentualer Anteil der bereits erstellten und gereviewten Testfälle',
        1,
        'FL-5.3.1 (K1) Testmetriken wiedergeben können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – CTFL CORE Lehrplan 5.3.1, Testmetriken, 3. Aufzählungspunkt: „Testfalldurchführung (z. B. Anzahl ausgeführter/nicht ausgeführter Testfälle …)“.\n\nb) FALSCH – Diese Metrik kann zwar gemessen werden, ihre Aussagekraft ist jedoch verschwindend gering. Die Anzahl der Tester sagt nicht viel über die Qualität des Testobjekts oder über den Testfortschritt aus.\n\nc) FALSCH – Die Überdeckung der Anforderungen durch Code wird nicht während der Testdurchführung gemessen. Hierbei wird höchstens die TEST(!)überdeckung des Codes oder der Anforderungen gemessen.\n\nd) FALSCH – diese Metrik ist ein Aspekt des Fortschritts im Rahmen der Aktivitäten vor der Testdurchführung und nicht der Testdurchführung selbst.',
        ''],
        ['Welche der folgenden Antwortmöglichkeiten kann sich auf die (initiale) Testplanung auswirken oder Teil davon sein?',
        'Budgetbeschränkungen',
        'Testprotokoll',
        'Ausfallrate',
        'Anwendungsfälle aus dem aktuellen Projekt',
        1,
        'FL-5.2.1 (K2) Den Zweck und Inhalt eines Testkonzepts zusammenfassen können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Festlegen des Testbudgets ist Bestandteil der Testplanungsaktivitäten. Nach CTFL CORE Lehrplan 2018; Abschnitt 5.2.1: gehören zum Testplan die Budgetierung (7.Aufzählungspunkt) und die Entscheidung, was getestet werden soll (4. Aufzählungspunkt); d. h., wenn Sie den Test planen und es Budgeteinschränkungen gibt, sind Prioritäten darüber erforderlich, was getestet und was weggelassen werden soll."\n\nb) FALSCH – Das Testprotokoll entsteht erst während der Testdurchführung t (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.3, Arbeitsergebnisse der Testdurchführung, 2. Aufzählungspunkt). Es wird auch während der Testdurchführung überprüft (siehe CTFL CORE Lehrplan 2018; Abschnitt 1.4.2; Testüberwachung undTeststeuerung, 1. Aufzählungspunkt).\n\nc) FALSCH – Die Ausfallrate ist eine Metrik, die im Rahmen der Aktivität „Testüberwachung“ und Steuerung natürlich erst bei der Testdurchführung gemessen wird; siehe CTFL CORE Lehrplan 2018; Abschnitt 5.3.1, Gängige Testmetriken, 4.Aufzählungspunkt.\n\nd) FALSCH – Anwendungsfälle werden erst im Rahmen der Aktivität „Testanalyse“verwendet, die erst nach der initialen Testplanung stattfindet. (Siehe z. B. CTFL CORE Lehrplan 2018; Abschnitt 1.4.2, Testanalyse, 1. Unterpunkt des 1. Aufzählungspunktes.)',
        ''],
        ['Welche der folgenden Listen enthält nur typische Endekriterien?',
        'Kennzahlen zu Zuverlässigkeit, Kennzahlen zu Testüberdeckung, Status über Fehlerbehebung und Restrisiken',
        'Kennzahlen zu Zuverlässigkeit, Kennzahlen zu Testüberdeckung, Grad der Unabhängigkeit der Tester, Grad der Produktvollständigkeit',
        'Kennzahlen zu Zuverlässigkeit, Kennzahlen zu Testüberdeckung, Testkosten, Zeit bis Markteinführung („Time-to-Market“), Grad der Produktvollständigkeit',
        'Zeit bis Markteinführung („Time-to-Market“), Restfehler, Qualifikation der Tester, Testüberdeckung und Testkosten',
        1,
        'FL-5.2.3 (K2) Beispiele für mögliche Eingangs- und Endekriterien geben können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – siehe CTFL Lehrplan 2018; Abschnitt 5.2.3 (4 der 5 Punkte, außer „geplante Tests wurden durchgeführt“)\n\nb) FALSCH – Der Grad der Unabhängigkeit der Tester spielt keine Rolle bei den Endekriterien (vgl. CTFL CORE Lehrplan 2018; Abschn. 5.2.3).\n\nc) FALSCH – „Grad der Produktvollständigkeit“ ist kein typisches Endekriterium (vgl. CTFL CORE Lehrplan 2018; Abschn. 5.2.3).\n\nd) FALSCH – Die „Qualifikation der Tester“ ist kein typisches Endekriterium (vgl. CTFL CORE Lehrplan 2018, Abschn. 5.2.3).',
        ''],
        ['Welches der folgenden Elemente ist NICHT in einem Testabschlussbericht enthalten?',
        'Definition der Endekriterien (Definition-of-Done)',
        'Abweichungen von der Testvorgehensweise',
        'Messung des tatsächlichen Fortschritts im Vergleich zu den Endekriterien',
        'Bewertung der Qualität des Testobjekts',
        1,
        'FL-5.3.2 (K2) Zweck, Inhalte und Zielgruppen für Testberichte zusammenfassen können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – Diese Informationen wurden bereits vorher im Testkonzept definiert (Endekriterien in CTFL CORE Lehrplan 2018, Abschn. 1.4.3, Arbeitsergebnisse der Testplanung; sind aber nicht Bestandteil des Testabschlussberichts (CTFL CORE Lehrplan 2018, Abschn. 5.3.2, „Typische … Testabschlussberichte … enthalten“).\n\nb) FALSCH – Diese Informationen sind in einem Testbericht enthalten, siehe CTFL CORE Lehrplan 2018; Abschnitt 5.3.2, „Typische … Testabschlussberichte … enthalten“, Aufzählungspunkte 2 und 3: Informationen darüber, was während eines Testzeitraums passiert ist, und welche Abweichungen es gab.\n\nc) FALSCH – Diese Informationen sind in einem Testbericht enthalten, siehe CTFL CORE Lehrplan 2018; Abschnitt 5.3.2, Aufzählungspunkt 4 und 6:\n• Stand der Tests und Produktqualität in Bezug auf die Endekriterien oder die Definition-of-Done (Aufzählungspunkt 4)\n• Metriken über Fehlerzustände, Testfälle, Testüberdeckung, Aktivitätsfortschritt und Ressourcenverbrauch (bspw. wie in Abschnitt 5.3.1 Beim Testen verwendete Metriken beschrieben) (Aufzählungspunkt 6)\n\nd) FALSCH – Diese Informationen sind in einem Testbericht enthalten, siehe CTFL CORE Lehrplan 2018; Abschnitt 5.3.2, 1. Aufzählung, 4. Aufzählungspunkt, und 2. Aufzählung, 4. Aufzählungspunkt.',
        ''],
        ['Welche vier gängigen Arten von Teststrategien/Vorgehensweisen wurden in diesem Testkonzept umgesetzt?',
        'analytisch, methodisch, regressionsvermeidend und reaktiv',
        'analytisch, standardkonform, beratend und reaktiv',
        'analytisch, methodisch, standardkonform und beratend',
        'methodisch, beratend, regressionsvermeidend und reaktiv',
        2,
        'FL-5.2.2 (K2) Zwischen verschiedenen Teststrategien unterscheiden können.\nBegründung: (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\nDie Zuordnung der Punkte 1 bis 4 zu Vorgehensweisen/Ansätze gemäß Abschnitt 5.2.2 im CTFL CORE Syllabus 2018 ist nur bei Option b) KORREKT.\n\nDie Zuordnungen lassen sich wie folgt begründen:\n\n1.: Vorgehensweise/Ansatz 3 ist analytisch; siehe CTFL CORE Syllabus 2018, Abschnitt \n\n5.2.2, erster Aufzählungspunkt, 2. Satz: Risikobasiertes Testen ist ein Beispiel für eine analytische Vorgehensweise, bei der Tests auf Grundlage der Risikostufe entworfen und priorisiert werden.“\n\n2.: Vorgehensweise/Ansatz 2 ist standardkonform, denn die Regelungsalgorithmen wurden gegen den branchenspezifischen Standard der Energiesparverordnung geprüft (siehe CTFL CORE Syllabus 2018, Abschnitt 5.2.2, vierter Aufzählungspunkt).\n\n3.: Vorgehensweise/Ansatz 4 ist abgeleitet (oder beratend); siehe CTFL CORE Syllabus 2018, Abschnitt 5.2.2, 5. Aufzählungspunkt: „Diese Art der Teststrategie wird vorrangig durch Beratung, Anleitung oder Anweisungen von Stakeholdern, Fachexperten oder Technologieexperten bestimmt, die von außerhalb des Testteams oder sogar von außerhalb des Unternehmens kommen können.“\n\n4.: Vorgehensweise/Ansatz 1 ist reaktiv; siehe CTFL CORE Syllabus 2018, Abschnitt 5.2.2, 7. (letzter) Aufzählungspunkt, letzter Satz: „Exploratives Testen ist eine gängige Vorgehensweise in reaktiven Strategien.“, wobei das explorative Testen der Kategorie erfahrungsbasiertes Testen zugeordnet ist (siehe CTFL CORE Syllabus 2018, Abschnitte 4.4 und 4.4.2).',
        'https://i.imgur.com/l3BspUz.png'],
        ['Welcher der folgenden Punkte kennzeichnet einen auf Metriken basierenden Ansatz für die Testaufwandsschätzung?',
        'Budget, das von einem früheren, ähnlichen Testprojekt verwendet wurde.',
        'Übergreifende Erfahrung aus gesammelten Interviews mit Testmanagern.',
        'Im Testteam abgestimmte Aufwandsschätzung für die Testautomatisierung.',
        'Von den Fachexperten gesammelte durchschnittliche Kalkulationen.',
        1,
        'FL-5.2.6 (K2) Den Unterschied zwischen zwei Schätzverfahren erklären können: das metrikenbasierte Verfahren und das expertenbasierte Verfahren\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) KORREKT – siehe CTFL CORE Lehrplan 2018; Abschnitt 5.2.6, erster Aufzählungspunkt: „Das metrikbasierte Verfahren: Schätzung des Testaufwands auf Basis von Metriken früherer ähnlicher Projekte oder auf Basis von typischen Werten“.\n\nb) FALSCH – Dies ist das expertenbasierte Verfahren: „Schätzung des Testaufwands basierend auf der Erfahrung der für die Testaufgaben zuständigen Person oder von Experten“ (siehe CTFL CORE Lehrplan 2018; Abschnitt 5.2.6, zweiter Aufzählungspunkt).\n\nc) FALSCH – Dies ist ein expertenbasiertes Verfahren. „(…) ein Beispiel für das expertenbasierte Verfahren, da Teammitglieder den Aufwand schätzen …“ (vgl. CTFL CORE Lehrplan 2018; Abschnitt 5.2.6, 2. Absatz, letzter Satz).\n\nd) FALSCH – Dies ist das expertenbasierte Verfahren: „Schätzung des Testaufwands basierend auf der Erfahrung der für die Testaufgaben zuständigen Person oder von Experten“ (siehe CTFL CORE Lehrplan 2018; Abschnitt 5.2.6, zweiter Aufzählungspunkt).',
        ''],
        ['Welche Reihenfolge der Testausführung berücksichtigt die dargestellten Abhängigkeiten?',
        'R1 -> R3 -> R4 -> R7 -> R2 -> R5 -> R6',
        'R1 -> R3 -> R2 -> R4 -> R7 -> R5 -> R6',
        'R1 -> R3 -> R2 -> R5 -> R6 -> R4 -> R7',
        'R1 -> R2 -> R5 -> R6 -> R3 -> R4-> R7',
        3,
        'FL-5.2.4 (K3) Wissen über Priorisierung sowie technische und logische Abhängigkeiten anwenden können, um die Testdurchführung für ein gegebenes Testfallset zu planen.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3\n\na) FALSCH – R4 ist abhängig von R2, also sollte R2 vor R4 getestet werden.\n\nb) FALSCH – R4 ist abhängig von R2, R5 und R6, also sollten R5 und R6 vor R4 getestet werden.\n\nc) KORREKT – Die Tests sind in einer Reihenfolge festgelegt, welche alle 7 Abhängigkeiten berücksichtigt: R1 -> R3; R1 -> R2; R2 -> R5; R2 -> R6; R3 -> R2; R4 von R2, R5 und R6 abhängig; R7 von R2, R5 und R6 abhängig\n\nd) FALSCH – R2 ist abhängig von R3, also sollte R3 vor R2 getestet werden.',
        'https://i.imgur.com/FL98A08.png'],
        ['Welche Information wurde in dem dargestellten Fehlerbericht vergessen?',
        'Tatsächliches Testergebnis',
        'Identifikation der getesteten Softwareversion',
        'Status des Fehlerzustands',
        'Ideen zur Verbesserung des Testfalls',
        2,
        'FL-5.6.1 (K3) Einen Fehlerbericht schreiben können, der einen während des Testens gefundenen Fehler enthält.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Das Testergebnis („Temperatur des Getränks zu niedrig (weniger als 40 ºC)“) steht in der kurzen Zusammenfassung.\n\nb) KORREKT – Beim Testen verschiedener Softwareversionen sind die Informationen zur Identifizierung notwendig (vgl. CTFL CORE Lehrplan 2018; Abschnitt 5.6; Absatz „Ein Fehlerbericht … enthält …:“, 4.Aufzählungspunkt).\n\nc) FALSCH – Sie schreiben gerade den Fehlerbericht, daher ist der Status per Definitionautomatisch offen.\n\nd) FALSCH – Diese Informationen sind für den Tester nützlich, müssen aber nicht in den Fehlerbericht aufgenommen werden (vgl. CTFL CORE Lehrplan 2018; Abschnitt 5.6; Absatz „Ein Fehlerbericht … enthält …:“).',
        'https://i.imgur.com/IHw4YGs.png'],
        ['Welche der folgenden Aussagen beschreibt am EHESTEN einen Vorteil für die Nutzung eines Testausführungswerkzeugs.',
        'Es ist einfach, Regressionstests zu erstellen.',
        'Es ist einfach, die Versionen von Testobjekten zu kontrollieren.',
        'Es ist einfach, Testfälle für Zugriffssicherheitstests zu entwerfen.',
        'Es ist einfach, Regressionstests durchzuführen.',
        4,
        'FL-6.1.2 (K1) Nutzen und Risiken der Testautomatisierung identifizieren können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Die Vorteile liegen nicht in der Erstellung von Regressionstests, sondern in deren Ausführung.\n\nb) FALSCH – Dies geschieht mit Hilfe von Konfigurationsmanagementwerkzeugen.\n\nc) FALSCH – Dies erfordert spezielle Werkzeuge.\n\nd) KORREKT – CTFL CORE Lehrplan 2018; Abschnitt 6.1.2: Durch die „Reduktion von sich wiederholender manueller Arbeit (z. B.Durchführung von Regressionstests, Aufsetzen oder Abbau von Testumgebungen, wiederholte Eingabe der gleichen Testdaten und Prüfung gegen Programmierrichtlinien) und dadurch Zeiteinsparung.“',
        ''],
        ['Welche der folgenden Testwerkzeuge sind für Entwickler besser geeignet als für Tester?',
        'Anforderungsmanagementwerkzeuge',
        'Konfigurationsmanagementwerkzeuge',
        'Statische Analysewerkzeuge',
        'Performanztestwerkzeuge',
        3,
        'FL-6.1.1 (K2) Testwerkzeuge gemäß ihrem Zweck und den Testaktivitäten, die sie unterstützen, klassifizieren können.\n\nBegründung (nach CTFL CORE Lehrplan 2018, V.3.1; Glossar V.3.3)\n\na) FALSCH – Anforderungsmanagementwerkzeuge sind gem. CTFL CORE Lehrplan 2018, Abschnitt 6.1.1 nicht insbesondere für Entwickler geeignet (kein Zusatz „(E)“).\n\nb) FALSCH – Konfigurationswerkzeuge sind gem. CTFL CORE Lehrplan 2018, Abschnitt 6.1.1 nicht insbesondere für Entwickler geeignet (kein Zusatz „(E)“).\n\nc) KORREKT – Statische Analysewerkzeuge sind gem. CTFL CORE Lehrplan 2018, Abschnitt 6.1.1 insbesondere für Entwickler geeignet, siehe Zusatz „(E)“.\n\nd) FALSCH – Performanztestwerkzeuge sind gem. CTFL CORE Lehrplan 2018; Abschnitt 6.1.1 nicht insbesondere für Entwickler geeignet (kein Zusatz „(E)“).',
        '']
        ];
        function validate()
        { //Validate answer, show explanation
            var a1 = document.getElementById("check1").checked;
            var a2 = document.getElementById("check2").checked;
            var a3 = document.getElementById("check3").checked;
            var a4 = document.getElementById("check4").checked;
            if (a1 + a2 + a3 + a4 != 1)
            { //Error, there is not only exactly one answer selected.
                alert(msgAlertOnlyOne);
                return;
            }
            var correctAnswer = qanda[q-1][5];
            if (a1 && correctAnswer == 1 || a2 && correctAnswer == 2 || a3 && correctAnswer == 3 || a4 && correctAnswer == 4)
            { //Correct
                if (a1) document.getElementById("answer1").classList.add("correct");
                if (a2) document.getElementById("answer2").classList.add("correct");
                if (a3) document.getElementById("answer3").classList.add("correct");
                if (a4) document.getElementById("answer4").classList.add("correct");
                correctAnswers++;
            }
            else
            { //Wrong
                if (correctAnswer == 1) document.getElementById("answer1").classList.add("correct");
                if (correctAnswer == 2) document.getElementById("answer2").classList.add("correct");
                if (correctAnswer == 3) document.getElementById("answer3").classList.add("correct");
                if (correctAnswer == 4) document.getElementById("answer4").classList.add("correct");
            }
            document.getElementById("submit").style.visibility = "hidden";
            document.getElementById("next").style.visibility = "visible";
            document.getElementById("explanation").style.visibility = "visible";
            document.getElementById("explanation").value = qanda[q-1][6];
        }
        function moveon()
        { //Move to the next question
            q++;
            if (q > qanda.length)
            {
                alert(msgCorrectAnswers + correctAnswers + msgCorrectAnswersOf + qanda.length)
                q = 1;
                correctAnswers  = 0;
            }
            document.getElementById("next").style.visibility = "hidden";
            document.getElementById("submit").style.visibility = "visible";
            document.getElementById("explanation").style.visibility = "hidden";
            document.getElementById("check1").checked = false;
            document.getElementById("check2").checked = false;
            document.getElementById("check3").checked = false;
            document.getElementById("check4").checked = false;
            document.getElementById("answer1").innerHTML = qanda[q-1][1];
            document.getElementById("answer2").innerHTML = qanda[q-1][2];
            document.getElementById("answer3").innerHTML = qanda[q-1][3];
            document.getElementById("answer4").innerHTML = qanda[q-1][4];
            document.getElementById("explanation").value = "";
            document.getElementById("question").innerHTML = qanda[q-1][0];
            document.getElementById("answer1").classList.remove("correct");
            document.getElementById("answer2").classList.remove("correct");
            document.getElementById("answer3").classList.remove("correct");
            document.getElementById("answer4").classList.remove("correct");
            document.getElementById("check1").style="outline-style:none";
            document.getElementById("check2").style="outline-style:none";
            document.getElementById("check3").style="outline-style:none";
            document.getElementById("check4").style="outline-style:none";
            if (qanda[q-1][7] == "")
            {
                document.getElementById("image").style.display = "none";
            }
            else
            {
                document.getElementById("image").style.display = "inline";
                document.getElementById("image").src = qanda[q-1][7];
            }
        }
    </script>
    </head>
    <body style="font: normal 12px Verdana, Arial, sans-serif">
    <form action="#">
        <div id="question"></div>
        <br/>
        <img id="image" src="" style="display:none;" width="500">
        <fieldset>
        <div>
        <input type="checkbox" id="check1">&nbsp;<label for="check1" id="answer1" ></label>
        </div>
        <br/>
        <div>
        <input type="checkbox" id="check2">&nbsp;<label for="check2" id="answer2" ></label>
        </div>
        <br/>
        <div>
        <input type="checkbox" id="check3">&nbsp;<label for="check3" id="answer3"></label>
        </div>
        <br/>
        <div >
        <input type="checkbox" id="check4" >&nbsp;<label for="check4" id="answer4"></label>
        </div>
        </fieldset>
        <br/>
        <br/>
        <input id="submit" type="button" value="Absenden" onclick="validate()">
        <input id="next" type="button" value="Nächste Frage" onclick="moveon()" style="visibility:hidden;">
        <br/>
        <br/>
        <textarea id="explanation" style="visibility:hidden;border:none;resize:none;"></textarea>
        </form>
        <script>
        moveon(); //Start
        </script>
    </body>
</html>